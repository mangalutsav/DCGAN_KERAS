{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "from keras.layers import *\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import math\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://bamos.github.io/data/2016-08-09/gen-architecture.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"http://bamos.github.io/data/2016-08-09/gen-architecture.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    model = Sequential([\n",
    "        Dense(1024*4*4, input_dim=100, activation=LeakyReLU(0.2)),\n",
    "        BatchNormalization(),\n",
    "        Reshape((4,4,1024)),\n",
    "        UpSampling2D(),\n",
    "        Conv2D(512, (5, 5), padding='same', activation=LeakyReLU(0.2)),\n",
    "        BatchNormalization(),\n",
    "        UpSampling2D(),\n",
    "        Conv2D(256,(5, 5), padding='same', activation='tanh'),\n",
    "        BatchNormalization(),\n",
    "        UpSampling2D(),\n",
    "        Conv2D(128, (5, 5), padding='same', activation='tanh'),\n",
    "        BatchNormalization(),\n",
    "        UpSampling2D(),\n",
    "        Conv2D(3,(5, 5), padding='same', activation='tanh')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 16384)             1654784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 16384)             65536     \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 512)         13107712  \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 256)       3277056   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 32, 32, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_13 (UpSampling (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 64, 64, 3)         9603      \n",
      "=================================================================\n",
      "Total params: 18,937,603.0\n",
      "Trainable params: 18,903,043.0\n",
      "Non-trainable params: 34,560.0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "m1=generator_model().summary()\n",
    "print(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://bamos.github.io/data/2016-08-09/discrim-architecture.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"http://bamos.github.io/data/2016-08-09/discrim-architecture.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (5, 5), input_shape=(64,64,3), padding='same', activation=LeakyReLU(0.2)),\n",
    "        MaxPool2D(pool_size=(2,2)),\n",
    "        Dropout(0.3),\n",
    "        Convolution2D(128, (5, 5), padding='same', activation=LeakyReLU(0.2)),\n",
    "        MaxPool2D(pool_size=(2,2)),\n",
    "        Dropout(0.3),\n",
    "        Convolution2D(256, (5, 5), padding='same', activation=LeakyReLU(0.2)),\n",
    "        MaxPool2D(pool_size=(2,2)),\n",
    "        Dropout(0.3),\n",
    "        Convolution2D(512, (5, 5), padding='same', activation=LeakyReLU(0.2)),\n",
    "        MaxPool2D(pool_size=(2,2)),\n",
    "        Dropout(0.3),\n",
    "        Flatten(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 64, 64, 64)        4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 32, 32, 128)       204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 8, 8, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 4,314,753.0\n",
      "Trainable params: 4,314,753.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(discriminator_model().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(g, d):\n",
    "    model = Sequential()\n",
    "    model.add(g)\n",
    "    d.trainable = False\n",
    "    model.add(d)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "cannot identify image file <open file '/home/shubham/DCGAN/img_align_celeba_64/Legends of Tomorrow 3.desktop', mode 'rb' at 0x7fb17d856f60>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a7cfae164483>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/shubham/DCGAN/img_align_celeba_64/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mx_complete\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_complete\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shubham/anaconda2/lib/python2.7/site-packages/skimage/io/_io.pyc\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_grey, plugin, flatten, **plugin_args)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shubham/anaconda2/lib/python2.7/site-packages/skimage/io/manage_plugins.pyc\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                                (plugin, kind))\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shubham/anaconda2/lib/python2.7/site-packages/skimage/io/_plugins/pil_plugin.pyc\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, dtype, img_num, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shubham/anaconda2/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2318\u001b[0m     raise IOError(\"cannot identify image file %r\"\n\u001b[0;32m-> 2319\u001b[0;31m                   % (filename if filename else fp))\n\u001b[0m\u001b[1;32m   2320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: cannot identify image file <open file '/home/shubham/DCGAN/img_align_celeba_64/Legends of Tomorrow 3.desktop', mode 'rb' at 0x7fb17d856f60>"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "imgs=os.listdir('/home/shubham/DCGAN/img_align_celeba_64')\n",
    "l=[]\n",
    "for j,i in enumerate(imgs):\n",
    "    l.append(io.imread('/home/shubham/DCGAN/img_align_celeba_64/'+i))\n",
    "x_complete=np.array(l)\n",
    "plt.imshow(x_complete[0])\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa970678110>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8ANBEX4gKMIPBEX4gaAIPxAU4QeC+n8DZI6NXofNrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa9a8655050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train=X_train.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=(X_train-127.5)/127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa978a653d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8ANBEX4gKMIPBEX4gaAIPxAU4QeC+n8DZI6NXofNrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa97065bb90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -0.97647059\n",
      "  -0.85882354 -0.85882354 -0.85882354 -0.01176471  0.06666667  0.37254903\n",
      "  -0.79607844  0.3019608   1.          0.93725491 -0.00392157 -1.         -1.\n",
      "  -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -0.7647059  -0.71764708 -0.26274511  0.20784314  0.33333334\n",
      "   0.98431373  0.98431373  0.98431373  0.98431373  0.98431373  0.7647059\n",
      "   0.34901962  0.98431373  0.89803922  0.52941179 -0.49803922 -1.         -1.\n",
      "  -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -0.6156863   0.86666667  0.98431373  0.98431373  0.98431373  0.98431373\n",
      "   0.98431373  0.98431373  0.98431373  0.98431373  0.96862745 -0.27058825\n",
      "  -0.35686275 -0.35686275 -0.56078434 -0.69411767 -1.         -1.         -1.\n",
      "  -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -0.85882354  0.71764708  0.98431373  0.98431373  0.98431373  0.98431373\n",
      "   0.98431373  0.5529412   0.42745098  0.93725491  0.89019608 -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -0.37254903  0.22352941 -0.16078432  0.98431373  0.98431373\n",
      "   0.60784316 -0.9137255  -1.         -0.66274512  0.20784314 -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -0.89019608 -0.99215686  0.20784314  0.98431373\n",
      "  -0.29411766 -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.          0.09019608  0.98431373\n",
      "   0.49019608 -0.98431373 -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -0.9137255   0.49019608\n",
      "   0.98431373 -0.4509804  -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -0.72549021\n",
      "   0.89019608  0.7647059   0.25490198 -0.15294118 -0.99215686 -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -0.36470589  0.88235295  0.98431373  0.98431373 -0.06666667 -0.80392158\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -0.64705884  0.45882353  0.98431373  0.98431373  0.17647059 -0.78823531\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -0.87450981 -0.27058825  0.97647059  0.98431373  0.46666667\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.          0.95294118  0.98431373  0.95294118\n",
      "  -0.49803922 -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -0.63921571  0.01960784  0.43529412  0.98431373  0.98431373  0.62352943\n",
      "  -0.98431373 -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -0.69411767\n",
      "   0.16078432  0.79607844  0.98431373  0.98431373  0.98431373  0.96078432\n",
      "   0.42745098 -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -0.81176472 -0.10588235  0.73333335\n",
      "   0.98431373  0.98431373  0.98431373  0.98431373  0.57647061 -0.3882353\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -0.81960785 -0.48235294  0.67058825  0.98431373  0.98431373\n",
      "   0.98431373  0.98431373  0.5529412  -0.36470589 -0.98431373 -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -0.85882354  0.34117648  0.71764708  0.98431373  0.98431373  0.98431373\n",
      "   0.98431373  0.52941179 -0.37254903 -0.92941177 -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -0.56862748  0.34901962\n",
      "   0.77254903  0.98431373  0.98431373  0.98431373  0.98431373  0.9137255\n",
      "   0.04313726 -0.9137255  -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.          0.06666667  0.98431373\n",
      "   0.98431373  0.98431373  0.66274512  0.05882353  0.03529412 -0.87450981\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -1.         -1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train[:, :, :, None]\n",
    "X_test = X_test[:, :, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[:, :, 0]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa978a14d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=combine_images(X_train[0:1000])\n",
    "plt.imshow(img)\n",
    "from PIL import Image\n",
    "Image.fromarray(img.astype(np.uint8)).save(\n",
    "                   \"sample\"+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1]*12 + [0]*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask=np.ones((64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask[24:40,24:40]=0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true,y_pred):\n",
    "    loss=0.\n",
    "    res1=K.variable(value=y_true)\n",
    "    res2=K.variable(value=y_pred)\n",
    "    for i in range(int(y_true.shape[0])):\n",
    "        res1=np.multiply(mask,y_true[i,:,:,0])\n",
    "        res2=np.multiply(mask,y_pred[i,:,:,0])\n",
    "        los=abs(res1-res2)\n",
    "        loss+=sum(sum(abs(los)))\n",
    "    return 0.1*loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(BATCH_SIZE):\n",
    "    d = discriminator_model()\n",
    "    g= generator_model()\n",
    "    d_on_g = generator_containing_discriminator(g, d)\n",
    "    d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    g.compile(loss= 'hinge_loss', optimizer=\"adam\")\n",
    "    d_on_g.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    d.trainable = True\n",
    "    d.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    for epoch in range(10):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "        for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
    "            noise = np.random.uniform(-1, 1, size=(BATCH_SIZE, 100))\n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            generated_images = g.predict(noise, verbose=0)\n",
    "            if index % 20 == 0:\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5+127.5\n",
    "                Image.fromarray(image.astype(np.uint8)).save(\n",
    "                    str(epoch)+\"_\"+str(index)+\".png\")\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "            d_loss = d.train_on_batch(X, y)\n",
    "            print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
    "            noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "            d.trainable = False\n",
    "            g_loss = d_on_g.train_on_batch(noise, [1] * BATCH_SIZE)\n",
    "            g1_loss= g.train_on_batch(noise,generated_images) #for mG(z)-m(Y)\n",
    "            print(\"batch %d g1_loss : %f\" % (index, g1_loss))\n",
    "            d.trainable = True\n",
    "            print(\"batch %d g_loss : %f\" % (index, g_loss))\n",
    "            if index % 10 == 9:\n",
    "                g.save_weights('generator', True)\n",
    "                d.save_weights('discriminator', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch is', 0)\n",
      "('Number of batches', 468)\n",
      "batch 0 d_loss : 0.730649\n",
      "batch 0 g1_loss : 0.240129\n",
      "batch 0 g_loss : 0.776239\n",
      "batch 1 d_loss : 0.723530\n",
      "batch 1 g1_loss : 0.232085\n",
      "batch 1 g_loss : 0.767185\n",
      "batch 2 d_loss : 0.708389\n",
      "batch 2 g1_loss : 0.230493\n",
      "batch 2 g_loss : 0.753768\n",
      "batch 3 d_loss : 0.690191\n",
      "batch 3 g1_loss : 0.226204\n",
      "batch 3 g_loss : 0.742533\n",
      "batch 4 d_loss : 0.671703\n",
      "batch 4 g1_loss : 0.222564\n",
      "batch 4 g_loss : 0.736073\n",
      "batch 5 d_loss : 0.657287\n",
      "batch 5 g1_loss : 0.219599\n",
      "batch 5 g_loss : 0.721227\n",
      "batch 6 d_loss : 0.636199\n",
      "batch 6 g1_loss : 0.220284\n",
      "batch 6 g_loss : 0.708528\n",
      "batch 7 d_loss : 0.611801\n",
      "batch 7 g1_loss : 0.214050\n",
      "batch 7 g_loss : 0.697963\n",
      "batch 8 d_loss : 0.591273\n",
      "batch 8 g1_loss : 0.213718\n",
      "batch 8 g_loss : 0.682710\n",
      "batch 9 d_loss : 0.584175\n",
      "batch 9 g1_loss : 0.207315\n",
      "batch 9 g_loss : 0.671675\n",
      "batch 10 d_loss : 0.569356\n",
      "batch 10 g1_loss : 0.208265\n",
      "batch 10 g_loss : 0.659580\n",
      "batch 11 d_loss : 0.543587\n",
      "batch 11 g1_loss : 0.203303\n",
      "batch 11 g_loss : 0.649322\n",
      "batch 12 d_loss : 0.531239\n",
      "batch 12 g1_loss : 0.199812\n",
      "batch 12 g_loss : 0.639255\n",
      "batch 13 d_loss : 0.515156\n",
      "batch 13 g1_loss : 0.200598\n",
      "batch 13 g_loss : 0.630324\n",
      "batch 14 d_loss : 0.503583\n",
      "batch 14 g1_loss : 0.197611\n",
      "batch 14 g_loss : 0.625343\n",
      "batch 15 d_loss : 0.503055\n",
      "batch 15 g1_loss : 0.193182\n",
      "batch 15 g_loss : 0.614032\n",
      "batch 16 d_loss : 0.488347\n",
      "batch 16 g1_loss : 0.191720\n",
      "batch 16 g_loss : 0.603249\n",
      "batch 17 d_loss : 0.477046\n",
      "batch 17 g1_loss : 0.189975\n",
      "batch 17 g_loss : 0.598188\n",
      "batch 18 d_loss : 0.471756\n",
      "batch 18 g1_loss : 0.187789\n",
      "batch 18 g_loss : 0.593104\n",
      "batch 19 d_loss : 0.464956\n",
      "batch 19 g1_loss : 0.185278\n",
      "batch 19 g_loss : 0.588745\n",
      "batch 20 d_loss : 0.464550\n",
      "batch 20 g1_loss : 0.183888\n",
      "batch 20 g_loss : 0.580203\n",
      "batch 21 d_loss : 0.457614\n",
      "batch 21 g1_loss : 0.179074\n",
      "batch 21 g_loss : 0.574774\n",
      "batch 22 d_loss : 0.454221\n",
      "batch 22 g1_loss : 0.176968\n",
      "batch 22 g_loss : 0.570276\n",
      "batch 23 d_loss : 0.447448\n",
      "batch 23 g1_loss : 0.179687\n",
      "batch 23 g_loss : 0.567088\n",
      "batch 24 d_loss : 0.445485\n",
      "batch 24 g1_loss : 0.179552\n",
      "batch 24 g_loss : 0.562463\n",
      "batch 25 d_loss : 0.444041\n",
      "batch 25 g1_loss : 0.173329\n",
      "batch 25 g_loss : 0.564656\n",
      "batch 26 d_loss : 0.444435\n",
      "batch 26 g1_loss : 0.173544\n",
      "batch 26 g_loss : 0.560328\n",
      "batch 27 d_loss : 0.443929\n",
      "batch 27 g1_loss : 0.168360\n",
      "batch 27 g_loss : 0.560249\n",
      "batch 28 d_loss : 0.449639\n",
      "batch 28 g1_loss : 0.169645\n",
      "batch 28 g_loss : 0.556881\n",
      "batch 29 d_loss : 0.445967\n",
      "batch 29 g1_loss : 0.167624\n",
      "batch 29 g_loss : 0.555634\n",
      "batch 30 d_loss : 0.439992\n",
      "batch 30 g1_loss : 0.165866\n",
      "batch 30 g_loss : 0.555305\n",
      "batch 31 d_loss : 0.445335\n",
      "batch 31 g1_loss : 0.164276\n",
      "batch 31 g_loss : 0.555610\n",
      "batch 32 d_loss : 0.443979\n",
      "batch 32 g1_loss : 0.162413\n",
      "batch 32 g_loss : 0.556024\n",
      "batch 33 d_loss : 0.446424\n",
      "batch 33 g1_loss : 0.159884\n",
      "batch 33 g_loss : 0.552338\n",
      "batch 34 d_loss : 0.443920\n",
      "batch 34 g1_loss : 0.158421\n",
      "batch 34 g_loss : 0.556920\n",
      "batch 35 d_loss : 0.449869\n",
      "batch 35 g1_loss : 0.158355\n",
      "batch 35 g_loss : 0.559480\n",
      "batch 36 d_loss : 0.455320\n",
      "batch 36 g1_loss : 0.158010\n",
      "batch 36 g_loss : 0.556821\n",
      "batch 37 d_loss : 0.455556\n",
      "batch 37 g1_loss : 0.153133\n",
      "batch 37 g_loss : 0.557459\n",
      "batch 38 d_loss : 0.452769\n",
      "batch 38 g1_loss : 0.156529\n",
      "batch 38 g_loss : 0.557357\n",
      "batch 39 d_loss : 0.452524\n",
      "batch 39 g1_loss : 0.151621\n",
      "batch 39 g_loss : 0.560421\n",
      "batch 40 d_loss : 0.454453\n",
      "batch 40 g1_loss : 0.149836\n",
      "batch 40 g_loss : 0.563149\n",
      "batch 41 d_loss : 0.458241\n",
      "batch 41 g1_loss : 0.149895\n",
      "batch 41 g_loss : 0.563537\n",
      "batch 42 d_loss : 0.461766\n",
      "batch 42 g1_loss : 0.149597\n",
      "batch 42 g_loss : 0.566238\n",
      "batch 43 d_loss : 0.460224\n",
      "batch 43 g1_loss : 0.144972\n",
      "batch 43 g_loss : 0.569618\n",
      "batch 44 d_loss : 0.459191\n",
      "batch 44 g1_loss : 0.144047\n",
      "batch 44 g_loss : 0.570938\n",
      "batch 45 d_loss : 0.454170\n",
      "batch 45 g1_loss : 0.144836\n",
      "batch 45 g_loss : 0.571259\n",
      "batch 46 d_loss : 0.465805\n",
      "batch 46 g1_loss : 0.145162\n",
      "batch 46 g_loss : 0.574590\n",
      "batch 47 d_loss : 0.476007\n",
      "batch 47 g1_loss : 0.141023\n",
      "batch 47 g_loss : 0.579266\n",
      "batch 48 d_loss : 0.467697\n",
      "batch 48 g1_loss : 0.138963\n",
      "batch 48 g_loss : 0.583811\n",
      "batch 49 d_loss : 0.464964\n",
      "batch 49 g1_loss : 0.140491\n",
      "batch 49 g_loss : 0.587911\n",
      "batch 50 d_loss : 0.464410\n",
      "batch 50 g1_loss : 0.138146\n",
      "batch 50 g_loss : 0.590446\n",
      "batch 51 d_loss : 0.468914\n",
      "batch 51 g1_loss : 0.137302\n",
      "batch 51 g_loss : 0.597009\n",
      "batch 52 d_loss : 0.463217\n",
      "batch 52 g1_loss : 0.134729\n",
      "batch 52 g_loss : 0.597668\n",
      "batch 53 d_loss : 0.464329\n",
      "batch 53 g1_loss : 0.132452\n",
      "batch 53 g_loss : 0.607496\n",
      "batch 54 d_loss : 0.469647\n",
      "batch 54 g1_loss : 0.133458\n",
      "batch 54 g_loss : 0.616523\n",
      "batch 55 d_loss : 0.463621\n",
      "batch 55 g1_loss : 0.133828\n",
      "batch 55 g_loss : 0.616986\n",
      "batch 56 d_loss : 0.463904\n",
      "batch 56 g1_loss : 0.130800\n",
      "batch 56 g_loss : 0.621128\n",
      "batch 57 d_loss : 0.463662\n",
      "batch 57 g1_loss : 0.130351\n",
      "batch 57 g_loss : 0.628863\n",
      "batch 58 d_loss : 0.461130\n",
      "batch 58 g1_loss : 0.129799\n",
      "batch 58 g_loss : 0.634443\n",
      "batch 59 d_loss : 0.467553\n",
      "batch 59 g1_loss : 0.126456\n",
      "batch 59 g_loss : 0.641080\n",
      "batch 60 d_loss : 0.462970\n",
      "batch 60 g1_loss : 0.125310\n",
      "batch 60 g_loss : 0.649225\n",
      "batch 61 d_loss : 0.473727\n",
      "batch 61 g1_loss : 0.124110\n",
      "batch 61 g_loss : 0.655713\n",
      "batch 62 d_loss : 0.470251\n",
      "batch 62 g1_loss : 0.124052\n",
      "batch 62 g_loss : 0.665045\n",
      "batch 63 d_loss : 0.458808\n",
      "batch 63 g1_loss : 0.123591\n",
      "batch 63 g_loss : 0.672700\n",
      "batch 64 d_loss : 0.462494\n",
      "batch 64 g1_loss : 0.121230\n",
      "batch 64 g_loss : 0.673425\n",
      "batch 65 d_loss : 0.459678\n",
      "batch 65 g1_loss : 0.118822\n",
      "batch 65 g_loss : 0.689106\n",
      "batch 66 d_loss : 0.465345\n",
      "batch 66 g1_loss : 0.117244\n",
      "batch 66 g_loss : 0.691530\n",
      "batch 67 d_loss : 0.464182\n",
      "batch 67 g1_loss : 0.118392\n",
      "batch 67 g_loss : 0.703702\n",
      "batch 68 d_loss : 0.452548\n",
      "batch 68 g1_loss : 0.117450\n",
      "batch 68 g_loss : 0.709099\n",
      "batch 69 d_loss : 0.453648\n",
      "batch 69 g1_loss : 0.115480\n",
      "batch 69 g_loss : 0.719313\n",
      "batch 70 d_loss : 0.456169\n",
      "batch 70 g1_loss : 0.112495\n",
      "batch 70 g_loss : 0.732752\n",
      "batch 71 d_loss : 0.449479\n",
      "batch 71 g1_loss : 0.110657\n",
      "batch 71 g_loss : 0.734373\n",
      "batch 72 d_loss : 0.448851\n",
      "batch 72 g1_loss : 0.110369\n",
      "batch 72 g_loss : 0.747244\n",
      "batch 73 d_loss : 0.455831\n",
      "batch 73 g1_loss : 0.109174\n",
      "batch 73 g_loss : 0.752910\n",
      "batch 74 d_loss : 0.446743\n",
      "batch 74 g1_loss : 0.107400\n",
      "batch 74 g_loss : 0.764421\n",
      "batch 75 d_loss : 0.447847\n",
      "batch 75 g1_loss : 0.107474\n",
      "batch 75 g_loss : 0.774597\n",
      "batch 76 d_loss : 0.440751\n",
      "batch 76 g1_loss : 0.106278\n",
      "batch 76 g_loss : 0.778791\n",
      "batch 77 d_loss : 0.438083\n",
      "batch 77 g1_loss : 0.104794\n",
      "batch 77 g_loss : 0.791951\n",
      "batch 78 d_loss : 0.432901\n",
      "batch 78 g1_loss : 0.103523\n",
      "batch 78 g_loss : 0.801748\n",
      "batch 79 d_loss : 0.428911\n",
      "batch 79 g1_loss : 0.103333\n",
      "batch 79 g_loss : 0.811015\n",
      "batch 80 d_loss : 0.423400\n",
      "batch 80 g1_loss : 0.102305\n",
      "batch 80 g_loss : 0.817712\n",
      "batch 81 d_loss : 0.422164\n",
      "batch 81 g1_loss : 0.100685\n",
      "batch 81 g_loss : 0.833194\n",
      "batch 82 d_loss : 0.413840\n",
      "batch 82 g1_loss : 0.099912\n",
      "batch 82 g_loss : 0.844062\n",
      "batch 83 d_loss : 0.419320\n",
      "batch 83 g1_loss : 0.099053\n",
      "batch 83 g_loss : 0.855070\n",
      "batch 84 d_loss : 0.402653\n",
      "batch 84 g1_loss : 0.097568\n",
      "batch 84 g_loss : 0.862583\n",
      "batch 85 d_loss : 0.394666\n",
      "batch 85 g1_loss : 0.097791\n",
      "batch 85 g_loss : 0.879543\n",
      "batch 86 d_loss : 0.402591\n",
      "batch 86 g1_loss : 0.098715\n",
      "batch 86 g_loss : 0.891266\n",
      "batch 87 d_loss : 0.386974\n",
      "batch 87 g1_loss : 0.096152\n",
      "batch 87 g_loss : 0.902650\n",
      "batch 88 d_loss : 0.388987\n",
      "batch 88 g1_loss : 0.096061\n",
      "batch 88 g_loss : 0.915127\n",
      "batch 89 d_loss : 0.387360\n",
      "batch 89 g1_loss : 0.095087\n",
      "batch 89 g_loss : 0.927748\n",
      "batch 90 d_loss : 0.382675\n",
      "batch 90 g1_loss : 0.093594\n",
      "batch 90 g_loss : 0.938006\n",
      "batch 91 d_loss : 0.373119\n",
      "batch 91 g1_loss : 0.093432\n",
      "batch 91 g_loss : 0.953094\n",
      "batch 92 d_loss : 0.364669\n",
      "batch 92 g1_loss : 0.092466\n",
      "batch 92 g_loss : 0.962431\n",
      "batch 93 d_loss : 0.353490\n",
      "batch 93 g1_loss : 0.090727\n",
      "batch 93 g_loss : 0.977404\n",
      "batch 94 d_loss : 0.353988\n",
      "batch 94 g1_loss : 0.091491\n",
      "batch 94 g_loss : 0.993425\n",
      "batch 95 d_loss : 0.346036\n",
      "batch 95 g1_loss : 0.091240\n",
      "batch 95 g_loss : 1.010057\n",
      "batch 96 d_loss : 0.353068\n",
      "batch 96 g1_loss : 0.088497\n",
      "batch 96 g_loss : 1.024300\n",
      "batch 97 d_loss : 0.335968\n",
      "batch 97 g1_loss : 0.087877\n",
      "batch 97 g_loss : 1.039068\n",
      "batch 98 d_loss : 0.341646\n",
      "batch 98 g1_loss : 0.089515\n",
      "batch 98 g_loss : 1.053291\n",
      "batch 99 d_loss : 0.351761\n",
      "batch 99 g1_loss : 0.087242\n",
      "batch 99 g_loss : 1.062737\n",
      "batch 100 d_loss : 0.341557\n",
      "batch 100 g1_loss : 0.088842\n",
      "batch 100 g_loss : 1.075032\n",
      "batch 101 d_loss : 0.305081\n",
      "batch 101 g1_loss : 0.086393\n",
      "batch 101 g_loss : 1.098463\n",
      "batch 102 d_loss : 0.299607\n",
      "batch 102 g1_loss : 0.084551\n",
      "batch 102 g_loss : 1.111323\n",
      "batch 103 d_loss : 0.310954\n",
      "batch 103 g1_loss : 0.087061\n",
      "batch 103 g_loss : 1.121254\n",
      "batch 104 d_loss : 0.293390\n",
      "batch 104 g1_loss : 0.084860\n",
      "batch 104 g_loss : 1.140593\n",
      "batch 105 d_loss : 0.284102\n",
      "batch 105 g1_loss : 0.084425\n",
      "batch 105 g_loss : 1.160123\n",
      "batch 106 d_loss : 0.299718\n",
      "batch 106 g1_loss : 0.085880\n",
      "batch 106 g_loss : 1.163477\n",
      "batch 107 d_loss : 0.302939\n",
      "batch 107 g1_loss : 0.085565\n",
      "batch 107 g_loss : 1.188051\n",
      "batch 108 d_loss : 0.291184\n",
      "batch 108 g1_loss : 0.085109\n",
      "batch 108 g_loss : 1.201686\n",
      "batch 109 d_loss : 0.288723\n",
      "batch 109 g1_loss : 0.087283\n",
      "batch 109 g_loss : 1.204483\n",
      "batch 110 d_loss : 0.267347\n",
      "batch 110 g1_loss : 0.085610\n",
      "batch 110 g_loss : 1.224045\n",
      "batch 111 d_loss : 0.262081\n",
      "batch 111 g1_loss : 0.084443\n",
      "batch 111 g_loss : 1.245742\n",
      "batch 112 d_loss : 0.259428\n",
      "batch 112 g1_loss : 0.084777\n",
      "batch 112 g_loss : 1.258482\n",
      "batch 113 d_loss : 0.275553\n",
      "batch 113 g1_loss : 0.085590\n",
      "batch 113 g_loss : 1.263384\n",
      "batch 114 d_loss : 0.275985\n",
      "batch 114 g1_loss : 0.084568\n",
      "batch 114 g_loss : 1.283153\n",
      "batch 115 d_loss : 0.278549\n",
      "batch 115 g1_loss : 0.085264\n",
      "batch 115 g_loss : 1.283251\n",
      "batch 116 d_loss : 0.239969\n",
      "batch 116 g1_loss : 0.085122\n",
      "batch 116 g_loss : 1.302036\n",
      "batch 117 d_loss : 0.233340\n",
      "batch 117 g1_loss : 0.086033\n",
      "batch 117 g_loss : 1.310731\n",
      "batch 118 d_loss : 0.247013\n",
      "batch 118 g1_loss : 0.086149\n",
      "batch 118 g_loss : 1.313505\n",
      "batch 119 d_loss : 0.224434\n",
      "batch 119 g1_loss : 0.086756\n",
      "batch 119 g_loss : 1.320060\n",
      "batch 120 d_loss : 0.241379\n",
      "batch 120 g1_loss : 0.087231\n",
      "batch 120 g_loss : 1.339672\n",
      "batch 121 d_loss : 0.236789\n",
      "batch 121 g1_loss : 0.087800\n",
      "batch 121 g_loss : 1.340545\n",
      "batch 122 d_loss : 0.218043\n",
      "batch 122 g1_loss : 0.089041\n",
      "batch 122 g_loss : 1.348817\n",
      "batch 123 d_loss : 0.218113\n",
      "batch 123 g1_loss : 0.091793\n",
      "batch 123 g_loss : 1.345626\n",
      "batch 124 d_loss : 0.203840\n",
      "batch 124 g1_loss : 0.091598\n",
      "batch 124 g_loss : 1.363654\n",
      "batch 125 d_loss : 0.188870\n",
      "batch 125 g1_loss : 0.090626\n",
      "batch 125 g_loss : 1.368933\n",
      "batch 126 d_loss : 0.186533\n",
      "batch 126 g1_loss : 0.091517\n",
      "batch 126 g_loss : 1.378484\n",
      "batch 127 d_loss : 0.192624\n",
      "batch 127 g1_loss : 0.094460\n",
      "batch 127 g_loss : 1.397358\n",
      "batch 128 d_loss : 0.186799\n",
      "batch 128 g1_loss : 0.094326\n",
      "batch 128 g_loss : 1.400802\n",
      "batch 129 d_loss : 0.197668\n",
      "batch 129 g1_loss : 0.094391\n",
      "batch 129 g_loss : 1.424780\n",
      "batch 130 d_loss : 0.197233\n",
      "batch 130 g1_loss : 0.094042\n",
      "batch 130 g_loss : 1.422843\n",
      "batch 131 d_loss : 0.201956\n",
      "batch 131 g1_loss : 0.098487\n",
      "batch 131 g_loss : 1.442949\n",
      "batch 132 d_loss : 0.186421\n",
      "batch 132 g1_loss : 0.099678\n",
      "batch 132 g_loss : 1.437001\n",
      "batch 133 d_loss : 0.192822\n",
      "batch 133 g1_loss : 0.099597\n",
      "batch 133 g_loss : 1.424591\n",
      "batch 134 d_loss : 0.168349\n",
      "batch 134 g1_loss : 0.103372\n",
      "batch 134 g_loss : 1.436495\n",
      "batch 135 d_loss : 0.174442\n",
      "batch 135 g1_loss : 0.103639\n",
      "batch 135 g_loss : 1.451873\n",
      "batch 136 d_loss : 0.183768\n",
      "batch 136 g1_loss : 0.108289\n",
      "batch 136 g_loss : 1.454484\n",
      "batch 137 d_loss : 0.221463\n",
      "batch 137 g1_loss : 0.108605\n",
      "batch 137 g_loss : 1.435935\n",
      "batch 138 d_loss : 0.186340\n",
      "batch 138 g1_loss : 0.111624\n",
      "batch 138 g_loss : 1.434386\n",
      "batch 139 d_loss : 0.185956\n",
      "batch 139 g1_loss : 0.114813\n",
      "batch 139 g_loss : 1.446094\n",
      "batch 140 d_loss : 0.169813\n",
      "batch 140 g1_loss : 0.116043\n",
      "batch 140 g_loss : 1.428504\n",
      "batch 141 d_loss : 0.163301\n",
      "batch 141 g1_loss : 0.118632\n",
      "batch 141 g_loss : 1.420237\n",
      "batch 142 d_loss : 0.167316\n",
      "batch 142 g1_loss : 0.121202\n",
      "batch 142 g_loss : 1.421813\n",
      "batch 143 d_loss : 0.173413\n",
      "batch 143 g1_loss : 0.124473\n",
      "batch 143 g_loss : 1.413873\n",
      "batch 144 d_loss : 0.182736\n",
      "batch 144 g1_loss : 0.123659\n",
      "batch 144 g_loss : 1.429147\n",
      "batch 145 d_loss : 0.181824\n",
      "batch 145 g1_loss : 0.128411\n",
      "batch 145 g_loss : 1.405126\n",
      "batch 146 d_loss : 0.187841\n",
      "batch 146 g1_loss : 0.126670\n",
      "batch 146 g_loss : 1.402268\n",
      "batch 147 d_loss : 0.186389\n",
      "batch 147 g1_loss : 0.134195\n",
      "batch 147 g_loss : 1.390037\n",
      "batch 148 d_loss : 0.191328\n",
      "batch 148 g1_loss : 0.142353\n",
      "batch 148 g_loss : 1.352552\n",
      "batch 149 d_loss : 0.193963\n",
      "batch 149 g1_loss : 0.142760\n",
      "batch 149 g_loss : 1.382409\n",
      "batch 150 d_loss : 0.164829\n",
      "batch 150 g1_loss : 0.144572\n",
      "batch 150 g_loss : 1.348140\n",
      "batch 151 d_loss : 0.166130\n",
      "batch 151 g1_loss : 0.146927\n",
      "batch 151 g_loss : 1.343605\n",
      "batch 152 d_loss : 0.173394\n",
      "batch 152 g1_loss : 0.154056\n",
      "batch 152 g_loss : 1.322225\n",
      "batch 153 d_loss : 0.170799\n",
      "batch 153 g1_loss : 0.154417\n",
      "batch 153 g_loss : 1.333133\n",
      "batch 154 d_loss : 0.178772\n",
      "batch 154 g1_loss : 0.160150\n",
      "batch 154 g_loss : 1.322997\n",
      "batch 155 d_loss : 0.202626\n",
      "batch 155 g1_loss : 0.168982\n",
      "batch 155 g_loss : 1.326459\n",
      "batch 156 d_loss : 0.196363\n",
      "batch 156 g1_loss : 0.169647\n",
      "batch 156 g_loss : 1.322654\n",
      "batch 157 d_loss : 0.193266\n",
      "batch 157 g1_loss : 0.174888\n",
      "batch 157 g_loss : 1.291847\n",
      "batch 158 d_loss : 0.204160\n",
      "batch 158 g1_loss : 0.181560\n",
      "batch 158 g_loss : 1.299700\n",
      "batch 159 d_loss : 0.185742\n",
      "batch 159 g1_loss : 0.187188\n",
      "batch 159 g_loss : 1.258603\n",
      "batch 160 d_loss : 0.184982\n",
      "batch 160 g1_loss : 0.193150\n",
      "batch 160 g_loss : 1.259603\n",
      "batch 161 d_loss : 0.185211\n",
      "batch 161 g1_loss : 0.198732\n",
      "batch 161 g_loss : 1.236102\n",
      "batch 162 d_loss : 0.207594\n",
      "batch 162 g1_loss : 0.205246\n",
      "batch 162 g_loss : 1.233864\n",
      "batch 163 d_loss : 0.210906\n",
      "batch 163 g1_loss : 0.207664\n",
      "batch 163 g_loss : 1.230737\n",
      "batch 164 d_loss : 0.238310\n",
      "batch 164 g1_loss : 0.213306\n",
      "batch 164 g_loss : 1.218884\n",
      "batch 165 d_loss : 0.221269\n",
      "batch 165 g1_loss : 0.220344\n",
      "batch 165 g_loss : 1.193785\n",
      "batch 166 d_loss : 0.245543\n",
      "batch 166 g1_loss : 0.223836\n",
      "batch 166 g_loss : 1.175521\n",
      "batch 167 d_loss : 0.230407\n",
      "batch 167 g1_loss : 0.226476\n",
      "batch 167 g_loss : 1.153634\n",
      "batch 168 d_loss : 0.249253\n",
      "batch 168 g1_loss : 0.233138\n",
      "batch 168 g_loss : 1.170534\n",
      "batch 169 d_loss : 0.259955\n",
      "batch 169 g1_loss : 0.241600\n",
      "batch 169 g_loss : 1.148311\n",
      "batch 170 d_loss : 0.221871\n",
      "batch 170 g1_loss : 0.245450\n",
      "batch 170 g_loss : 1.143459\n",
      "batch 171 d_loss : 0.215224\n",
      "batch 171 g1_loss : 0.244442\n",
      "batch 171 g_loss : 1.147001\n",
      "batch 172 d_loss : 0.284173\n",
      "batch 172 g1_loss : 0.253423\n",
      "batch 172 g_loss : 1.118743\n",
      "batch 173 d_loss : 0.281565\n",
      "batch 173 g1_loss : 0.254665\n",
      "batch 173 g_loss : 1.121348\n",
      "batch 174 d_loss : 0.255272\n",
      "batch 174 g1_loss : 0.266857\n",
      "batch 174 g_loss : 1.131655\n",
      "batch 175 d_loss : 0.243144\n",
      "batch 175 g1_loss : 0.269889\n",
      "batch 175 g_loss : 1.121572\n",
      "batch 176 d_loss : 0.240496\n",
      "batch 176 g1_loss : 0.273657\n",
      "batch 176 g_loss : 1.100327\n",
      "batch 177 d_loss : 0.228840\n",
      "batch 177 g1_loss : 0.275395\n",
      "batch 177 g_loss : 1.114198\n",
      "batch 178 d_loss : 0.233349\n",
      "batch 178 g1_loss : 0.281161\n",
      "batch 178 g_loss : 1.131074\n",
      "batch 179 d_loss : 0.250122\n",
      "batch 179 g1_loss : 0.289885\n",
      "batch 179 g_loss : 1.148898\n",
      "batch 180 d_loss : 0.236794\n",
      "batch 180 g1_loss : 0.298664\n",
      "batch 180 g_loss : 1.159413\n",
      "batch 181 d_loss : 0.247710\n",
      "batch 181 g1_loss : 0.303681\n",
      "batch 181 g_loss : 1.154475\n",
      "batch 182 d_loss : 0.230348\n",
      "batch 182 g1_loss : 0.310201\n",
      "batch 182 g_loss : 1.184193\n",
      "batch 183 d_loss : 0.234162\n",
      "batch 183 g1_loss : 0.305456\n",
      "batch 183 g_loss : 1.236565\n",
      "batch 184 d_loss : 0.243766\n",
      "batch 184 g1_loss : 0.311785\n",
      "batch 184 g_loss : 1.245466\n",
      "batch 185 d_loss : 0.236905\n",
      "batch 185 g1_loss : 0.313405\n",
      "batch 185 g_loss : 1.271766\n",
      "batch 186 d_loss : 0.235646\n",
      "batch 186 g1_loss : 0.320699\n",
      "batch 186 g_loss : 1.293357\n",
      "batch 187 d_loss : 0.193973\n",
      "batch 187 g1_loss : 0.319199\n",
      "batch 187 g_loss : 1.299279\n",
      "batch 188 d_loss : 0.190078\n",
      "batch 188 g1_loss : 0.316750\n",
      "batch 188 g_loss : 1.381984\n",
      "batch 189 d_loss : 0.197168\n",
      "batch 189 g1_loss : 0.327356\n",
      "batch 189 g_loss : 1.399636\n",
      "batch 190 d_loss : 0.203382\n",
      "batch 190 g1_loss : 0.329573\n",
      "batch 190 g_loss : 1.446381\n",
      "batch 191 d_loss : 0.187600\n",
      "batch 191 g1_loss : 0.333415\n",
      "batch 191 g_loss : 1.488244\n",
      "batch 192 d_loss : 0.167950\n",
      "batch 192 g1_loss : 0.335229\n",
      "batch 192 g_loss : 1.517447\n",
      "batch 193 d_loss : 0.154456\n",
      "batch 193 g1_loss : 0.347942\n",
      "batch 193 g_loss : 1.572016\n",
      "batch 194 d_loss : 0.173740\n",
      "batch 194 g1_loss : 0.339902\n",
      "batch 194 g_loss : 1.604622\n",
      "batch 195 d_loss : 0.171497\n",
      "batch 195 g1_loss : 0.345421\n",
      "batch 195 g_loss : 1.652492\n",
      "batch 196 d_loss : 0.162196\n",
      "batch 196 g1_loss : 0.342213\n",
      "batch 196 g_loss : 1.701935\n",
      "batch 197 d_loss : 0.138476\n",
      "batch 197 g1_loss : 0.350012\n",
      "batch 197 g_loss : 1.735113\n",
      "batch 198 d_loss : 0.122898\n",
      "batch 198 g1_loss : 0.351814\n",
      "batch 198 g_loss : 1.785323\n",
      "batch 199 d_loss : 0.128899\n",
      "batch 199 g1_loss : 0.346808\n",
      "batch 199 g_loss : 1.844422\n",
      "batch 200 d_loss : 0.133648\n",
      "batch 200 g1_loss : 0.348374\n",
      "batch 200 g_loss : 1.865029\n",
      "batch 201 d_loss : 0.123485\n",
      "batch 201 g1_loss : 0.358553\n",
      "batch 201 g_loss : 1.876809\n",
      "batch 202 d_loss : 0.122171\n",
      "batch 202 g1_loss : 0.357128\n",
      "batch 202 g_loss : 1.963525\n",
      "batch 203 d_loss : 0.108058\n",
      "batch 203 g1_loss : 0.356185\n",
      "batch 203 g_loss : 1.988197\n",
      "batch 204 d_loss : 0.106797\n",
      "batch 204 g1_loss : 0.365302\n",
      "batch 204 g_loss : 2.013394\n",
      "batch 205 d_loss : 0.108047\n",
      "batch 205 g1_loss : 0.363135\n",
      "batch 205 g_loss : 2.040552\n",
      "batch 206 d_loss : 0.109827\n",
      "batch 206 g1_loss : 0.358036\n",
      "batch 206 g_loss : 2.067730\n",
      "batch 207 d_loss : 0.113850\n",
      "batch 207 g1_loss : 0.354098\n",
      "batch 207 g_loss : 2.085594\n",
      "batch 208 d_loss : 0.095363\n",
      "batch 208 g1_loss : 0.354865\n",
      "batch 208 g_loss : 2.085220\n",
      "batch 209 d_loss : 0.093395\n",
      "batch 209 g1_loss : 0.352716\n",
      "batch 209 g_loss : 2.103041\n",
      "batch 210 d_loss : 0.091440\n",
      "batch 210 g1_loss : 0.351054\n",
      "batch 210 g_loss : 2.090209\n",
      "batch 211 d_loss : 0.091378\n",
      "batch 211 g1_loss : 0.349881\n",
      "batch 211 g_loss : 2.105153\n",
      "batch 212 d_loss : 0.098467\n",
      "batch 212 g1_loss : 0.349410\n",
      "batch 212 g_loss : 2.121063\n",
      "batch 213 d_loss : 0.113072\n",
      "batch 213 g1_loss : 0.351770\n",
      "batch 213 g_loss : 2.062963\n",
      "batch 214 d_loss : 0.118856\n",
      "batch 214 g1_loss : 0.363610\n",
      "batch 214 g_loss : 2.051316\n",
      "batch 215 d_loss : 0.096084\n",
      "batch 215 g1_loss : 0.351453\n",
      "batch 215 g_loss : 2.037087\n",
      "batch 216 d_loss : 0.107701\n",
      "batch 216 g1_loss : 0.353252\n",
      "batch 216 g_loss : 2.030933\n",
      "batch 217 d_loss : 0.113160\n",
      "batch 217 g1_loss : 0.350365\n",
      "batch 217 g_loss : 2.011809\n",
      "batch 218 d_loss : 0.113996\n",
      "batch 218 g1_loss : 0.338299\n",
      "batch 218 g_loss : 2.008330\n",
      "batch 219 d_loss : 0.112150\n",
      "batch 219 g1_loss : 0.341671\n",
      "batch 219 g_loss : 1.997932\n",
      "batch 220 d_loss : 0.112691\n",
      "batch 220 g1_loss : 0.333632\n",
      "batch 220 g_loss : 1.926852\n",
      "batch 221 d_loss : 0.115756\n",
      "batch 221 g1_loss : 0.343021\n",
      "batch 221 g_loss : 1.907534\n",
      "batch 222 d_loss : 0.122564\n",
      "batch 222 g1_loss : 0.329907\n",
      "batch 222 g_loss : 1.855341\n",
      "batch 223 d_loss : 0.125369\n",
      "batch 223 g1_loss : 0.324174\n",
      "batch 223 g_loss : 1.843781\n",
      "batch 224 d_loss : 0.122768\n",
      "batch 224 g1_loss : 0.327759\n",
      "batch 224 g_loss : 1.822576\n",
      "batch 225 d_loss : 0.144503\n",
      "batch 225 g1_loss : 0.320506\n",
      "batch 225 g_loss : 1.862998\n",
      "batch 226 d_loss : 0.147062\n",
      "batch 226 g1_loss : 0.310462\n",
      "batch 226 g_loss : 1.825750\n",
      "batch 227 d_loss : 0.145252\n",
      "batch 227 g1_loss : 0.303136\n",
      "batch 227 g_loss : 1.831095\n",
      "batch 228 d_loss : 0.159678\n",
      "batch 228 g1_loss : 0.304334\n",
      "batch 228 g_loss : 1.825285\n",
      "batch 229 d_loss : 0.155581\n",
      "batch 229 g1_loss : 0.294412\n",
      "batch 229 g_loss : 1.833002\n",
      "batch 230 d_loss : 0.151412\n",
      "batch 230 g1_loss : 0.296775\n",
      "batch 230 g_loss : 1.855692\n",
      "batch 231 d_loss : 0.156768\n",
      "batch 231 g1_loss : 0.295724\n",
      "batch 231 g_loss : 1.893207\n",
      "batch 232 d_loss : 0.144397\n",
      "batch 232 g1_loss : 0.282307\n",
      "batch 232 g_loss : 1.881023\n",
      "batch 233 d_loss : 0.172170\n",
      "batch 233 g1_loss : 0.277536\n",
      "batch 233 g_loss : 1.851851\n",
      "batch 234 d_loss : 0.186495\n",
      "batch 234 g1_loss : 0.267382\n",
      "batch 234 g_loss : 1.931797\n",
      "batch 235 d_loss : 0.189415\n",
      "batch 235 g1_loss : 0.276299\n",
      "batch 235 g_loss : 1.961174\n",
      "batch 236 d_loss : 0.193124\n",
      "batch 236 g1_loss : 0.264503\n",
      "batch 236 g_loss : 1.951130\n",
      "batch 237 d_loss : 0.180005\n",
      "batch 237 g1_loss : 0.250985\n",
      "batch 237 g_loss : 1.954978\n",
      "batch 238 d_loss : 0.176621\n",
      "batch 238 g1_loss : 0.255328\n",
      "batch 238 g_loss : 1.989611\n",
      "batch 239 d_loss : 0.235825\n",
      "batch 239 g1_loss : 0.245771\n",
      "batch 239 g_loss : 1.973459\n",
      "batch 240 d_loss : 0.210454\n",
      "batch 240 g1_loss : 0.242375\n",
      "batch 240 g_loss : 1.900038\n",
      "batch 241 d_loss : 0.183539\n",
      "batch 241 g1_loss : 0.235289\n",
      "batch 241 g_loss : 1.902519\n",
      "batch 242 d_loss : 0.216218\n",
      "batch 242 g1_loss : 0.224715\n",
      "batch 242 g_loss : 1.893434\n",
      "batch 243 d_loss : 0.307871\n",
      "batch 243 g1_loss : 0.225265\n",
      "batch 243 g_loss : 1.781165\n",
      "batch 244 d_loss : 0.209863\n",
      "batch 244 g1_loss : 0.229124\n",
      "batch 244 g_loss : 1.815520\n",
      "batch 245 d_loss : 0.251653\n",
      "batch 245 g1_loss : 0.224231\n",
      "batch 245 g_loss : 1.789570\n",
      "batch 246 d_loss : 0.263521\n",
      "batch 246 g1_loss : 0.218007\n",
      "batch 246 g_loss : 1.648023\n",
      "batch 247 d_loss : 0.292079\n",
      "batch 247 g1_loss : 0.229436\n",
      "batch 247 g_loss : 1.678251\n",
      "batch 248 d_loss : 0.277232\n",
      "batch 248 g1_loss : 0.218495\n",
      "batch 248 g_loss : 1.585177\n",
      "batch 249 d_loss : 0.250601\n",
      "batch 249 g1_loss : 0.220785\n",
      "batch 249 g_loss : 1.593255\n",
      "batch 250 d_loss : 0.221500\n",
      "batch 250 g1_loss : 0.218501\n",
      "batch 250 g_loss : 1.669863\n",
      "batch 251 d_loss : 0.240177\n",
      "batch 251 g1_loss : 0.219072\n",
      "batch 251 g_loss : 1.656281\n",
      "batch 252 d_loss : 0.197849\n",
      "batch 252 g1_loss : 0.219000\n",
      "batch 252 g_loss : 1.793863\n",
      "batch 253 d_loss : 0.225965\n",
      "batch 253 g1_loss : 0.211663\n",
      "batch 253 g_loss : 1.890996\n",
      "batch 254 d_loss : 0.294451\n",
      "batch 254 g1_loss : 0.214141\n",
      "batch 254 g_loss : 1.944711\n",
      "batch 255 d_loss : 0.298169\n",
      "batch 255 g1_loss : 0.212996\n",
      "batch 255 g_loss : 1.877537\n",
      "batch 256 d_loss : 0.270537\n",
      "batch 256 g1_loss : 0.221326\n",
      "batch 256 g_loss : 1.825388\n",
      "batch 257 d_loss : 0.270892\n",
      "batch 257 g1_loss : 0.219846\n",
      "batch 257 g_loss : 1.914912\n",
      "batch 258 d_loss : 0.226139\n",
      "batch 258 g1_loss : 0.220575\n",
      "batch 258 g_loss : 1.849544\n",
      "batch 259 d_loss : 0.259950\n",
      "batch 259 g1_loss : 0.234544\n",
      "batch 259 g_loss : 1.801489\n",
      "batch 260 d_loss : 0.307975\n",
      "batch 260 g1_loss : 0.243395\n",
      "batch 260 g_loss : 1.736440\n",
      "batch 261 d_loss : 0.328863\n",
      "batch 261 g1_loss : 0.251186\n",
      "batch 261 g_loss : 1.642910\n",
      "batch 262 d_loss : 0.339845\n",
      "batch 262 g1_loss : 0.237836\n",
      "batch 262 g_loss : 1.719068\n",
      "batch 263 d_loss : 0.263160\n",
      "batch 263 g1_loss : 0.247465\n",
      "batch 263 g_loss : 1.524646\n",
      "batch 264 d_loss : 0.236082\n",
      "batch 264 g1_loss : 0.255320\n",
      "batch 264 g_loss : 1.618245\n",
      "batch 265 d_loss : 0.306524\n",
      "batch 265 g1_loss : 0.266248\n",
      "batch 265 g_loss : 1.640177\n",
      "batch 266 d_loss : 0.284216\n",
      "batch 266 g1_loss : 0.255119\n",
      "batch 266 g_loss : 1.733308\n",
      "batch 267 d_loss : 0.333906\n",
      "batch 267 g1_loss : 0.278306\n",
      "batch 267 g_loss : 1.635479\n",
      "batch 268 d_loss : 0.281714\n",
      "batch 268 g1_loss : 0.288384\n",
      "batch 268 g_loss : 1.632427\n",
      "batch 269 d_loss : 0.296563\n",
      "batch 269 g1_loss : 0.290278\n",
      "batch 269 g_loss : 1.730243\n",
      "batch 270 d_loss : 0.315316\n",
      "batch 270 g1_loss : 0.295690\n",
      "batch 270 g_loss : 1.759748\n",
      "batch 271 d_loss : 0.335991\n",
      "batch 271 g1_loss : 0.308335\n",
      "batch 271 g_loss : 1.706294\n",
      "batch 272 d_loss : 0.345388\n",
      "batch 272 g1_loss : 0.331048\n",
      "batch 272 g_loss : 1.707725\n",
      "batch 273 d_loss : 0.262658\n",
      "batch 273 g1_loss : 0.330810\n",
      "batch 273 g_loss : 1.667146\n",
      "batch 274 d_loss : 0.348390\n",
      "batch 274 g1_loss : 0.339155\n",
      "batch 274 g_loss : 1.663998\n",
      "batch 275 d_loss : 0.380902\n",
      "batch 275 g1_loss : 0.338499\n",
      "batch 275 g_loss : 1.555585\n",
      "batch 276 d_loss : 0.361265\n",
      "batch 276 g1_loss : 0.353861\n",
      "batch 276 g_loss : 1.573320\n",
      "batch 277 d_loss : 0.372060\n",
      "batch 277 g1_loss : 0.370007\n",
      "batch 277 g_loss : 1.599209\n",
      "batch 278 d_loss : 0.429846\n",
      "batch 278 g1_loss : 0.391608\n",
      "batch 278 g_loss : 1.457596\n",
      "batch 279 d_loss : 0.394744\n",
      "batch 279 g1_loss : 0.386213\n",
      "batch 279 g_loss : 1.517598\n",
      "batch 280 d_loss : 0.578466\n",
      "batch 280 g1_loss : 0.372448\n",
      "batch 280 g_loss : 1.351759\n",
      "batch 281 d_loss : 0.575488\n",
      "batch 281 g1_loss : 0.383769\n",
      "batch 281 g_loss : 1.252576\n",
      "batch 282 d_loss : 0.421925\n",
      "batch 282 g1_loss : 0.411400\n",
      "batch 282 g_loss : 1.128676\n",
      "batch 283 d_loss : 0.433830\n",
      "batch 283 g1_loss : 0.420910\n",
      "batch 283 g_loss : 1.204269\n",
      "batch 284 d_loss : 0.497111\n",
      "batch 284 g1_loss : 0.428489\n",
      "batch 284 g_loss : 1.356707\n",
      "batch 285 d_loss : 0.453832\n",
      "batch 285 g1_loss : 0.440786\n",
      "batch 285 g_loss : 1.292240\n",
      "batch 286 d_loss : 0.365578\n",
      "batch 286 g1_loss : 0.436862\n",
      "batch 286 g_loss : 1.392805\n",
      "batch 287 d_loss : 0.406981\n",
      "batch 287 g1_loss : 0.455048\n",
      "batch 287 g_loss : 1.348810\n",
      "batch 288 d_loss : 0.455427\n",
      "batch 288 g1_loss : 0.469578\n",
      "batch 288 g_loss : 1.520372\n",
      "batch 289 d_loss : 0.461357\n",
      "batch 289 g1_loss : 0.464993\n",
      "batch 289 g_loss : 1.603586\n",
      "batch 290 d_loss : 0.386191\n",
      "batch 290 g1_loss : 0.492718\n",
      "batch 290 g_loss : 1.572712\n",
      "batch 291 d_loss : 0.453195\n",
      "batch 291 g1_loss : 0.486052\n",
      "batch 291 g_loss : 1.597762\n",
      "batch 292 d_loss : 0.532996\n",
      "batch 292 g1_loss : 0.476678\n",
      "batch 292 g_loss : 1.452248\n",
      "batch 293 d_loss : 0.787455\n",
      "batch 293 g1_loss : 0.494049\n",
      "batch 293 g_loss : 1.321786\n",
      "batch 294 d_loss : 0.668753\n",
      "batch 294 g1_loss : 0.516685\n",
      "batch 294 g_loss : 1.135457\n",
      "batch 295 d_loss : 0.494553\n",
      "batch 295 g1_loss : 0.514936\n",
      "batch 295 g_loss : 1.038234\n",
      "batch 296 d_loss : 0.568349\n",
      "batch 296 g1_loss : 0.526546\n",
      "batch 296 g_loss : 0.979408\n",
      "batch 297 d_loss : 0.628782\n",
      "batch 297 g1_loss : 0.513547\n",
      "batch 297 g_loss : 0.998181\n",
      "batch 298 d_loss : 0.586417\n",
      "batch 298 g1_loss : 0.516771\n",
      "batch 298 g_loss : 1.012796\n",
      "batch 299 d_loss : 0.611369\n",
      "batch 299 g1_loss : 0.539400\n",
      "batch 299 g_loss : 0.993136\n",
      "batch 300 d_loss : 0.633218\n",
      "batch 300 g1_loss : 0.541024\n",
      "batch 300 g_loss : 0.989630\n",
      "batch 301 d_loss : 0.544695\n",
      "batch 301 g1_loss : 0.537119\n",
      "batch 301 g_loss : 1.073938\n",
      "batch 302 d_loss : 0.609341\n",
      "batch 302 g1_loss : 0.528627\n",
      "batch 302 g_loss : 1.073536\n",
      "batch 303 d_loss : 0.524124\n",
      "batch 303 g1_loss : 0.545053\n",
      "batch 303 g_loss : 1.002640\n",
      "batch 304 d_loss : 0.624392\n",
      "batch 304 g1_loss : 0.522598\n",
      "batch 304 g_loss : 1.044062\n",
      "batch 305 d_loss : 0.518550\n",
      "batch 305 g1_loss : 0.543569\n",
      "batch 305 g_loss : 1.098033\n",
      "batch 306 d_loss : 0.490740\n",
      "batch 306 g1_loss : 0.548888\n",
      "batch 306 g_loss : 1.240910\n",
      "batch 307 d_loss : 0.564363\n",
      "batch 307 g1_loss : 0.545640\n",
      "batch 307 g_loss : 1.144047\n",
      "batch 308 d_loss : 0.499644\n",
      "batch 308 g1_loss : 0.566458\n",
      "batch 308 g_loss : 1.151721\n",
      "batch 309 d_loss : 0.484821\n",
      "batch 309 g1_loss : 0.547278\n",
      "batch 309 g_loss : 1.139851\n",
      "batch 310 d_loss : 0.761053\n",
      "batch 310 g1_loss : 0.553937\n",
      "batch 310 g_loss : 1.101658\n",
      "batch 311 d_loss : 0.699864\n",
      "batch 311 g1_loss : 0.542627\n",
      "batch 311 g_loss : 0.981016\n",
      "batch 312 d_loss : 0.534161\n",
      "batch 312 g1_loss : 0.552457\n",
      "batch 312 g_loss : 0.928725\n",
      "batch 313 d_loss : 0.543399\n",
      "batch 313 g1_loss : 0.543952\n",
      "batch 313 g_loss : 0.988157\n",
      "batch 314 d_loss : 0.580998\n",
      "batch 314 g1_loss : 0.517607\n",
      "batch 314 g_loss : 0.946609\n",
      "batch 315 d_loss : 0.553200\n",
      "batch 315 g1_loss : 0.512789\n",
      "batch 315 g_loss : 0.895145\n",
      "batch 316 d_loss : 0.578180\n",
      "batch 316 g1_loss : 0.554045\n",
      "batch 316 g_loss : 0.933530\n",
      "batch 317 d_loss : 0.602904\n",
      "batch 317 g1_loss : 0.533127\n",
      "batch 317 g_loss : 1.022257\n",
      "batch 318 d_loss : 0.604608\n",
      "batch 318 g1_loss : 0.549417\n",
      "batch 318 g_loss : 0.982752\n",
      "batch 319 d_loss : 0.584330\n",
      "batch 319 g1_loss : 0.512190\n",
      "batch 319 g_loss : 0.997689\n",
      "batch 320 d_loss : 0.587997\n",
      "batch 320 g1_loss : 0.533233\n",
      "batch 320 g_loss : 1.005924\n",
      "batch 321 d_loss : 0.573218\n",
      "batch 321 g1_loss : 0.509555\n",
      "batch 321 g_loss : 0.942313\n",
      "batch 322 d_loss : 0.592016\n",
      "batch 322 g1_loss : 0.531126\n",
      "batch 322 g_loss : 1.020468\n",
      "batch 323 d_loss : 0.648354\n",
      "batch 323 g1_loss : 0.550695\n",
      "batch 323 g_loss : 0.916671\n",
      "batch 324 d_loss : 0.571608\n",
      "batch 324 g1_loss : 0.542042\n",
      "batch 324 g_loss : 0.910141\n",
      "batch 325 d_loss : 0.637865\n",
      "batch 325 g1_loss : 0.538533\n",
      "batch 325 g_loss : 0.856171\n",
      "batch 326 d_loss : 0.656904\n",
      "batch 326 g1_loss : 0.528371\n",
      "batch 326 g_loss : 0.864853\n",
      "batch 327 d_loss : 0.552631\n",
      "batch 327 g1_loss : 0.522513\n",
      "batch 327 g_loss : 0.886468\n",
      "batch 328 d_loss : 0.505917\n",
      "batch 328 g1_loss : 0.536801\n",
      "batch 328 g_loss : 0.962508\n",
      "batch 329 d_loss : 0.501727\n",
      "batch 329 g1_loss : 0.521569\n",
      "batch 329 g_loss : 0.986817\n",
      "batch 330 d_loss : 0.611739\n",
      "batch 330 g1_loss : 0.504764\n",
      "batch 330 g_loss : 1.040851\n",
      "batch 331 d_loss : 0.617361\n",
      "batch 331 g1_loss : 0.510273\n",
      "batch 331 g_loss : 0.990064\n",
      "batch 332 d_loss : 0.579291\n",
      "batch 332 g1_loss : 0.508702\n",
      "batch 332 g_loss : 1.015785\n",
      "batch 333 d_loss : 0.485179\n",
      "batch 333 g1_loss : 0.503318\n",
      "batch 333 g_loss : 1.015079\n",
      "batch 334 d_loss : 0.503323\n",
      "batch 334 g1_loss : 0.520085\n",
      "batch 334 g_loss : 1.021239\n",
      "batch 335 d_loss : 0.564866\n",
      "batch 335 g1_loss : 0.507452\n",
      "batch 335 g_loss : 0.993829\n",
      "batch 336 d_loss : 0.526741\n",
      "batch 336 g1_loss : 0.482507\n",
      "batch 336 g_loss : 1.000835\n",
      "batch 337 d_loss : 0.498570\n",
      "batch 337 g1_loss : 0.516861\n",
      "batch 337 g_loss : 1.014068\n",
      "batch 338 d_loss : 0.537125\n",
      "batch 338 g1_loss : 0.499398\n",
      "batch 338 g_loss : 1.048423\n",
      "batch 339 d_loss : 0.542477\n",
      "batch 339 g1_loss : 0.492828\n",
      "batch 339 g_loss : 1.000314\n",
      "batch 340 d_loss : 0.578284\n",
      "batch 340 g1_loss : 0.484960\n",
      "batch 340 g_loss : 1.017286\n",
      "batch 341 d_loss : 0.474487\n",
      "batch 341 g1_loss : 0.493799\n",
      "batch 341 g_loss : 1.019426\n",
      "batch 342 d_loss : 0.546766\n",
      "batch 342 g1_loss : 0.488777\n",
      "batch 342 g_loss : 0.956416\n",
      "batch 343 d_loss : 0.552645\n",
      "batch 343 g1_loss : 0.499780\n",
      "batch 343 g_loss : 0.979174\n",
      "batch 344 d_loss : 0.579592\n",
      "batch 344 g1_loss : 0.492394\n",
      "batch 344 g_loss : 0.912973\n",
      "batch 345 d_loss : 0.572211\n",
      "batch 345 g1_loss : 0.514079\n",
      "batch 345 g_loss : 0.914748\n",
      "batch 346 d_loss : 0.559716\n",
      "batch 346 g1_loss : 0.482952\n",
      "batch 346 g_loss : 0.898410\n",
      "batch 347 d_loss : 0.569495\n",
      "batch 347 g1_loss : 0.499630\n",
      "batch 347 g_loss : 0.893207\n",
      "batch 348 d_loss : 0.557225\n",
      "batch 348 g1_loss : 0.478618\n",
      "batch 348 g_loss : 0.915796\n",
      "batch 349 d_loss : 0.591206\n",
      "batch 349 g1_loss : 0.479648\n",
      "batch 349 g_loss : 0.918746\n",
      "batch 350 d_loss : 0.548757\n",
      "batch 350 g1_loss : 0.486996\n",
      "batch 350 g_loss : 0.963554\n",
      "batch 351 d_loss : 0.526893\n",
      "batch 351 g1_loss : 0.472907\n",
      "batch 351 g_loss : 0.984768\n",
      "batch 352 d_loss : 0.544266\n",
      "batch 352 g1_loss : 0.469197\n",
      "batch 352 g_loss : 0.980655\n",
      "batch 353 d_loss : 0.593082\n",
      "batch 353 g1_loss : 0.453758\n",
      "batch 353 g_loss : 0.978641\n",
      "batch 354 d_loss : 0.552466\n",
      "batch 354 g1_loss : 0.489256\n",
      "batch 354 g_loss : 0.968260\n",
      "batch 355 d_loss : 0.601704\n",
      "batch 355 g1_loss : 0.458890\n",
      "batch 355 g_loss : 0.943518\n",
      "batch 356 d_loss : 0.524808\n",
      "batch 356 g1_loss : 0.478691\n",
      "batch 356 g_loss : 0.932754\n",
      "batch 357 d_loss : 0.547656\n",
      "batch 357 g1_loss : 0.465412\n",
      "batch 357 g_loss : 0.923452\n",
      "batch 358 d_loss : 0.548727\n",
      "batch 358 g1_loss : 0.476925\n",
      "batch 358 g_loss : 0.921660\n",
      "batch 359 d_loss : 0.629622\n",
      "batch 359 g1_loss : 0.450815\n",
      "batch 359 g_loss : 0.906442\n",
      "batch 360 d_loss : 0.568100\n",
      "batch 360 g1_loss : 0.462245\n",
      "batch 360 g_loss : 0.870254\n",
      "batch 361 d_loss : 0.545525\n",
      "batch 361 g1_loss : 0.462090\n",
      "batch 361 g_loss : 0.898745\n",
      "batch 362 d_loss : 0.539183\n",
      "batch 362 g1_loss : 0.460889\n",
      "batch 362 g_loss : 0.946147\n",
      "batch 363 d_loss : 0.514017\n",
      "batch 363 g1_loss : 0.450993\n",
      "batch 363 g_loss : 0.939676\n",
      "batch 364 d_loss : 0.490685\n",
      "batch 364 g1_loss : 0.447247\n",
      "batch 364 g_loss : 1.027548\n",
      "batch 365 d_loss : 0.467989\n",
      "batch 365 g1_loss : 0.448687\n",
      "batch 365 g_loss : 1.057158\n",
      "batch 366 d_loss : 0.490184\n",
      "batch 366 g1_loss : 0.443860\n",
      "batch 366 g_loss : 1.121736\n",
      "batch 367 d_loss : 0.536687\n",
      "batch 367 g1_loss : 0.452567\n",
      "batch 367 g_loss : 1.100033\n",
      "batch 368 d_loss : 0.535311\n",
      "batch 368 g1_loss : 0.449964\n",
      "batch 368 g_loss : 1.039343\n",
      "batch 369 d_loss : 0.553630\n",
      "batch 369 g1_loss : 0.449274\n",
      "batch 369 g_loss : 1.042077\n",
      "batch 370 d_loss : 0.504683\n",
      "batch 370 g1_loss : 0.495343\n",
      "batch 370 g_loss : 1.029902\n",
      "batch 371 d_loss : 0.516738\n",
      "batch 371 g1_loss : 0.484558\n",
      "batch 371 g_loss : 0.982510\n",
      "batch 372 d_loss : 0.497613\n",
      "batch 372 g1_loss : 0.448943\n",
      "batch 372 g_loss : 1.048131\n",
      "batch 373 d_loss : 0.496415\n",
      "batch 373 g1_loss : 0.472376\n",
      "batch 373 g_loss : 1.048090\n",
      "batch 374 d_loss : 0.492297\n",
      "batch 374 g1_loss : 0.456305\n",
      "batch 374 g_loss : 1.076284\n",
      "batch 375 d_loss : 0.462633\n",
      "batch 375 g1_loss : 0.462314\n",
      "batch 375 g_loss : 1.073362\n",
      "batch 376 d_loss : 0.449856\n",
      "batch 376 g1_loss : 0.455612\n",
      "batch 376 g_loss : 1.156832\n",
      "batch 377 d_loss : 0.474952\n",
      "batch 377 g1_loss : 0.437791\n",
      "batch 377 g_loss : 1.174675\n",
      "batch 378 d_loss : 0.478119\n",
      "batch 378 g1_loss : 0.439480\n",
      "batch 378 g_loss : 1.199886\n",
      "batch 379 d_loss : 0.483386\n",
      "batch 379 g1_loss : 0.483953\n",
      "batch 379 g_loss : 1.081396\n",
      "batch 380 d_loss : 0.450437\n",
      "batch 380 g1_loss : 0.456428\n",
      "batch 380 g_loss : 1.104739\n",
      "batch 381 d_loss : 0.451702\n",
      "batch 381 g1_loss : 0.448774\n",
      "batch 381 g_loss : 1.119427\n",
      "batch 382 d_loss : 0.552614\n",
      "batch 382 g1_loss : 0.469377\n",
      "batch 382 g_loss : 1.016630\n",
      "batch 383 d_loss : 0.558659\n",
      "batch 383 g1_loss : 0.470711\n",
      "batch 383 g_loss : 0.962807\n",
      "batch 384 d_loss : 0.516827\n",
      "batch 384 g1_loss : 0.452149\n",
      "batch 384 g_loss : 0.974445\n",
      "batch 385 d_loss : 0.506122\n",
      "batch 385 g1_loss : 0.459604\n",
      "batch 385 g_loss : 0.933153\n",
      "batch 386 d_loss : 0.525777\n",
      "batch 386 g1_loss : 0.467070\n",
      "batch 386 g_loss : 0.965688\n",
      "batch 387 d_loss : 0.515916\n",
      "batch 387 g1_loss : 0.495268\n",
      "batch 387 g_loss : 0.964969\n",
      "batch 388 d_loss : 0.488639\n",
      "batch 388 g1_loss : 0.452344\n",
      "batch 388 g_loss : 0.981570\n",
      "batch 389 d_loss : 0.545599\n",
      "batch 389 g1_loss : 0.478518\n",
      "batch 389 g_loss : 0.942247\n",
      "batch 390 d_loss : 0.524406\n",
      "batch 390 g1_loss : 0.478376\n",
      "batch 390 g_loss : 1.023342\n",
      "batch 391 d_loss : 0.496183\n",
      "batch 391 g1_loss : 0.468009\n",
      "batch 391 g_loss : 1.017251\n",
      "batch 392 d_loss : 0.481034\n",
      "batch 392 g1_loss : 0.460116\n",
      "batch 392 g_loss : 1.096099\n",
      "batch 393 d_loss : 0.530878\n",
      "batch 393 g1_loss : 0.463080\n",
      "batch 393 g_loss : 1.098733\n",
      "batch 394 d_loss : 0.534165\n",
      "batch 394 g1_loss : 0.459365\n",
      "batch 394 g_loss : 1.094748\n",
      "batch 395 d_loss : 0.523250\n",
      "batch 395 g1_loss : 0.476233\n",
      "batch 395 g_loss : 1.022507\n",
      "batch 396 d_loss : 0.439953\n",
      "batch 396 g1_loss : 0.467887\n",
      "batch 396 g_loss : 1.035065\n",
      "batch 397 d_loss : 0.469902\n",
      "batch 397 g1_loss : 0.494869\n",
      "batch 397 g_loss : 1.090444\n",
      "batch 398 d_loss : 0.437063\n",
      "batch 398 g1_loss : 0.455311\n",
      "batch 398 g_loss : 1.137307\n",
      "batch 399 d_loss : 0.463144\n",
      "batch 399 g1_loss : 0.472860\n",
      "batch 399 g_loss : 1.152614\n",
      "batch 400 d_loss : 0.466490\n",
      "batch 400 g1_loss : 0.485221\n",
      "batch 400 g_loss : 1.138764\n",
      "batch 401 d_loss : 0.500715\n",
      "batch 401 g1_loss : 0.482692\n",
      "batch 401 g_loss : 1.175527\n",
      "batch 402 d_loss : 0.517255\n",
      "batch 402 g1_loss : 0.480497\n",
      "batch 402 g_loss : 1.083067\n",
      "batch 403 d_loss : 0.498531\n",
      "batch 403 g1_loss : 0.476373\n",
      "batch 403 g_loss : 1.104870\n",
      "batch 404 d_loss : 0.531463\n",
      "batch 404 g1_loss : 0.479677\n",
      "batch 404 g_loss : 1.087875\n",
      "batch 405 d_loss : 0.474384\n",
      "batch 405 g1_loss : 0.494452\n",
      "batch 405 g_loss : 1.120768\n",
      "batch 406 d_loss : 0.590666\n",
      "batch 406 g1_loss : 0.487767\n",
      "batch 406 g_loss : 0.962335\n",
      "batch 407 d_loss : 0.593151\n",
      "batch 407 g1_loss : 0.499172\n",
      "batch 407 g_loss : 0.938843\n",
      "batch 408 d_loss : 0.531493\n",
      "batch 408 g1_loss : 0.501401\n",
      "batch 408 g_loss : 0.979202\n",
      "batch 409 d_loss : 0.479353\n",
      "batch 409 g1_loss : 0.477994\n",
      "batch 409 g_loss : 1.008205\n",
      "batch 410 d_loss : 0.453677\n",
      "batch 410 g1_loss : 0.469976\n",
      "batch 410 g_loss : 1.017822\n",
      "batch 411 d_loss : 0.528290\n",
      "batch 411 g1_loss : 0.517286\n",
      "batch 411 g_loss : 0.979223\n",
      "batch 412 d_loss : 0.499787\n",
      "batch 412 g1_loss : 0.506210\n",
      "batch 412 g_loss : 1.059959\n",
      "batch 413 d_loss : 0.480347\n",
      "batch 413 g1_loss : 0.495997\n",
      "batch 413 g_loss : 1.075962\n",
      "batch 414 d_loss : 0.447287\n",
      "batch 414 g1_loss : 0.507100\n",
      "batch 414 g_loss : 1.116792\n",
      "batch 415 d_loss : 0.474721\n",
      "batch 415 g1_loss : 0.509168\n",
      "batch 415 g_loss : 1.092044\n",
      "batch 416 d_loss : 0.523082\n",
      "batch 416 g1_loss : 0.495402\n",
      "batch 416 g_loss : 1.083949\n",
      "batch 417 d_loss : 0.495401\n",
      "batch 417 g1_loss : 0.510164\n",
      "batch 417 g_loss : 1.089199\n",
      "batch 418 d_loss : 0.528878\n",
      "batch 418 g1_loss : 0.495854\n",
      "batch 418 g_loss : 1.035570\n",
      "batch 419 d_loss : 0.493310\n",
      "batch 419 g1_loss : 0.486247\n",
      "batch 419 g_loss : 1.049919\n",
      "batch 420 d_loss : 0.522789\n",
      "batch 420 g1_loss : 0.495184\n",
      "batch 420 g_loss : 0.984907\n",
      "batch 421 d_loss : 0.499767\n",
      "batch 421 g1_loss : 0.503928\n",
      "batch 421 g_loss : 1.002255\n",
      "batch 422 d_loss : 0.485194\n",
      "batch 422 g1_loss : 0.486408\n",
      "batch 422 g_loss : 0.979972\n",
      "batch 423 d_loss : 0.497636\n",
      "batch 423 g1_loss : 0.520505\n",
      "batch 423 g_loss : 1.002847\n",
      "batch 424 d_loss : 0.501929\n",
      "batch 424 g1_loss : 0.492696\n",
      "batch 424 g_loss : 1.029744\n",
      "batch 425 d_loss : 0.470377\n",
      "batch 425 g1_loss : 0.529940\n",
      "batch 425 g_loss : 1.179940\n",
      "batch 426 d_loss : 0.442572\n",
      "batch 426 g1_loss : 0.494413\n",
      "batch 426 g_loss : 1.155001\n",
      "batch 427 d_loss : 0.459531\n",
      "batch 427 g1_loss : 0.513369\n",
      "batch 427 g_loss : 1.187989\n",
      "batch 428 d_loss : 0.515280\n",
      "batch 428 g1_loss : 0.512789\n",
      "batch 428 g_loss : 1.101328\n",
      "batch 429 d_loss : 0.543345\n",
      "batch 429 g1_loss : 0.518544\n",
      "batch 429 g_loss : 1.087941\n",
      "batch 430 d_loss : 0.467965\n",
      "batch 430 g1_loss : 0.505297\n",
      "batch 430 g_loss : 1.016861\n",
      "batch 431 d_loss : 0.481842\n",
      "batch 431 g1_loss : 0.489978\n",
      "batch 431 g_loss : 1.119551\n",
      "batch 432 d_loss : 0.498500\n",
      "batch 432 g1_loss : 0.494527\n",
      "batch 432 g_loss : 1.023884\n",
      "batch 433 d_loss : 0.461705\n",
      "batch 433 g1_loss : 0.502544\n",
      "batch 433 g_loss : 1.033417\n",
      "batch 434 d_loss : 0.460029\n",
      "batch 434 g1_loss : 0.515530\n",
      "batch 434 g_loss : 1.043638\n",
      "batch 435 d_loss : 0.439163\n",
      "batch 435 g1_loss : 0.510810\n",
      "batch 435 g_loss : 1.120586\n",
      "batch 436 d_loss : 0.438956\n",
      "batch 436 g1_loss : 0.514487\n",
      "batch 436 g_loss : 1.160565\n",
      "batch 437 d_loss : 0.481186\n",
      "batch 437 g1_loss : 0.515167\n",
      "batch 437 g_loss : 1.160827\n",
      "batch 438 d_loss : 0.513435\n",
      "batch 438 g1_loss : 0.510870\n",
      "batch 438 g_loss : 1.125593\n",
      "batch 439 d_loss : 0.508188\n",
      "batch 439 g1_loss : 0.521616\n",
      "batch 439 g_loss : 1.045033\n",
      "batch 440 d_loss : 0.495354\n",
      "batch 440 g1_loss : 0.524730\n",
      "batch 440 g_loss : 1.049210\n",
      "batch 441 d_loss : 0.550525\n",
      "batch 441 g1_loss : 0.518814\n",
      "batch 441 g_loss : 0.960737\n",
      "batch 442 d_loss : 0.536942\n",
      "batch 442 g1_loss : 0.515840\n",
      "batch 442 g_loss : 0.891875\n",
      "batch 443 d_loss : 0.487851\n",
      "batch 443 g1_loss : 0.528351\n",
      "batch 443 g_loss : 0.980574\n",
      "batch 444 d_loss : 0.487660\n",
      "batch 444 g1_loss : 0.535975\n",
      "batch 444 g_loss : 1.058723\n",
      "batch 445 d_loss : 0.525151\n",
      "batch 445 g1_loss : 0.499842\n",
      "batch 445 g_loss : 1.018954\n",
      "batch 446 d_loss : 0.489667\n",
      "batch 446 g1_loss : 0.516074\n",
      "batch 446 g_loss : 0.990163\n",
      "batch 447 d_loss : 0.483163\n",
      "batch 447 g1_loss : 0.528159\n",
      "batch 447 g_loss : 1.040185\n",
      "batch 448 d_loss : 0.497890\n",
      "batch 448 g1_loss : 0.518243\n",
      "batch 448 g_loss : 1.016011\n",
      "batch 449 d_loss : 0.476488\n",
      "batch 449 g1_loss : 0.506326\n",
      "batch 449 g_loss : 1.104204\n",
      "batch 450 d_loss : 0.492579\n",
      "batch 450 g1_loss : 0.509661\n",
      "batch 450 g_loss : 1.067142\n",
      "batch 451 d_loss : 0.503683\n",
      "batch 451 g1_loss : 0.503310\n",
      "batch 451 g_loss : 1.031340\n",
      "batch 452 d_loss : 0.534030\n",
      "batch 452 g1_loss : 0.508520\n",
      "batch 452 g_loss : 1.005502\n",
      "batch 453 d_loss : 0.492471\n",
      "batch 453 g1_loss : 0.520263\n",
      "batch 453 g_loss : 0.983838\n",
      "batch 454 d_loss : 0.515356\n",
      "batch 454 g1_loss : 0.508191\n",
      "batch 454 g_loss : 0.981079\n",
      "batch 455 d_loss : 0.495410\n",
      "batch 455 g1_loss : 0.501511\n",
      "batch 455 g_loss : 1.042864\n",
      "batch 456 d_loss : 0.462583\n",
      "batch 456 g1_loss : 0.503895\n",
      "batch 456 g_loss : 1.054686\n",
      "batch 457 d_loss : 0.513403\n",
      "batch 457 g1_loss : 0.523667\n",
      "batch 457 g_loss : 1.053500\n",
      "batch 458 d_loss : 0.461657\n",
      "batch 458 g1_loss : 0.518746\n",
      "batch 458 g_loss : 1.040524\n",
      "batch 459 d_loss : 0.480138\n",
      "batch 459 g1_loss : 0.555667\n",
      "batch 459 g_loss : 1.044009\n",
      "batch 460 d_loss : 0.459508\n",
      "batch 460 g1_loss : 0.495901\n",
      "batch 460 g_loss : 1.098217\n",
      "batch 461 d_loss : 0.438268\n",
      "batch 461 g1_loss : 0.490648\n",
      "batch 461 g_loss : 1.118306\n",
      "batch 462 d_loss : 0.451535\n",
      "batch 462 g1_loss : 0.515103\n",
      "batch 462 g_loss : 1.138199\n",
      "batch 463 d_loss : 0.447055\n",
      "batch 463 g1_loss : 0.527991\n",
      "batch 463 g_loss : 1.177257\n",
      "batch 464 d_loss : 0.440471\n",
      "batch 464 g1_loss : 0.530341\n",
      "batch 464 g_loss : 1.254922\n",
      "batch 465 d_loss : 0.463093\n",
      "batch 465 g1_loss : 0.515231\n",
      "batch 465 g_loss : 1.231067\n",
      "batch 466 d_loss : 0.497981\n",
      "batch 466 g1_loss : 0.499512\n",
      "batch 466 g_loss : 1.123033\n",
      "batch 467 d_loss : 0.443666\n",
      "batch 467 g1_loss : 0.483226\n",
      "batch 467 g_loss : 1.111797\n",
      "('Epoch is', 1)\n",
      "('Number of batches', 468)\n",
      "batch 0 d_loss : 0.498503\n",
      "batch 0 g1_loss : 0.512101\n",
      "batch 0 g_loss : 1.055903\n",
      "batch 1 d_loss : 0.497284\n",
      "batch 1 g1_loss : 0.510776\n",
      "batch 1 g_loss : 1.046242\n",
      "batch 2 d_loss : 0.464565\n",
      "batch 2 g1_loss : 0.508542\n",
      "batch 2 g_loss : 1.024452\n",
      "batch 3 d_loss : 0.508943\n",
      "batch 3 g1_loss : 0.519742\n",
      "batch 3 g_loss : 0.940427\n",
      "batch 4 d_loss : 0.514610\n",
      "batch 4 g1_loss : 0.496561\n",
      "batch 4 g_loss : 1.020469\n",
      "batch 5 d_loss : 0.485927\n",
      "batch 5 g1_loss : 0.556200\n",
      "batch 5 g_loss : 0.968160\n",
      "batch 6 d_loss : 0.490203\n",
      "batch 6 g1_loss : 0.514507\n",
      "batch 6 g_loss : 1.043015\n",
      "batch 7 d_loss : 0.502423\n",
      "batch 7 g1_loss : 0.507357\n",
      "batch 7 g_loss : 1.036863\n",
      "batch 8 d_loss : 0.509499\n",
      "batch 8 g1_loss : 0.516105\n",
      "batch 8 g_loss : 1.051142\n",
      "batch 9 d_loss : 0.489482\n",
      "batch 9 g1_loss : 0.512223\n",
      "batch 9 g_loss : 1.065540\n",
      "batch 10 d_loss : 0.441297\n",
      "batch 10 g1_loss : 0.473735\n",
      "batch 10 g_loss : 1.160874\n",
      "batch 11 d_loss : 0.541735\n",
      "batch 11 g1_loss : 0.498076\n",
      "batch 11 g_loss : 1.108704\n",
      "batch 12 d_loss : 0.487720\n",
      "batch 12 g1_loss : 0.490829\n",
      "batch 12 g_loss : 1.045400\n",
      "batch 13 d_loss : 0.460782\n",
      "batch 13 g1_loss : 0.512402\n",
      "batch 13 g_loss : 1.093545\n",
      "batch 14 d_loss : 0.512430\n",
      "batch 14 g1_loss : 0.506731\n",
      "batch 14 g_loss : 1.067612\n",
      "batch 15 d_loss : 0.470651\n",
      "batch 15 g1_loss : 0.503319\n",
      "batch 15 g_loss : 1.108901\n",
      "batch 16 d_loss : 0.475863\n",
      "batch 16 g1_loss : 0.516066\n",
      "batch 16 g_loss : 1.134098\n",
      "batch 17 d_loss : 0.453044\n",
      "batch 17 g1_loss : 0.513186\n",
      "batch 17 g_loss : 1.105502\n",
      "batch 18 d_loss : 0.503052\n",
      "batch 18 g1_loss : 0.530542\n",
      "batch 18 g_loss : 1.129508\n",
      "batch 19 d_loss : 0.477173\n",
      "batch 19 g1_loss : 0.526231\n",
      "batch 19 g_loss : 1.118680\n",
      "batch 20 d_loss : 0.458069\n",
      "batch 20 g1_loss : 0.502140\n",
      "batch 20 g_loss : 1.076656\n",
      "batch 21 d_loss : 0.517704\n",
      "batch 21 g1_loss : 0.502423\n",
      "batch 21 g_loss : 1.037062\n",
      "batch 22 d_loss : 0.500035\n",
      "batch 22 g1_loss : 0.542921\n",
      "batch 22 g_loss : 1.018227\n",
      "batch 23 d_loss : 0.451451\n",
      "batch 23 g1_loss : 0.509319\n",
      "batch 23 g_loss : 1.059034\n",
      "batch 24 d_loss : 0.444973\n",
      "batch 24 g1_loss : 0.496467\n",
      "batch 24 g_loss : 1.015444\n",
      "batch 25 d_loss : 0.477221\n",
      "batch 25 g1_loss : 0.507634\n",
      "batch 25 g_loss : 1.059053\n",
      "batch 26 d_loss : 0.487717\n",
      "batch 26 g1_loss : 0.498631\n",
      "batch 26 g_loss : 1.099594\n",
      "batch 27 d_loss : 0.506515\n",
      "batch 27 g1_loss : 0.510388\n",
      "batch 27 g_loss : 1.069776\n",
      "batch 28 d_loss : 0.478199\n",
      "batch 28 g1_loss : 0.514591\n",
      "batch 28 g_loss : 1.054060\n",
      "batch 29 d_loss : 0.529529\n",
      "batch 29 g1_loss : 0.504984\n",
      "batch 29 g_loss : 1.099389\n",
      "batch 30 d_loss : 0.455582\n",
      "batch 30 g1_loss : 0.541659\n",
      "batch 30 g_loss : 1.101375\n",
      "batch 31 d_loss : 0.506852\n",
      "batch 31 g1_loss : 0.526628\n",
      "batch 31 g_loss : 1.084672\n",
      "batch 32 d_loss : 0.532100\n",
      "batch 32 g1_loss : 0.524321\n",
      "batch 32 g_loss : 1.070859\n",
      "batch 33 d_loss : 0.466633\n",
      "batch 33 g1_loss : 0.502241\n",
      "batch 33 g_loss : 1.076411\n",
      "batch 34 d_loss : 0.524303\n",
      "batch 34 g1_loss : 0.501215\n",
      "batch 34 g_loss : 1.088791\n",
      "batch 35 d_loss : 0.476477\n",
      "batch 35 g1_loss : 0.487015\n",
      "batch 35 g_loss : 1.034917\n",
      "batch 36 d_loss : 0.514633\n",
      "batch 36 g1_loss : 0.523221\n",
      "batch 36 g_loss : 1.066900\n",
      "batch 37 d_loss : 0.527741\n",
      "batch 37 g1_loss : 0.513476\n",
      "batch 37 g_loss : 1.106250\n",
      "batch 38 d_loss : 0.516854\n",
      "batch 38 g1_loss : 0.499384\n",
      "batch 38 g_loss : 1.049955\n",
      "batch 39 d_loss : 0.484717\n",
      "batch 39 g1_loss : 0.515775\n",
      "batch 39 g_loss : 1.057564\n",
      "batch 40 d_loss : 0.471453\n",
      "batch 40 g1_loss : 0.530823\n",
      "batch 40 g_loss : 1.067693\n",
      "batch 41 d_loss : 0.498594\n",
      "batch 41 g1_loss : 0.511658\n",
      "batch 41 g_loss : 1.116406\n",
      "batch 42 d_loss : 0.466013\n",
      "batch 42 g1_loss : 0.533646\n",
      "batch 42 g_loss : 1.127180\n",
      "batch 43 d_loss : 0.457955\n",
      "batch 43 g1_loss : 0.530306\n",
      "batch 43 g_loss : 1.148835\n",
      "batch 44 d_loss : 0.482275\n",
      "batch 44 g1_loss : 0.540680\n",
      "batch 44 g_loss : 1.192710\n",
      "batch 45 d_loss : 0.471605\n",
      "batch 45 g1_loss : 0.538600\n",
      "batch 45 g_loss : 1.086123\n",
      "batch 46 d_loss : 0.484583\n",
      "batch 46 g1_loss : 0.526596\n",
      "batch 46 g_loss : 1.086255\n",
      "batch 47 d_loss : 0.478192\n",
      "batch 47 g1_loss : 0.545264\n",
      "batch 47 g_loss : 1.133365\n",
      "batch 48 d_loss : 0.461316\n",
      "batch 48 g1_loss : 0.522336\n",
      "batch 48 g_loss : 1.077446\n",
      "batch 49 d_loss : 0.458620\n",
      "batch 49 g1_loss : 0.533317\n",
      "batch 49 g_loss : 1.096664\n",
      "batch 50 d_loss : 0.499381\n",
      "batch 50 g1_loss : 0.519921\n",
      "batch 50 g_loss : 1.111426\n",
      "batch 51 d_loss : 0.451768\n",
      "batch 51 g1_loss : 0.505665\n",
      "batch 51 g_loss : 1.086774\n",
      "batch 52 d_loss : 0.517813\n",
      "batch 52 g1_loss : 0.512987\n",
      "batch 52 g_loss : 1.079141\n",
      "batch 53 d_loss : 0.523670\n",
      "batch 53 g1_loss : 0.525793\n",
      "batch 53 g_loss : 1.048953\n",
      "batch 54 d_loss : 0.514854\n",
      "batch 54 g1_loss : 0.526722\n",
      "batch 54 g_loss : 1.023122\n",
      "batch 55 d_loss : 0.510372\n",
      "batch 55 g1_loss : 0.522354\n",
      "batch 55 g_loss : 1.052633\n",
      "batch 56 d_loss : 0.538202\n",
      "batch 56 g1_loss : 0.529071\n",
      "batch 56 g_loss : 1.036221\n",
      "batch 57 d_loss : 0.556163\n",
      "batch 57 g1_loss : 0.516692\n",
      "batch 57 g_loss : 0.940158\n",
      "batch 58 d_loss : 0.476068\n",
      "batch 58 g1_loss : 0.514257\n",
      "batch 58 g_loss : 1.023665\n",
      "batch 59 d_loss : 0.530978\n",
      "batch 59 g1_loss : 0.525321\n",
      "batch 59 g_loss : 0.982578\n",
      "batch 60 d_loss : 0.496877\n",
      "batch 60 g1_loss : 0.533103\n",
      "batch 60 g_loss : 1.001323\n",
      "batch 61 d_loss : 0.554682\n",
      "batch 61 g1_loss : 0.539099\n",
      "batch 61 g_loss : 1.009132\n",
      "batch 62 d_loss : 0.535674\n",
      "batch 62 g1_loss : 0.519667\n",
      "batch 62 g_loss : 1.056742\n",
      "batch 63 d_loss : 0.503451\n",
      "batch 63 g1_loss : 0.531093\n",
      "batch 63 g_loss : 1.102145\n",
      "batch 64 d_loss : 0.486680\n",
      "batch 64 g1_loss : 0.533136\n",
      "batch 64 g_loss : 1.070743\n",
      "batch 65 d_loss : 0.553718\n",
      "batch 65 g1_loss : 0.523431\n",
      "batch 65 g_loss : 1.071445\n",
      "batch 66 d_loss : 0.504726\n",
      "batch 66 g1_loss : 0.546018\n",
      "batch 66 g_loss : 1.029528\n",
      "batch 67 d_loss : 0.496177\n",
      "batch 67 g1_loss : 0.512659\n",
      "batch 67 g_loss : 1.109448\n",
      "batch 68 d_loss : 0.495027\n",
      "batch 68 g1_loss : 0.532969\n",
      "batch 68 g_loss : 1.094607\n",
      "batch 69 d_loss : 0.498785\n",
      "batch 69 g1_loss : 0.543175\n",
      "batch 69 g_loss : 1.090282\n",
      "batch 70 d_loss : 0.490828\n",
      "batch 70 g1_loss : 0.520343\n",
      "batch 70 g_loss : 1.067271\n",
      "batch 71 d_loss : 0.493865\n",
      "batch 71 g1_loss : 0.550425\n",
      "batch 71 g_loss : 1.036879\n",
      "batch 72 d_loss : 0.530612\n",
      "batch 72 g1_loss : 0.538429\n",
      "batch 72 g_loss : 0.988864\n",
      "batch 73 d_loss : 0.522908\n",
      "batch 73 g1_loss : 0.540754\n",
      "batch 73 g_loss : 1.077119\n",
      "batch 74 d_loss : 0.534746\n",
      "batch 74 g1_loss : 0.529317\n",
      "batch 74 g_loss : 1.029079\n",
      "batch 75 d_loss : 0.538299\n",
      "batch 75 g1_loss : 0.536906\n",
      "batch 75 g_loss : 1.009589\n",
      "batch 76 d_loss : 0.467212\n",
      "batch 76 g1_loss : 0.520070\n",
      "batch 76 g_loss : 1.050593\n",
      "batch 77 d_loss : 0.483482\n",
      "batch 77 g1_loss : 0.523579\n",
      "batch 77 g_loss : 1.093218\n",
      "batch 78 d_loss : 0.485725\n",
      "batch 78 g1_loss : 0.553080\n",
      "batch 78 g_loss : 1.221333\n",
      "batch 79 d_loss : 0.496258\n",
      "batch 79 g1_loss : 0.523651\n",
      "batch 79 g_loss : 1.116021\n",
      "batch 80 d_loss : 0.493543\n",
      "batch 80 g1_loss : 0.519394\n",
      "batch 80 g_loss : 1.152008\n",
      "batch 81 d_loss : 0.456584\n",
      "batch 81 g1_loss : 0.520978\n",
      "batch 81 g_loss : 1.156293\n",
      "batch 82 d_loss : 0.500451\n",
      "batch 82 g1_loss : 0.521489\n",
      "batch 82 g_loss : 1.129444\n",
      "batch 83 d_loss : 0.520702\n",
      "batch 83 g1_loss : 0.521597\n",
      "batch 83 g_loss : 1.084962\n",
      "batch 84 d_loss : 0.463406\n",
      "batch 84 g1_loss : 0.540495\n",
      "batch 84 g_loss : 1.090772\n",
      "batch 85 d_loss : 0.489812\n",
      "batch 85 g1_loss : 0.520159\n",
      "batch 85 g_loss : 1.043099\n",
      "batch 86 d_loss : 0.499038\n",
      "batch 86 g1_loss : 0.531803\n",
      "batch 86 g_loss : 1.046752\n",
      "batch 87 d_loss : 0.450978\n",
      "batch 87 g1_loss : 0.526758\n",
      "batch 87 g_loss : 1.083431\n",
      "batch 88 d_loss : 0.492077\n",
      "batch 88 g1_loss : 0.537120\n",
      "batch 88 g_loss : 1.089150\n",
      "batch 89 d_loss : 0.500014\n",
      "batch 89 g1_loss : 0.526486\n",
      "batch 89 g_loss : 1.112113\n",
      "batch 90 d_loss : 0.522216\n",
      "batch 90 g1_loss : 0.538552\n",
      "batch 90 g_loss : 1.038613\n",
      "batch 91 d_loss : 0.502738\n",
      "batch 91 g1_loss : 0.524200\n",
      "batch 91 g_loss : 0.982533\n",
      "batch 92 d_loss : 0.479843\n",
      "batch 92 g1_loss : 0.509832\n",
      "batch 92 g_loss : 1.059979\n",
      "batch 93 d_loss : 0.494655\n",
      "batch 93 g1_loss : 0.519525\n",
      "batch 93 g_loss : 1.122032\n",
      "batch 94 d_loss : 0.499202\n",
      "batch 94 g1_loss : 0.512815\n",
      "batch 94 g_loss : 1.129039\n",
      "batch 95 d_loss : 0.508795\n",
      "batch 95 g1_loss : 0.515616\n",
      "batch 95 g_loss : 1.110140\n",
      "batch 96 d_loss : 0.565363\n",
      "batch 96 g1_loss : 0.516408\n",
      "batch 96 g_loss : 1.130012\n",
      "batch 97 d_loss : 0.497753\n",
      "batch 97 g1_loss : 0.520863\n",
      "batch 97 g_loss : 1.176727\n",
      "batch 98 d_loss : 0.487546\n",
      "batch 98 g1_loss : 0.516220\n",
      "batch 98 g_loss : 1.136708\n",
      "batch 99 d_loss : 0.517993\n",
      "batch 99 g1_loss : 0.534511\n",
      "batch 99 g_loss : 1.107780\n",
      "batch 100 d_loss : 0.534154\n",
      "batch 100 g1_loss : 0.537421\n",
      "batch 100 g_loss : 1.061745\n",
      "batch 101 d_loss : 0.503797\n",
      "batch 101 g1_loss : 0.528542\n",
      "batch 101 g_loss : 1.073947\n",
      "batch 102 d_loss : 0.531216\n",
      "batch 102 g1_loss : 0.527568\n",
      "batch 102 g_loss : 1.061660\n",
      "batch 103 d_loss : 0.519990\n",
      "batch 103 g1_loss : 0.546689\n",
      "batch 103 g_loss : 1.132020\n",
      "batch 104 d_loss : 0.516819\n",
      "batch 104 g1_loss : 0.514179\n",
      "batch 104 g_loss : 1.167309\n",
      "batch 105 d_loss : 0.476615\n",
      "batch 105 g1_loss : 0.507745\n",
      "batch 105 g_loss : 1.203610\n",
      "batch 106 d_loss : 0.543487\n",
      "batch 106 g1_loss : 0.537609\n",
      "batch 106 g_loss : 1.083768\n",
      "batch 107 d_loss : 0.540885\n",
      "batch 107 g1_loss : 0.520990\n",
      "batch 107 g_loss : 1.118777\n",
      "batch 108 d_loss : 0.547073\n",
      "batch 108 g1_loss : 0.527077\n",
      "batch 108 g_loss : 1.053609\n",
      "batch 109 d_loss : 0.587940\n",
      "batch 109 g1_loss : 0.528986\n",
      "batch 109 g_loss : 0.943258\n",
      "batch 110 d_loss : 0.565480\n",
      "batch 110 g1_loss : 0.537140\n",
      "batch 110 g_loss : 1.002592\n",
      "batch 111 d_loss : 0.568887\n",
      "batch 111 g1_loss : 0.534570\n",
      "batch 111 g_loss : 0.988434\n",
      "batch 112 d_loss : 0.493178\n",
      "batch 112 g1_loss : 0.525364\n",
      "batch 112 g_loss : 1.001723\n",
      "batch 113 d_loss : 0.563893\n",
      "batch 113 g1_loss : 0.529008\n",
      "batch 113 g_loss : 1.054849\n",
      "batch 114 d_loss : 0.600400\n",
      "batch 114 g1_loss : 0.537274\n",
      "batch 114 g_loss : 0.963487\n",
      "batch 115 d_loss : 0.669715\n",
      "batch 115 g1_loss : 0.537725\n",
      "batch 115 g_loss : 0.912981\n",
      "batch 116 d_loss : 0.545972\n",
      "batch 116 g1_loss : 0.550613\n",
      "batch 116 g_loss : 0.916340\n",
      "batch 117 d_loss : 0.496838\n",
      "batch 117 g1_loss : 0.544368\n",
      "batch 117 g_loss : 1.012922\n",
      "batch 118 d_loss : 0.518027\n",
      "batch 118 g1_loss : 0.519896\n",
      "batch 118 g_loss : 0.982380\n",
      "batch 119 d_loss : 0.481898\n",
      "batch 119 g1_loss : 0.541227\n",
      "batch 119 g_loss : 1.102646\n",
      "batch 120 d_loss : 0.535409\n",
      "batch 120 g1_loss : 0.524640\n",
      "batch 120 g_loss : 1.025917\n",
      "batch 121 d_loss : 0.534544\n",
      "batch 121 g1_loss : 0.545161\n",
      "batch 121 g_loss : 0.976841\n",
      "batch 122 d_loss : 0.506933\n",
      "batch 122 g1_loss : 0.532586\n",
      "batch 122 g_loss : 1.029044\n",
      "batch 123 d_loss : 0.556173\n",
      "batch 123 g1_loss : 0.535858\n",
      "batch 123 g_loss : 1.019986\n",
      "batch 124 d_loss : 0.516193\n",
      "batch 124 g1_loss : 0.526223\n",
      "batch 124 g_loss : 0.952257\n",
      "batch 125 d_loss : 0.495584\n",
      "batch 125 g1_loss : 0.532209\n",
      "batch 125 g_loss : 1.014292\n",
      "batch 126 d_loss : 0.481169\n",
      "batch 126 g1_loss : 0.528871\n",
      "batch 126 g_loss : 1.090895\n",
      "batch 127 d_loss : 0.462776\n",
      "batch 127 g1_loss : 0.520079\n",
      "batch 127 g_loss : 1.118234\n",
      "batch 128 d_loss : 0.457627\n",
      "batch 128 g1_loss : 0.542004\n",
      "batch 128 g_loss : 1.180937\n",
      "batch 129 d_loss : 0.472049\n",
      "batch 129 g1_loss : 0.529911\n",
      "batch 129 g_loss : 1.132316\n",
      "batch 130 d_loss : 0.486959\n",
      "batch 130 g1_loss : 0.517748\n",
      "batch 130 g_loss : 1.093858\n",
      "batch 131 d_loss : 0.556008\n",
      "batch 131 g1_loss : 0.521393\n",
      "batch 131 g_loss : 1.048129\n",
      "batch 132 d_loss : 0.529245\n",
      "batch 132 g1_loss : 0.522035\n",
      "batch 132 g_loss : 0.981062\n",
      "batch 133 d_loss : 0.525509\n",
      "batch 133 g1_loss : 0.541353\n",
      "batch 133 g_loss : 0.978042\n",
      "batch 134 d_loss : 0.543551\n",
      "batch 134 g1_loss : 0.542888\n",
      "batch 134 g_loss : 0.926774\n",
      "batch 135 d_loss : 0.498530\n",
      "batch 135 g1_loss : 0.540668\n",
      "batch 135 g_loss : 1.047345\n",
      "batch 136 d_loss : 0.534852\n",
      "batch 136 g1_loss : 0.523988\n",
      "batch 136 g_loss : 1.033260\n",
      "batch 137 d_loss : 0.605295\n",
      "batch 137 g1_loss : 0.529511\n",
      "batch 137 g_loss : 1.028625\n",
      "batch 138 d_loss : 0.524712\n",
      "batch 138 g1_loss : 0.527359\n",
      "batch 138 g_loss : 0.955375\n",
      "batch 139 d_loss : 0.533451\n",
      "batch 139 g1_loss : 0.531112\n",
      "batch 139 g_loss : 0.978152\n",
      "batch 140 d_loss : 0.493640\n",
      "batch 140 g1_loss : 0.524358\n",
      "batch 140 g_loss : 1.085814\n",
      "batch 141 d_loss : 0.474327\n",
      "batch 141 g1_loss : 0.520294\n",
      "batch 141 g_loss : 1.113797\n",
      "batch 142 d_loss : 0.497609\n",
      "batch 142 g1_loss : 0.530993\n",
      "batch 142 g_loss : 1.151001\n",
      "batch 143 d_loss : 0.479597\n",
      "batch 143 g1_loss : 0.507537\n",
      "batch 143 g_loss : 1.088205\n",
      "batch 144 d_loss : 0.489508\n",
      "batch 144 g1_loss : 0.500486\n",
      "batch 144 g_loss : 1.132671\n",
      "batch 145 d_loss : 0.491380\n",
      "batch 145 g1_loss : 0.494531\n",
      "batch 145 g_loss : 1.066591\n",
      "batch 146 d_loss : 0.477974\n",
      "batch 146 g1_loss : 0.519956\n",
      "batch 146 g_loss : 1.127806\n",
      "batch 147 d_loss : 0.513557\n",
      "batch 147 g1_loss : 0.487319\n",
      "batch 147 g_loss : 1.122903\n",
      "batch 148 d_loss : 0.518157\n",
      "batch 148 g1_loss : 0.514276\n",
      "batch 148 g_loss : 1.044305\n",
      "batch 149 d_loss : 0.521516\n",
      "batch 149 g1_loss : 0.527669\n",
      "batch 149 g_loss : 1.015955\n",
      "batch 150 d_loss : 0.518886\n",
      "batch 150 g1_loss : 0.525861\n",
      "batch 150 g_loss : 1.051060\n",
      "batch 151 d_loss : 0.508570\n",
      "batch 151 g1_loss : 0.523205\n",
      "batch 151 g_loss : 1.126006\n",
      "batch 152 d_loss : 0.517530\n",
      "batch 152 g1_loss : 0.518187\n",
      "batch 152 g_loss : 1.113354\n",
      "batch 153 d_loss : 0.478746\n",
      "batch 153 g1_loss : 0.498549\n",
      "batch 153 g_loss : 1.200960\n",
      "batch 154 d_loss : 0.466165\n",
      "batch 154 g1_loss : 0.495161\n",
      "batch 154 g_loss : 1.225071\n",
      "batch 155 d_loss : 0.537546\n",
      "batch 155 g1_loss : 0.488604\n",
      "batch 155 g_loss : 1.128778\n",
      "batch 156 d_loss : 0.551781\n",
      "batch 156 g1_loss : 0.512661\n",
      "batch 156 g_loss : 1.067228\n",
      "batch 157 d_loss : 0.484761\n",
      "batch 157 g1_loss : 0.504314\n",
      "batch 157 g_loss : 1.061116\n",
      "batch 158 d_loss : 0.543894\n",
      "batch 158 g1_loss : 0.506027\n",
      "batch 158 g_loss : 0.996678\n",
      "batch 159 d_loss : 0.493972\n",
      "batch 159 g1_loss : 0.514003\n",
      "batch 159 g_loss : 1.091091\n",
      "batch 160 d_loss : 0.461047\n",
      "batch 160 g1_loss : 0.504787\n",
      "batch 160 g_loss : 1.206169\n",
      "batch 161 d_loss : 0.465292\n",
      "batch 161 g1_loss : 0.473102\n",
      "batch 161 g_loss : 1.183373\n",
      "batch 162 d_loss : 0.472453\n",
      "batch 162 g1_loss : 0.509377\n",
      "batch 162 g_loss : 1.211953\n",
      "batch 163 d_loss : 0.521686\n",
      "batch 163 g1_loss : 0.485717\n",
      "batch 163 g_loss : 1.174588\n",
      "batch 164 d_loss : 0.477695\n",
      "batch 164 g1_loss : 0.493937\n",
      "batch 164 g_loss : 1.067692\n",
      "batch 165 d_loss : 0.468803\n",
      "batch 165 g1_loss : 0.498448\n",
      "batch 165 g_loss : 1.111599\n",
      "batch 166 d_loss : 0.475894\n",
      "batch 166 g1_loss : 0.493925\n",
      "batch 166 g_loss : 1.087761\n",
      "batch 167 d_loss : 0.487609\n",
      "batch 167 g1_loss : 0.518410\n",
      "batch 167 g_loss : 1.058163\n",
      "batch 168 d_loss : 0.451730\n",
      "batch 168 g1_loss : 0.499197\n",
      "batch 168 g_loss : 1.208975\n",
      "batch 169 d_loss : 0.506509\n",
      "batch 169 g1_loss : 0.533526\n",
      "batch 169 g_loss : 1.175688\n",
      "batch 170 d_loss : 0.435777\n",
      "batch 170 g1_loss : 0.501481\n",
      "batch 170 g_loss : 1.182066\n",
      "batch 171 d_loss : 0.444853\n",
      "batch 171 g1_loss : 0.499988\n",
      "batch 171 g_loss : 1.315150\n",
      "batch 172 d_loss : 0.559146\n",
      "batch 172 g1_loss : 0.482030\n",
      "batch 172 g_loss : 1.162400\n",
      "batch 173 d_loss : 0.511950\n",
      "batch 173 g1_loss : 0.496087\n",
      "batch 173 g_loss : 1.070229\n",
      "batch 174 d_loss : 0.455095\n",
      "batch 174 g1_loss : 0.492978\n",
      "batch 174 g_loss : 1.166954\n",
      "batch 175 d_loss : 0.517475\n",
      "batch 175 g1_loss : 0.498333\n",
      "batch 175 g_loss : 1.108959\n",
      "batch 176 d_loss : 0.552509\n",
      "batch 176 g1_loss : 0.495542\n",
      "batch 176 g_loss : 1.057646\n",
      "batch 177 d_loss : 0.490459\n",
      "batch 177 g1_loss : 0.495037\n",
      "batch 177 g_loss : 1.147847\n",
      "batch 178 d_loss : 0.499966\n",
      "batch 178 g1_loss : 0.493543\n",
      "batch 178 g_loss : 1.146708\n",
      "batch 179 d_loss : 0.520548\n",
      "batch 179 g1_loss : 0.511329\n",
      "batch 179 g_loss : 1.157833\n",
      "batch 180 d_loss : 0.485543\n",
      "batch 180 g1_loss : 0.507729\n",
      "batch 180 g_loss : 1.190112\n",
      "batch 181 d_loss : 0.464640\n",
      "batch 181 g1_loss : 0.490761\n",
      "batch 181 g_loss : 1.243552\n",
      "batch 182 d_loss : 0.450519\n",
      "batch 182 g1_loss : 0.500298\n",
      "batch 182 g_loss : 1.187761\n",
      "batch 183 d_loss : 0.482112\n",
      "batch 183 g1_loss : 0.499664\n",
      "batch 183 g_loss : 1.086049\n",
      "batch 184 d_loss : 0.496828\n",
      "batch 184 g1_loss : 0.486245\n",
      "batch 184 g_loss : 1.112242\n",
      "batch 185 d_loss : 0.505879\n",
      "batch 185 g1_loss : 0.505683\n",
      "batch 185 g_loss : 1.030037\n",
      "batch 186 d_loss : 0.530593\n",
      "batch 186 g1_loss : 0.509034\n",
      "batch 186 g_loss : 1.024427\n",
      "batch 187 d_loss : 0.479003\n",
      "batch 187 g1_loss : 0.526129\n",
      "batch 187 g_loss : 1.018301\n",
      "batch 188 d_loss : 0.456309\n",
      "batch 188 g1_loss : 0.489490\n",
      "batch 188 g_loss : 1.180345\n",
      "batch 189 d_loss : 0.520386\n",
      "batch 189 g1_loss : 0.500736\n",
      "batch 189 g_loss : 1.190428\n",
      "batch 190 d_loss : 0.496918\n",
      "batch 190 g1_loss : 0.489434\n",
      "batch 190 g_loss : 1.150324\n",
      "batch 191 d_loss : 0.516634\n",
      "batch 191 g1_loss : 0.508128\n",
      "batch 191 g_loss : 1.090713\n",
      "batch 192 d_loss : 0.491630\n",
      "batch 192 g1_loss : 0.488073\n",
      "batch 192 g_loss : 1.104912\n",
      "batch 193 d_loss : 0.437840\n",
      "batch 193 g1_loss : 0.516095\n",
      "batch 193 g_loss : 1.180146\n",
      "batch 194 d_loss : 0.524930\n",
      "batch 194 g1_loss : 0.494116\n",
      "batch 194 g_loss : 1.108946\n",
      "batch 195 d_loss : 0.492896\n",
      "batch 195 g1_loss : 0.528510\n",
      "batch 195 g_loss : 1.119779\n",
      "batch 196 d_loss : 0.484086\n",
      "batch 196 g1_loss : 0.524695\n",
      "batch 196 g_loss : 1.133795\n",
      "batch 197 d_loss : 0.459006\n",
      "batch 197 g1_loss : 0.523813\n",
      "batch 197 g_loss : 1.105452\n",
      "batch 198 d_loss : 0.421435\n",
      "batch 198 g1_loss : 0.504223\n",
      "batch 198 g_loss : 1.233639\n",
      "batch 199 d_loss : 0.432269\n",
      "batch 199 g1_loss : 0.528122\n",
      "batch 199 g_loss : 1.214690\n",
      "batch 200 d_loss : 0.467450\n",
      "batch 200 g1_loss : 0.502725\n",
      "batch 200 g_loss : 1.211928\n",
      "batch 201 d_loss : 0.505421\n",
      "batch 201 g1_loss : 0.527633\n",
      "batch 201 g_loss : 1.110824\n",
      "batch 202 d_loss : 0.522536\n",
      "batch 202 g1_loss : 0.531138\n",
      "batch 202 g_loss : 1.010868\n",
      "batch 203 d_loss : 0.456504\n",
      "batch 203 g1_loss : 0.512643\n",
      "batch 203 g_loss : 1.054463\n",
      "batch 204 d_loss : 0.453761\n",
      "batch 204 g1_loss : 0.524878\n",
      "batch 204 g_loss : 1.055850\n",
      "batch 205 d_loss : 0.484153\n",
      "batch 205 g1_loss : 0.513541\n",
      "batch 205 g_loss : 1.084418\n",
      "batch 206 d_loss : 0.502453\n",
      "batch 206 g1_loss : 0.532686\n",
      "batch 206 g_loss : 1.093098\n",
      "batch 207 d_loss : 0.571864\n",
      "batch 207 g1_loss : 0.530368\n",
      "batch 207 g_loss : 0.997102\n",
      "batch 208 d_loss : 0.483609\n",
      "batch 208 g1_loss : 0.513767\n",
      "batch 208 g_loss : 1.057739\n",
      "batch 209 d_loss : 0.420833\n",
      "batch 209 g1_loss : 0.532138\n",
      "batch 209 g_loss : 1.190722\n",
      "batch 210 d_loss : 0.456554\n",
      "batch 210 g1_loss : 0.532217\n",
      "batch 210 g_loss : 1.184976\n",
      "batch 211 d_loss : 0.449814\n",
      "batch 211 g1_loss : 0.522182\n",
      "batch 211 g_loss : 1.170288\n",
      "batch 212 d_loss : 0.470338\n",
      "batch 212 g1_loss : 0.517004\n",
      "batch 212 g_loss : 1.163894\n",
      "batch 213 d_loss : 0.500564\n",
      "batch 213 g1_loss : 0.522757\n",
      "batch 213 g_loss : 1.184737\n",
      "batch 214 d_loss : 0.540837\n",
      "batch 214 g1_loss : 0.535170\n",
      "batch 214 g_loss : 1.051695\n",
      "batch 215 d_loss : 0.491528\n",
      "batch 215 g1_loss : 0.526312\n",
      "batch 215 g_loss : 1.022094\n",
      "batch 216 d_loss : 0.521715\n",
      "batch 216 g1_loss : 0.531036\n",
      "batch 216 g_loss : 1.074212\n",
      "batch 217 d_loss : 0.538921\n",
      "batch 217 g1_loss : 0.524324\n",
      "batch 217 g_loss : 1.027979\n",
      "batch 218 d_loss : 0.449775\n",
      "batch 218 g1_loss : 0.509039\n",
      "batch 218 g_loss : 1.108117\n",
      "batch 219 d_loss : 0.447644\n",
      "batch 219 g1_loss : 0.513856\n",
      "batch 219 g_loss : 1.226433\n",
      "batch 220 d_loss : 0.449056\n",
      "batch 220 g1_loss : 0.508943\n",
      "batch 220 g_loss : 1.263372\n",
      "batch 221 d_loss : 0.497074\n",
      "batch 221 g1_loss : 0.526160\n",
      "batch 221 g_loss : 1.182745\n",
      "batch 222 d_loss : 0.476346\n",
      "batch 222 g1_loss : 0.526752\n",
      "batch 222 g_loss : 1.191353\n",
      "batch 223 d_loss : 0.516567\n",
      "batch 223 g1_loss : 0.531981\n",
      "batch 223 g_loss : 1.154981\n",
      "batch 224 d_loss : 0.483349\n",
      "batch 224 g1_loss : 0.537554\n",
      "batch 224 g_loss : 1.141049\n",
      "batch 225 d_loss : 0.563243\n",
      "batch 225 g1_loss : 0.533830\n",
      "batch 225 g_loss : 1.061211\n",
      "batch 226 d_loss : 0.502168\n",
      "batch 226 g1_loss : 0.542222\n",
      "batch 226 g_loss : 1.085634\n",
      "batch 227 d_loss : 0.555704\n",
      "batch 227 g1_loss : 0.508798\n",
      "batch 227 g_loss : 1.000880\n",
      "batch 228 d_loss : 0.521208\n",
      "batch 228 g1_loss : 0.528364\n",
      "batch 228 g_loss : 1.009489\n",
      "batch 229 d_loss : 0.454273\n",
      "batch 229 g1_loss : 0.521557\n",
      "batch 229 g_loss : 1.105243\n",
      "batch 230 d_loss : 0.436672\n",
      "batch 230 g1_loss : 0.517690\n",
      "batch 230 g_loss : 1.177284\n",
      "batch 231 d_loss : 0.486952\n",
      "batch 231 g1_loss : 0.519205\n",
      "batch 231 g_loss : 1.249208\n",
      "batch 232 d_loss : 0.521654\n",
      "batch 232 g1_loss : 0.500763\n",
      "batch 232 g_loss : 1.106685\n",
      "batch 233 d_loss : 0.548170\n",
      "batch 233 g1_loss : 0.542540\n",
      "batch 233 g_loss : 1.035946\n",
      "batch 234 d_loss : 0.566286\n",
      "batch 234 g1_loss : 0.518689\n",
      "batch 234 g_loss : 0.972675\n",
      "batch 235 d_loss : 0.608861\n",
      "batch 235 g1_loss : 0.520233\n",
      "batch 235 g_loss : 0.892197\n",
      "batch 236 d_loss : 0.441072\n",
      "batch 236 g1_loss : 0.548374\n",
      "batch 236 g_loss : 0.977880\n",
      "batch 237 d_loss : 0.503218\n",
      "batch 237 g1_loss : 0.521412\n",
      "batch 237 g_loss : 1.072235\n",
      "batch 238 d_loss : 0.483773\n",
      "batch 238 g1_loss : 0.526728\n",
      "batch 238 g_loss : 1.241189\n",
      "batch 239 d_loss : 0.565406\n",
      "batch 239 g1_loss : 0.517926\n",
      "batch 239 g_loss : 1.132435\n",
      "batch 240 d_loss : 0.494520\n",
      "batch 240 g1_loss : 0.501184\n",
      "batch 240 g_loss : 1.122690\n",
      "batch 241 d_loss : 0.438456\n",
      "batch 241 g1_loss : 0.524701\n",
      "batch 241 g_loss : 1.108075\n",
      "batch 242 d_loss : 0.463741\n",
      "batch 242 g1_loss : 0.517628\n",
      "batch 242 g_loss : 1.147967\n",
      "batch 243 d_loss : 0.499278\n",
      "batch 243 g1_loss : 0.498403\n",
      "batch 243 g_loss : 1.153641\n",
      "batch 244 d_loss : 0.511997\n",
      "batch 244 g1_loss : 0.506274\n",
      "batch 244 g_loss : 1.085817\n",
      "batch 245 d_loss : 0.493644\n",
      "batch 245 g1_loss : 0.513331\n",
      "batch 245 g_loss : 1.015844\n",
      "batch 246 d_loss : 0.501265\n",
      "batch 246 g1_loss : 0.510207\n",
      "batch 246 g_loss : 0.984506\n",
      "batch 247 d_loss : 0.526160\n",
      "batch 247 g1_loss : 0.501377\n",
      "batch 247 g_loss : 1.001876\n",
      "batch 248 d_loss : 0.490461\n",
      "batch 248 g1_loss : 0.521049\n",
      "batch 248 g_loss : 1.034860\n",
      "batch 249 d_loss : 0.453973\n",
      "batch 249 g1_loss : 0.506996\n",
      "batch 249 g_loss : 1.051639\n",
      "batch 250 d_loss : 0.450327\n",
      "batch 250 g1_loss : 0.494272\n",
      "batch 250 g_loss : 1.200738\n",
      "batch 251 d_loss : 0.565180\n",
      "batch 251 g1_loss : 0.514920\n",
      "batch 251 g_loss : 1.203449\n",
      "batch 252 d_loss : 0.491144\n",
      "batch 252 g1_loss : 0.501830\n",
      "batch 252 g_loss : 1.135616\n",
      "batch 253 d_loss : 0.545039\n",
      "batch 253 g1_loss : 0.491929\n",
      "batch 253 g_loss : 1.088439\n",
      "batch 254 d_loss : 0.506351\n",
      "batch 254 g1_loss : 0.487148\n",
      "batch 254 g_loss : 1.086652\n",
      "batch 255 d_loss : 0.480660\n",
      "batch 255 g1_loss : 0.492547\n",
      "batch 255 g_loss : 1.051437\n",
      "batch 256 d_loss : 0.452406\n",
      "batch 256 g1_loss : 0.507445\n",
      "batch 256 g_loss : 1.124159\n",
      "batch 257 d_loss : 0.427771\n",
      "batch 257 g1_loss : 0.516990\n",
      "batch 257 g_loss : 1.209550\n",
      "batch 258 d_loss : 0.501140\n",
      "batch 258 g1_loss : 0.485532\n",
      "batch 258 g_loss : 1.125142\n",
      "batch 259 d_loss : 0.452527\n",
      "batch 259 g1_loss : 0.514170\n",
      "batch 259 g_loss : 1.185008\n",
      "batch 260 d_loss : 0.543657\n",
      "batch 260 g1_loss : 0.486948\n",
      "batch 260 g_loss : 1.117924\n",
      "batch 261 d_loss : 0.472353\n",
      "batch 261 g1_loss : 0.488070\n",
      "batch 261 g_loss : 1.118180\n",
      "batch 262 d_loss : 0.487058\n",
      "batch 262 g1_loss : 0.498877\n",
      "batch 262 g_loss : 1.111649\n",
      "batch 263 d_loss : 0.439991\n",
      "batch 263 g1_loss : 0.484427\n",
      "batch 263 g_loss : 1.102939\n",
      "batch 264 d_loss : 0.423945\n",
      "batch 264 g1_loss : 0.494562\n",
      "batch 264 g_loss : 1.211206\n",
      "batch 265 d_loss : 0.498356\n",
      "batch 265 g1_loss : 0.497223\n",
      "batch 265 g_loss : 1.136232\n",
      "batch 266 d_loss : 0.514347\n",
      "batch 266 g1_loss : 0.497545\n",
      "batch 266 g_loss : 1.082301\n",
      "batch 267 d_loss : 0.451718\n",
      "batch 267 g1_loss : 0.477762\n",
      "batch 267 g_loss : 1.196841\n",
      "batch 268 d_loss : 0.412974\n",
      "batch 268 g1_loss : 0.499896\n",
      "batch 268 g_loss : 1.199776\n",
      "batch 269 d_loss : 0.464553\n",
      "batch 269 g1_loss : 0.482523\n",
      "batch 269 g_loss : 1.192081\n",
      "batch 270 d_loss : 0.473130\n",
      "batch 270 g1_loss : 0.493940\n",
      "batch 270 g_loss : 1.166013\n",
      "batch 271 d_loss : 0.530636\n",
      "batch 271 g1_loss : 0.473933\n",
      "batch 271 g_loss : 1.093609\n",
      "batch 272 d_loss : 0.488632\n",
      "batch 272 g1_loss : 0.486154\n",
      "batch 272 g_loss : 1.103883\n",
      "batch 273 d_loss : 0.415177\n",
      "batch 273 g1_loss : 0.497669\n",
      "batch 273 g_loss : 1.122733\n",
      "batch 274 d_loss : 0.474152\n",
      "batch 274 g1_loss : 0.491017\n",
      "batch 274 g_loss : 1.140163\n",
      "batch 275 d_loss : 0.507849\n",
      "batch 275 g1_loss : 0.495405\n",
      "batch 275 g_loss : 1.097752\n",
      "batch 276 d_loss : 0.487149\n",
      "batch 276 g1_loss : 0.483727\n",
      "batch 276 g_loss : 1.125269\n",
      "batch 277 d_loss : 0.462226\n",
      "batch 277 g1_loss : 0.480924\n",
      "batch 277 g_loss : 1.137451\n",
      "batch 278 d_loss : 0.475625\n",
      "batch 278 g1_loss : 0.490087\n",
      "batch 278 g_loss : 1.124041\n",
      "batch 279 d_loss : 0.440954\n",
      "batch 279 g1_loss : 0.501547\n",
      "batch 279 g_loss : 1.251444\n",
      "batch 280 d_loss : 0.507368\n",
      "batch 280 g1_loss : 0.490775\n",
      "batch 280 g_loss : 1.106029\n",
      "batch 281 d_loss : 0.528001\n",
      "batch 281 g1_loss : 0.505902\n",
      "batch 281 g_loss : 0.946019\n",
      "batch 282 d_loss : 0.460918\n",
      "batch 282 g1_loss : 0.498546\n",
      "batch 282 g_loss : 0.997835\n",
      "batch 283 d_loss : 0.450928\n",
      "batch 283 g1_loss : 0.489701\n",
      "batch 283 g_loss : 1.151403\n",
      "batch 284 d_loss : 0.464472\n",
      "batch 284 g1_loss : 0.500661\n",
      "batch 284 g_loss : 1.266172\n",
      "batch 285 d_loss : 0.417251\n",
      "batch 285 g1_loss : 0.498946\n",
      "batch 285 g_loss : 1.257727\n",
      "batch 286 d_loss : 0.405998\n",
      "batch 286 g1_loss : 0.503206\n",
      "batch 286 g_loss : 1.384309\n",
      "batch 287 d_loss : 0.396533\n",
      "batch 287 g1_loss : 0.491307\n",
      "batch 287 g_loss : 1.414615\n",
      "batch 288 d_loss : 0.420247\n",
      "batch 288 g1_loss : 0.502325\n",
      "batch 288 g_loss : 1.363635\n",
      "batch 289 d_loss : 0.484376\n",
      "batch 289 g1_loss : 0.500440\n",
      "batch 289 g_loss : 1.253545\n",
      "batch 290 d_loss : 0.457549\n",
      "batch 290 g1_loss : 0.506623\n",
      "batch 290 g_loss : 1.296884\n",
      "batch 291 d_loss : 0.465477\n",
      "batch 291 g1_loss : 0.508664\n",
      "batch 291 g_loss : 1.117982\n",
      "batch 292 d_loss : 0.489305\n",
      "batch 292 g1_loss : 0.485907\n",
      "batch 292 g_loss : 1.148937\n",
      "batch 293 d_loss : 0.501916\n",
      "batch 293 g1_loss : 0.504534\n",
      "batch 293 g_loss : 1.033192\n",
      "batch 294 d_loss : 0.489476\n",
      "batch 294 g1_loss : 0.499740\n",
      "batch 294 g_loss : 1.022117\n",
      "batch 295 d_loss : 0.489377\n",
      "batch 295 g1_loss : 0.505918\n",
      "batch 295 g_loss : 1.064464\n",
      "batch 296 d_loss : 0.474526\n",
      "batch 296 g1_loss : 0.512937\n",
      "batch 296 g_loss : 1.129835\n",
      "batch 297 d_loss : 0.465403\n",
      "batch 297 g1_loss : 0.500911\n",
      "batch 297 g_loss : 1.175973\n",
      "batch 298 d_loss : 0.480940\n",
      "batch 298 g1_loss : 0.505292\n",
      "batch 298 g_loss : 1.193625\n",
      "batch 299 d_loss : 0.499900\n",
      "batch 299 g1_loss : 0.521164\n",
      "batch 299 g_loss : 1.157527\n",
      "batch 300 d_loss : 0.473748\n",
      "batch 300 g1_loss : 0.507760\n",
      "batch 300 g_loss : 1.065884\n",
      "batch 301 d_loss : 0.505984\n",
      "batch 301 g1_loss : 0.494479\n",
      "batch 301 g_loss : 1.120961\n",
      "batch 302 d_loss : 0.489580\n",
      "batch 302 g1_loss : 0.488189\n",
      "batch 302 g_loss : 1.183646\n",
      "batch 303 d_loss : 0.427537\n",
      "batch 303 g1_loss : 0.509005\n",
      "batch 303 g_loss : 1.195974\n",
      "batch 304 d_loss : 0.467900\n",
      "batch 304 g1_loss : 0.497039\n",
      "batch 304 g_loss : 1.231572\n",
      "batch 305 d_loss : 0.446282\n",
      "batch 305 g1_loss : 0.507546\n",
      "batch 305 g_loss : 1.204206\n",
      "batch 306 d_loss : 0.432841\n",
      "batch 306 g1_loss : 0.510056\n",
      "batch 306 g_loss : 1.312183\n",
      "batch 307 d_loss : 0.512220\n",
      "batch 307 g1_loss : 0.515985\n",
      "batch 307 g_loss : 1.164003\n",
      "batch 308 d_loss : 0.502649\n",
      "batch 308 g1_loss : 0.515427\n",
      "batch 308 g_loss : 1.128221\n",
      "batch 309 d_loss : 0.448848\n",
      "batch 309 g1_loss : 0.519685\n",
      "batch 309 g_loss : 1.165950\n",
      "batch 310 d_loss : 0.535359\n",
      "batch 310 g1_loss : 0.517361\n",
      "batch 310 g_loss : 1.090882\n",
      "batch 311 d_loss : 0.505865\n",
      "batch 311 g1_loss : 0.533715\n",
      "batch 311 g_loss : 0.977051\n",
      "batch 312 d_loss : 0.455402\n",
      "batch 312 g1_loss : 0.506762\n",
      "batch 312 g_loss : 1.081438\n",
      "batch 313 d_loss : 0.467348\n",
      "batch 313 g1_loss : 0.508013\n",
      "batch 313 g_loss : 1.132126\n",
      "batch 314 d_loss : 0.461319\n",
      "batch 314 g1_loss : 0.500046\n",
      "batch 314 g_loss : 1.162854\n",
      "batch 315 d_loss : 0.453528\n",
      "batch 315 g1_loss : 0.527015\n",
      "batch 315 g_loss : 1.191661\n",
      "batch 316 d_loss : 0.515082\n",
      "batch 316 g1_loss : 0.527083\n",
      "batch 316 g_loss : 1.196250\n",
      "batch 317 d_loss : 0.495887\n",
      "batch 317 g1_loss : 0.523680\n",
      "batch 317 g_loss : 1.124390\n",
      "batch 318 d_loss : 0.489095\n",
      "batch 318 g1_loss : 0.533657\n",
      "batch 318 g_loss : 1.080516\n",
      "batch 319 d_loss : 0.458789\n",
      "batch 319 g1_loss : 0.544291\n",
      "batch 319 g_loss : 1.025450\n",
      "batch 320 d_loss : 0.440325\n",
      "batch 320 g1_loss : 0.526007\n",
      "batch 320 g_loss : 1.074679\n",
      "batch 321 d_loss : 0.471628\n",
      "batch 321 g1_loss : 0.537070\n",
      "batch 321 g_loss : 1.106731\n",
      "batch 322 d_loss : 0.552006\n",
      "batch 322 g1_loss : 0.533604\n",
      "batch 322 g_loss : 1.082487\n",
      "batch 323 d_loss : 0.539858\n",
      "batch 323 g1_loss : 0.530122\n",
      "batch 323 g_loss : 1.018177\n",
      "batch 324 d_loss : 0.540136\n",
      "batch 324 g1_loss : 0.523297\n",
      "batch 324 g_loss : 1.019812\n",
      "batch 325 d_loss : 0.491640\n",
      "batch 325 g1_loss : 0.521623\n",
      "batch 325 g_loss : 1.002217\n",
      "batch 326 d_loss : 0.521482\n",
      "batch 326 g1_loss : 0.523797\n",
      "batch 326 g_loss : 0.993533\n",
      "batch 327 d_loss : 0.480905\n",
      "batch 327 g1_loss : 0.518636\n",
      "batch 327 g_loss : 1.029410\n",
      "batch 328 d_loss : 0.457640\n",
      "batch 328 g1_loss : 0.532203\n",
      "batch 328 g_loss : 1.073883\n",
      "batch 329 d_loss : 0.487541\n",
      "batch 329 g1_loss : 0.535643\n",
      "batch 329 g_loss : 1.174543\n",
      "batch 330 d_loss : 0.557701\n",
      "batch 330 g1_loss : 0.538138\n",
      "batch 330 g_loss : 1.147092\n",
      "batch 331 d_loss : 0.476627\n",
      "batch 331 g1_loss : 0.511880\n",
      "batch 331 g_loss : 1.066728\n",
      "batch 332 d_loss : 0.486282\n",
      "batch 332 g1_loss : 0.493148\n",
      "batch 332 g_loss : 1.080014\n",
      "batch 333 d_loss : 0.467420\n",
      "batch 333 g1_loss : 0.513452\n",
      "batch 333 g_loss : 1.144099\n",
      "batch 334 d_loss : 0.426104\n",
      "batch 334 g1_loss : 0.543180\n",
      "batch 334 g_loss : 1.178070\n",
      "batch 335 d_loss : 0.437362\n",
      "batch 335 g1_loss : 0.520272\n",
      "batch 335 g_loss : 1.182065\n",
      "batch 336 d_loss : 0.418410\n",
      "batch 336 g1_loss : 0.544040\n",
      "batch 336 g_loss : 1.226595\n",
      "batch 337 d_loss : 0.410898\n",
      "batch 337 g1_loss : 0.533661\n",
      "batch 337 g_loss : 1.230153\n",
      "batch 338 d_loss : 0.429619\n",
      "batch 338 g1_loss : 0.535487\n",
      "batch 338 g_loss : 1.121121\n",
      "batch 339 d_loss : 0.421327\n",
      "batch 339 g1_loss : 0.523253\n",
      "batch 339 g_loss : 1.262511\n",
      "batch 340 d_loss : 0.467462\n",
      "batch 340 g1_loss : 0.514586\n",
      "batch 340 g_loss : 1.192538\n",
      "batch 341 d_loss : 0.410769\n",
      "batch 341 g1_loss : 0.523700\n",
      "batch 341 g_loss : 1.150450\n",
      "batch 342 d_loss : 0.442916\n",
      "batch 342 g1_loss : 0.517104\n",
      "batch 342 g_loss : 1.168983\n",
      "batch 343 d_loss : 0.446447\n",
      "batch 343 g1_loss : 0.536227\n",
      "batch 343 g_loss : 1.137073\n",
      "batch 344 d_loss : 0.524440\n",
      "batch 344 g1_loss : 0.543388\n",
      "batch 344 g_loss : 1.103741\n",
      "batch 345 d_loss : 0.461935\n",
      "batch 345 g1_loss : 0.531453\n",
      "batch 345 g_loss : 1.047356\n",
      "batch 346 d_loss : 0.482936\n",
      "batch 346 g1_loss : 0.537039\n",
      "batch 346 g_loss : 1.052469\n",
      "batch 347 d_loss : 0.450734\n",
      "batch 347 g1_loss : 0.522490\n",
      "batch 347 g_loss : 1.128272\n",
      "batch 348 d_loss : 0.436151\n",
      "batch 348 g1_loss : 0.521191\n",
      "batch 348 g_loss : 1.147269\n",
      "batch 349 d_loss : 0.460524\n",
      "batch 349 g1_loss : 0.533652\n",
      "batch 349 g_loss : 1.176827\n",
      "batch 350 d_loss : 0.486070\n",
      "batch 350 g1_loss : 0.512983\n",
      "batch 350 g_loss : 1.150653\n",
      "batch 351 d_loss : 0.438838\n",
      "batch 351 g1_loss : 0.529688\n",
      "batch 351 g_loss : 1.152532\n",
      "batch 352 d_loss : 0.459217\n",
      "batch 352 g1_loss : 0.534884\n",
      "batch 352 g_loss : 1.156164\n",
      "batch 353 d_loss : 0.455927\n",
      "batch 353 g1_loss : 0.526240\n",
      "batch 353 g_loss : 1.203463\n",
      "batch 354 d_loss : 0.458625\n",
      "batch 354 g1_loss : 0.528452\n",
      "batch 354 g_loss : 1.133699\n",
      "batch 355 d_loss : 0.473140\n",
      "batch 355 g1_loss : 0.513344\n",
      "batch 355 g_loss : 1.098745\n",
      "batch 356 d_loss : 0.435059\n",
      "batch 356 g1_loss : 0.528528\n",
      "batch 356 g_loss : 1.139696\n",
      "batch 357 d_loss : 0.470567\n",
      "batch 357 g1_loss : 0.515002\n",
      "batch 357 g_loss : 1.141087\n",
      "batch 358 d_loss : 0.452020\n",
      "batch 358 g1_loss : 0.531829\n",
      "batch 358 g_loss : 1.067110\n",
      "batch 359 d_loss : 0.526822\n",
      "batch 359 g1_loss : 0.516297\n",
      "batch 359 g_loss : 0.998069\n",
      "batch 360 d_loss : 0.471150\n",
      "batch 360 g1_loss : 0.523208\n",
      "batch 360 g_loss : 1.033849\n",
      "batch 361 d_loss : 0.475952\n",
      "batch 361 g1_loss : 0.525867\n",
      "batch 361 g_loss : 1.089449\n",
      "batch 362 d_loss : 0.461444\n",
      "batch 362 g1_loss : 0.521748\n",
      "batch 362 g_loss : 1.094591\n",
      "batch 363 d_loss : 0.443892\n",
      "batch 363 g1_loss : 0.516210\n",
      "batch 363 g_loss : 1.132047\n",
      "batch 364 d_loss : 0.445282\n",
      "batch 364 g1_loss : 0.533090\n",
      "batch 364 g_loss : 1.188330\n",
      "batch 365 d_loss : 0.421014\n",
      "batch 365 g1_loss : 0.534884\n",
      "batch 365 g_loss : 1.290304\n",
      "batch 366 d_loss : 0.438777\n",
      "batch 366 g1_loss : 0.523084\n",
      "batch 366 g_loss : 1.267349\n",
      "batch 367 d_loss : 0.500536\n",
      "batch 367 g1_loss : 0.514023\n",
      "batch 367 g_loss : 1.186360\n",
      "batch 368 d_loss : 0.460621\n",
      "batch 368 g1_loss : 0.529560\n",
      "batch 368 g_loss : 1.111155\n",
      "batch 369 d_loss : 0.449235\n",
      "batch 369 g1_loss : 0.518101\n",
      "batch 369 g_loss : 1.052924\n",
      "batch 370 d_loss : 0.498881\n",
      "batch 370 g1_loss : 0.527891\n",
      "batch 370 g_loss : 1.039036\n",
      "batch 371 d_loss : 0.486321\n",
      "batch 371 g1_loss : 0.499714\n",
      "batch 371 g_loss : 1.081261\n",
      "batch 372 d_loss : 0.437065\n",
      "batch 372 g1_loss : 0.537044\n",
      "batch 372 g_loss : 1.176944\n",
      "batch 373 d_loss : 0.445500\n",
      "batch 373 g1_loss : 0.521032\n",
      "batch 373 g_loss : 1.250437\n",
      "batch 374 d_loss : 0.461881\n",
      "batch 374 g1_loss : 0.514002\n",
      "batch 374 g_loss : 1.227053\n",
      "batch 375 d_loss : 0.432571\n",
      "batch 375 g1_loss : 0.510605\n",
      "batch 375 g_loss : 1.247535\n",
      "batch 376 d_loss : 0.428337\n",
      "batch 376 g1_loss : 0.522955\n",
      "batch 376 g_loss : 1.202484\n",
      "batch 377 d_loss : 0.484541\n",
      "batch 377 g1_loss : 0.527390\n",
      "batch 377 g_loss : 1.179389\n",
      "batch 378 d_loss : 0.439431\n",
      "batch 378 g1_loss : 0.507404\n",
      "batch 378 g_loss : 1.108077\n",
      "batch 379 d_loss : 0.451573\n",
      "batch 379 g1_loss : 0.509369\n",
      "batch 379 g_loss : 1.192729\n",
      "batch 380 d_loss : 0.412875\n",
      "batch 380 g1_loss : 0.520306\n",
      "batch 380 g_loss : 1.171463\n",
      "batch 381 d_loss : 0.414941\n",
      "batch 381 g1_loss : 0.522099\n",
      "batch 381 g_loss : 1.196204\n",
      "batch 382 d_loss : 0.469638\n",
      "batch 382 g1_loss : 0.525912\n",
      "batch 382 g_loss : 1.140995\n",
      "batch 383 d_loss : 0.552764\n",
      "batch 383 g1_loss : 0.544340\n",
      "batch 383 g_loss : 1.039518\n",
      "batch 384 d_loss : 0.486647\n",
      "batch 384 g1_loss : 0.523191\n",
      "batch 384 g_loss : 1.032143\n",
      "batch 385 d_loss : 0.411327\n",
      "batch 385 g1_loss : 0.512999\n",
      "batch 385 g_loss : 1.157490\n",
      "batch 386 d_loss : 0.509430\n",
      "batch 386 g1_loss : 0.517002\n",
      "batch 386 g_loss : 1.052684\n",
      "batch 387 d_loss : 0.517390\n",
      "batch 387 g1_loss : 0.526569\n",
      "batch 387 g_loss : 1.096402\n",
      "batch 388 d_loss : 0.423662\n",
      "batch 388 g1_loss : 0.523391\n",
      "batch 388 g_loss : 1.173521\n",
      "batch 389 d_loss : 0.494910\n",
      "batch 389 g1_loss : 0.512527\n",
      "batch 389 g_loss : 1.123127\n",
      "batch 390 d_loss : 0.487414\n",
      "batch 390 g1_loss : 0.522907\n",
      "batch 390 g_loss : 1.081926\n",
      "batch 391 d_loss : 0.434054\n",
      "batch 391 g1_loss : 0.509860\n",
      "batch 391 g_loss : 1.045980\n",
      "batch 392 d_loss : 0.424490\n",
      "batch 392 g1_loss : 0.507001\n",
      "batch 392 g_loss : 1.148299\n",
      "batch 393 d_loss : 0.487059\n",
      "batch 393 g1_loss : 0.533794\n",
      "batch 393 g_loss : 1.107991\n",
      "batch 394 d_loss : 0.486822\n",
      "batch 394 g1_loss : 0.543418\n",
      "batch 394 g_loss : 1.100490\n",
      "batch 395 d_loss : 0.454877\n",
      "batch 395 g1_loss : 0.509156\n",
      "batch 395 g_loss : 1.117025\n",
      "batch 396 d_loss : 0.389776\n",
      "batch 396 g1_loss : 0.526768\n",
      "batch 396 g_loss : 1.177900\n",
      "batch 397 d_loss : 0.443070\n",
      "batch 397 g1_loss : 0.521433\n",
      "batch 397 g_loss : 1.246289\n",
      "batch 398 d_loss : 0.409029\n",
      "batch 398 g1_loss : 0.520532\n",
      "batch 398 g_loss : 1.243617\n",
      "batch 399 d_loss : 0.473220\n",
      "batch 399 g1_loss : 0.544230\n",
      "batch 399 g_loss : 1.290849\n",
      "batch 400 d_loss : 0.473978\n",
      "batch 400 g1_loss : 0.530429\n",
      "batch 400 g_loss : 1.234722\n",
      "batch 401 d_loss : 0.436360\n",
      "batch 401 g1_loss : 0.540065\n",
      "batch 401 g_loss : 1.210665\n",
      "batch 402 d_loss : 0.451447\n",
      "batch 402 g1_loss : 0.541291\n",
      "batch 402 g_loss : 1.189452\n",
      "batch 403 d_loss : 0.443343\n",
      "batch 403 g1_loss : 0.534103\n",
      "batch 403 g_loss : 1.107563\n",
      "batch 404 d_loss : 0.478743\n",
      "batch 404 g1_loss : 0.525245\n",
      "batch 404 g_loss : 1.055486\n",
      "batch 405 d_loss : 0.413433\n",
      "batch 405 g1_loss : 0.534198\n",
      "batch 405 g_loss : 1.138388\n",
      "batch 406 d_loss : 0.485737\n",
      "batch 406 g1_loss : 0.550366\n",
      "batch 406 g_loss : 1.045818\n",
      "batch 407 d_loss : 0.536159\n",
      "batch 407 g1_loss : 0.539328\n",
      "batch 407 g_loss : 0.956676\n",
      "batch 408 d_loss : 0.428419\n",
      "batch 408 g1_loss : 0.534014\n",
      "batch 408 g_loss : 1.079512\n",
      "batch 409 d_loss : 0.440681\n",
      "batch 409 g1_loss : 0.544336\n",
      "batch 409 g_loss : 1.143924\n",
      "batch 410 d_loss : 0.393406\n",
      "batch 410 g1_loss : 0.522638\n",
      "batch 410 g_loss : 1.296376\n",
      "batch 411 d_loss : 0.477707\n",
      "batch 411 g1_loss : 0.559072\n",
      "batch 411 g_loss : 1.213407\n",
      "batch 412 d_loss : 0.448693\n",
      "batch 412 g1_loss : 0.537669\n",
      "batch 412 g_loss : 1.190989\n",
      "batch 413 d_loss : 0.408469\n",
      "batch 413 g1_loss : 0.544232\n",
      "batch 413 g_loss : 1.181542\n",
      "batch 414 d_loss : 0.406619\n",
      "batch 414 g1_loss : 0.551418\n",
      "batch 414 g_loss : 1.197627\n",
      "batch 415 d_loss : 0.450420\n",
      "batch 415 g1_loss : 0.529621\n",
      "batch 415 g_loss : 1.221425\n",
      "batch 416 d_loss : 0.454330\n",
      "batch 416 g1_loss : 0.566534\n",
      "batch 416 g_loss : 1.125449\n",
      "batch 417 d_loss : 0.464902\n",
      "batch 417 g1_loss : 0.543439\n",
      "batch 417 g_loss : 1.164680\n",
      "batch 418 d_loss : 0.466156\n",
      "batch 418 g1_loss : 0.556765\n",
      "batch 418 g_loss : 1.130631\n",
      "batch 419 d_loss : 0.429310\n",
      "batch 419 g1_loss : 0.555027\n",
      "batch 419 g_loss : 1.162996\n",
      "batch 420 d_loss : 0.412517\n",
      "batch 420 g1_loss : 0.560077\n",
      "batch 420 g_loss : 1.259580\n",
      "batch 421 d_loss : 0.441323\n",
      "batch 421 g1_loss : 0.561779\n",
      "batch 421 g_loss : 1.116115\n",
      "batch 422 d_loss : 0.450543\n",
      "batch 422 g1_loss : 0.568495\n",
      "batch 422 g_loss : 1.224262\n",
      "batch 423 d_loss : 0.415677\n",
      "batch 423 g1_loss : 0.550795\n",
      "batch 423 g_loss : 1.178729\n",
      "batch 424 d_loss : 0.424057\n",
      "batch 424 g1_loss : 0.576360\n",
      "batch 424 g_loss : 1.098710\n",
      "batch 425 d_loss : 0.429855\n",
      "batch 425 g1_loss : 0.565374\n",
      "batch 425 g_loss : 1.192288\n",
      "batch 426 d_loss : 0.402941\n",
      "batch 426 g1_loss : 0.556196\n",
      "batch 426 g_loss : 1.255623\n",
      "batch 427 d_loss : 0.418767\n",
      "batch 427 g1_loss : 0.552335\n",
      "batch 427 g_loss : 1.275759\n",
      "batch 428 d_loss : 0.475970\n",
      "batch 428 g1_loss : 0.546207\n",
      "batch 428 g_loss : 1.244233\n",
      "batch 429 d_loss : 0.476424\n",
      "batch 429 g1_loss : 0.576694\n",
      "batch 429 g_loss : 1.064186\n",
      "batch 430 d_loss : 0.426643\n",
      "batch 430 g1_loss : 0.534342\n",
      "batch 430 g_loss : 1.106206\n",
      "batch 431 d_loss : 0.417712\n",
      "batch 431 g1_loss : 0.542597\n",
      "batch 431 g_loss : 1.154552\n",
      "batch 432 d_loss : 0.418561\n",
      "batch 432 g1_loss : 0.540718\n",
      "batch 432 g_loss : 1.218370\n",
      "batch 433 d_loss : 0.434375\n",
      "batch 433 g1_loss : 0.565578\n",
      "batch 433 g_loss : 1.219700\n",
      "batch 434 d_loss : 0.467305\n",
      "batch 434 g1_loss : 0.538708\n",
      "batch 434 g_loss : 1.232111\n",
      "batch 435 d_loss : 0.425250\n",
      "batch 435 g1_loss : 0.539584\n",
      "batch 435 g_loss : 1.237537\n",
      "batch 436 d_loss : 0.387940\n",
      "batch 436 g1_loss : 0.575690\n",
      "batch 436 g_loss : 1.264751\n",
      "batch 437 d_loss : 0.422098\n",
      "batch 437 g1_loss : 0.557967\n",
      "batch 437 g_loss : 1.165519\n",
      "batch 438 d_loss : 0.436945\n",
      "batch 438 g1_loss : 0.570464\n",
      "batch 438 g_loss : 1.124173\n",
      "batch 439 d_loss : 0.436822\n",
      "batch 439 g1_loss : 0.553232\n",
      "batch 439 g_loss : 1.073093\n",
      "batch 440 d_loss : 0.425192\n",
      "batch 440 g1_loss : 0.538108\n",
      "batch 440 g_loss : 1.115041\n",
      "batch 441 d_loss : 0.490204\n",
      "batch 441 g1_loss : 0.557013\n",
      "batch 441 g_loss : 1.068639\n",
      "batch 442 d_loss : 0.501575\n",
      "batch 442 g1_loss : 0.548663\n",
      "batch 442 g_loss : 1.121805\n",
      "batch 443 d_loss : 0.438471\n",
      "batch 443 g1_loss : 0.544924\n",
      "batch 443 g_loss : 1.158351\n",
      "batch 444 d_loss : 0.424280\n",
      "batch 444 g1_loss : 0.551765\n",
      "batch 444 g_loss : 1.195727\n",
      "batch 445 d_loss : 0.453847\n",
      "batch 445 g1_loss : 0.542934\n",
      "batch 445 g_loss : 1.108019\n",
      "batch 446 d_loss : 0.418017\n",
      "batch 446 g1_loss : 0.551334\n",
      "batch 446 g_loss : 1.083961\n",
      "batch 447 d_loss : 0.419953\n",
      "batch 447 g1_loss : 0.565610\n",
      "batch 447 g_loss : 1.093700\n",
      "batch 448 d_loss : 0.423096\n",
      "batch 448 g1_loss : 0.544656\n",
      "batch 448 g_loss : 1.132535\n",
      "batch 449 d_loss : 0.425661\n",
      "batch 449 g1_loss : 0.553308\n",
      "batch 449 g_loss : 1.208425\n",
      "batch 450 d_loss : 0.404349\n",
      "batch 450 g1_loss : 0.571682\n",
      "batch 450 g_loss : 1.209880\n",
      "batch 451 d_loss : 0.410899\n",
      "batch 451 g1_loss : 0.541766\n",
      "batch 451 g_loss : 1.207448\n",
      "batch 452 d_loss : 0.449073\n",
      "batch 452 g1_loss : 0.532438\n",
      "batch 452 g_loss : 1.138497\n",
      "batch 453 d_loss : 0.409023\n",
      "batch 453 g1_loss : 0.567316\n",
      "batch 453 g_loss : 1.125978\n",
      "batch 454 d_loss : 0.412485\n",
      "batch 454 g1_loss : 0.580806\n",
      "batch 454 g_loss : 1.062261\n",
      "batch 455 d_loss : 0.414626\n",
      "batch 455 g1_loss : 0.577896\n",
      "batch 455 g_loss : 1.198712\n",
      "batch 456 d_loss : 0.440271\n",
      "batch 456 g1_loss : 0.552951\n",
      "batch 456 g_loss : 1.261161\n",
      "batch 457 d_loss : 0.419157\n",
      "batch 457 g1_loss : 0.559846\n",
      "batch 457 g_loss : 1.188322\n",
      "batch 458 d_loss : 0.358673\n",
      "batch 458 g1_loss : 0.538427\n",
      "batch 458 g_loss : 1.211383\n",
      "batch 459 d_loss : 0.431631\n",
      "batch 459 g1_loss : 0.572734\n",
      "batch 459 g_loss : 1.220466\n",
      "batch 460 d_loss : 0.400795\n",
      "batch 460 g1_loss : 0.540023\n",
      "batch 460 g_loss : 1.338821\n",
      "batch 461 d_loss : 0.344778\n",
      "batch 461 g1_loss : 0.543915\n",
      "batch 461 g_loss : 1.384102\n",
      "batch 462 d_loss : 0.364909\n",
      "batch 462 g1_loss : 0.564647\n",
      "batch 462 g_loss : 1.348366\n",
      "batch 463 d_loss : 0.392440\n",
      "batch 463 g1_loss : 0.551861\n",
      "batch 463 g_loss : 1.433438\n",
      "batch 464 d_loss : 0.415791\n",
      "batch 464 g1_loss : 0.556372\n",
      "batch 464 g_loss : 1.387225\n",
      "batch 465 d_loss : 0.364168\n",
      "batch 465 g1_loss : 0.549698\n",
      "batch 465 g_loss : 1.386770\n",
      "batch 466 d_loss : 0.428496\n",
      "batch 466 g1_loss : 0.544807\n",
      "batch 466 g_loss : 1.296832\n",
      "batch 467 d_loss : 0.414084\n",
      "batch 467 g1_loss : 0.563919\n",
      "batch 467 g_loss : 1.268008\n",
      "('Epoch is', 2)\n",
      "('Number of batches', 468)\n",
      "batch 0 d_loss : 0.420999\n",
      "batch 0 g1_loss : 0.542101\n",
      "batch 0 g_loss : 1.121367\n",
      "batch 1 d_loss : 0.450405\n",
      "batch 1 g1_loss : 0.556398\n",
      "batch 1 g_loss : 1.192792\n",
      "batch 2 d_loss : 0.394837\n",
      "batch 2 g1_loss : 0.541959\n",
      "batch 2 g_loss : 1.207009\n",
      "batch 3 d_loss : 0.457450\n",
      "batch 3 g1_loss : 0.568253\n",
      "batch 3 g_loss : 1.150903\n",
      "batch 4 d_loss : 0.457642\n",
      "batch 4 g1_loss : 0.579188\n",
      "batch 4 g_loss : 1.120807\n",
      "batch 5 d_loss : 0.417090\n",
      "batch 5 g1_loss : 0.545867\n",
      "batch 5 g_loss : 1.135394\n",
      "batch 6 d_loss : 0.428162\n",
      "batch 6 g1_loss : 0.532644\n",
      "batch 6 g_loss : 1.213517\n",
      "batch 7 d_loss : 0.440540\n",
      "batch 7 g1_loss : 0.542656\n",
      "batch 7 g_loss : 1.218451\n",
      "batch 8 d_loss : 0.439807\n",
      "batch 8 g1_loss : 0.550574\n",
      "batch 8 g_loss : 1.165498\n",
      "batch 9 d_loss : 0.460160\n",
      "batch 9 g1_loss : 0.564863\n",
      "batch 9 g_loss : 1.145058\n",
      "batch 10 d_loss : 0.417299\n",
      "batch 10 g1_loss : 0.558412\n",
      "batch 10 g_loss : 1.323558\n",
      "batch 11 d_loss : 0.483188\n",
      "batch 11 g1_loss : 0.554071\n",
      "batch 11 g_loss : 1.198496\n",
      "batch 12 d_loss : 0.433847\n",
      "batch 12 g1_loss : 0.558024\n",
      "batch 12 g_loss : 1.197908\n",
      "batch 13 d_loss : 0.412408\n",
      "batch 13 g1_loss : 0.543658\n",
      "batch 13 g_loss : 1.324477\n",
      "batch 14 d_loss : 0.471453\n",
      "batch 14 g1_loss : 0.547570\n",
      "batch 14 g_loss : 1.209238\n",
      "batch 15 d_loss : 0.428154\n",
      "batch 15 g1_loss : 0.562225\n",
      "batch 15 g_loss : 1.201822\n",
      "batch 16 d_loss : 0.385833\n",
      "batch 16 g1_loss : 0.550232\n",
      "batch 16 g_loss : 1.279364\n",
      "batch 17 d_loss : 0.398098\n",
      "batch 17 g1_loss : 0.544173\n",
      "batch 17 g_loss : 1.301632\n",
      "batch 18 d_loss : 0.415671\n",
      "batch 18 g1_loss : 0.535762\n",
      "batch 18 g_loss : 1.227379\n",
      "batch 19 d_loss : 0.410826\n",
      "batch 19 g1_loss : 0.559466\n",
      "batch 19 g_loss : 1.223117\n",
      "batch 20 d_loss : 0.394111\n",
      "batch 20 g1_loss : 0.567771\n",
      "batch 20 g_loss : 1.293168\n",
      "batch 21 d_loss : 0.493088\n",
      "batch 21 g1_loss : 0.555840\n",
      "batch 21 g_loss : 1.105946\n",
      "batch 22 d_loss : 0.456652\n",
      "batch 22 g1_loss : 0.561675\n",
      "batch 22 g_loss : 1.180696\n",
      "batch 23 d_loss : 0.406689\n",
      "batch 23 g1_loss : 0.547283\n",
      "batch 23 g_loss : 1.254941\n",
      "batch 24 d_loss : 0.348836\n",
      "batch 24 g1_loss : 0.533683\n",
      "batch 24 g_loss : 1.308027\n",
      "batch 25 d_loss : 0.393150\n",
      "batch 25 g1_loss : 0.556938\n",
      "batch 25 g_loss : 1.263593\n",
      "batch 26 d_loss : 0.412654\n",
      "batch 26 g1_loss : 0.543941\n",
      "batch 26 g_loss : 1.232320\n",
      "batch 27 d_loss : 0.425308\n",
      "batch 27 g1_loss : 0.563740\n",
      "batch 27 g_loss : 1.148651\n",
      "batch 28 d_loss : 0.448934\n",
      "batch 28 g1_loss : 0.538339\n",
      "batch 28 g_loss : 1.149872\n",
      "batch 29 d_loss : 0.443108\n",
      "batch 29 g1_loss : 0.536745\n",
      "batch 29 g_loss : 1.148990\n",
      "batch 30 d_loss : 0.371057\n",
      "batch 30 g1_loss : 0.581527\n",
      "batch 30 g_loss : 1.294182\n",
      "batch 31 d_loss : 0.400324\n",
      "batch 31 g1_loss : 0.572303\n",
      "batch 31 g_loss : 1.313392\n",
      "batch 32 d_loss : 0.443363\n",
      "batch 32 g1_loss : 0.543258\n",
      "batch 32 g_loss : 1.150712\n",
      "batch 33 d_loss : 0.375197\n",
      "batch 33 g1_loss : 0.567769\n",
      "batch 33 g_loss : 1.179849\n",
      "batch 34 d_loss : 0.422913\n",
      "batch 34 g1_loss : 0.564054\n",
      "batch 34 g_loss : 1.246680\n",
      "batch 35 d_loss : 0.417615\n",
      "batch 35 g1_loss : 0.556801\n",
      "batch 35 g_loss : 1.240800\n",
      "batch 36 d_loss : 0.439732\n",
      "batch 36 g1_loss : 0.540017\n",
      "batch 36 g_loss : 1.157450\n",
      "batch 37 d_loss : 0.481537\n",
      "batch 37 g1_loss : 0.543893\n",
      "batch 37 g_loss : 1.253257\n",
      "batch 38 d_loss : 0.407486\n",
      "batch 38 g1_loss : 0.551824\n",
      "batch 38 g_loss : 1.269344\n",
      "batch 39 d_loss : 0.416164\n",
      "batch 39 g1_loss : 0.553332\n",
      "batch 39 g_loss : 1.241433\n",
      "batch 40 d_loss : 0.384613\n",
      "batch 40 g1_loss : 0.549379\n",
      "batch 40 g_loss : 1.318124\n",
      "batch 41 d_loss : 0.436562\n",
      "batch 41 g1_loss : 0.559835\n",
      "batch 41 g_loss : 1.291087\n",
      "batch 42 d_loss : 0.395165\n",
      "batch 42 g1_loss : 0.571556\n",
      "batch 42 g_loss : 1.253798\n",
      "batch 43 d_loss : 0.369186\n",
      "batch 43 g1_loss : 0.518719\n",
      "batch 43 g_loss : 1.372562\n",
      "batch 44 d_loss : 0.402981\n",
      "batch 44 g1_loss : 0.553345\n",
      "batch 44 g_loss : 1.285632\n",
      "batch 45 d_loss : 0.399472\n",
      "batch 45 g1_loss : 0.544099\n",
      "batch 45 g_loss : 1.209453\n",
      "batch 46 d_loss : 0.403410\n",
      "batch 46 g1_loss : 0.541935\n",
      "batch 46 g_loss : 1.280172\n",
      "batch 47 d_loss : 0.419855\n",
      "batch 47 g1_loss : 0.569938\n",
      "batch 47 g_loss : 1.230190\n",
      "batch 48 d_loss : 0.400468\n",
      "batch 48 g1_loss : 0.543296\n",
      "batch 48 g_loss : 1.223162\n",
      "batch 49 d_loss : 0.379380\n",
      "batch 49 g1_loss : 0.518030\n",
      "batch 49 g_loss : 1.290622\n",
      "batch 50 d_loss : 0.395301\n",
      "batch 50 g1_loss : 0.531737\n",
      "batch 50 g_loss : 1.255829\n",
      "batch 51 d_loss : 0.355268\n",
      "batch 51 g1_loss : 0.531868\n",
      "batch 51 g_loss : 1.304411\n",
      "batch 52 d_loss : 0.436251\n",
      "batch 52 g1_loss : 0.552537\n",
      "batch 52 g_loss : 1.235612\n",
      "batch 53 d_loss : 0.436195\n",
      "batch 53 g1_loss : 0.558080\n",
      "batch 53 g_loss : 1.087196\n",
      "batch 54 d_loss : 0.399428\n",
      "batch 54 g1_loss : 0.573416\n",
      "batch 54 g_loss : 1.146640\n",
      "batch 55 d_loss : 0.387192\n",
      "batch 55 g1_loss : 0.582293\n",
      "batch 55 g_loss : 1.240961\n",
      "batch 56 d_loss : 0.455668\n",
      "batch 56 g1_loss : 0.574474\n",
      "batch 56 g_loss : 1.126746\n",
      "batch 57 d_loss : 0.462920\n",
      "batch 57 g1_loss : 0.584169\n",
      "batch 57 g_loss : 0.998883\n",
      "batch 58 d_loss : 0.391556\n",
      "batch 58 g1_loss : 0.552300\n",
      "batch 58 g_loss : 1.218213\n",
      "batch 59 d_loss : 0.425171\n",
      "batch 59 g1_loss : 0.549532\n",
      "batch 59 g_loss : 1.262946\n",
      "batch 60 d_loss : 0.401360\n",
      "batch 60 g1_loss : 0.542936\n",
      "batch 60 g_loss : 1.231506\n",
      "batch 61 d_loss : 0.456399\n",
      "batch 61 g1_loss : 0.543464\n",
      "batch 61 g_loss : 1.209556\n",
      "batch 62 d_loss : 0.442907\n",
      "batch 62 g1_loss : 0.545620\n",
      "batch 62 g_loss : 1.250204\n",
      "batch 63 d_loss : 0.386688\n",
      "batch 63 g1_loss : 0.542993\n",
      "batch 63 g_loss : 1.261816\n",
      "batch 64 d_loss : 0.404379\n",
      "batch 64 g1_loss : 0.557074\n",
      "batch 64 g_loss : 1.248813\n",
      "batch 65 d_loss : 0.436828\n",
      "batch 65 g1_loss : 0.544528\n",
      "batch 65 g_loss : 1.176085\n",
      "batch 66 d_loss : 0.452957\n",
      "batch 66 g1_loss : 0.542701\n",
      "batch 66 g_loss : 1.228907\n",
      "batch 67 d_loss : 0.420345\n",
      "batch 67 g1_loss : 0.540314\n",
      "batch 67 g_loss : 1.283172\n",
      "batch 68 d_loss : 0.395069\n",
      "batch 68 g1_loss : 0.549640\n",
      "batch 68 g_loss : 1.328829\n",
      "batch 69 d_loss : 0.425565\n",
      "batch 69 g1_loss : 0.538852\n",
      "batch 69 g_loss : 1.306866\n",
      "batch 70 d_loss : 0.383371\n",
      "batch 70 g1_loss : 0.580077\n",
      "batch 70 g_loss : 1.304686\n",
      "batch 71 d_loss : 0.389788\n",
      "batch 71 g1_loss : 0.551636\n",
      "batch 71 g_loss : 1.254527\n",
      "batch 72 d_loss : 0.404489\n",
      "batch 72 g1_loss : 0.548628\n",
      "batch 72 g_loss : 1.229614\n",
      "batch 73 d_loss : 0.423194\n",
      "batch 73 g1_loss : 0.553892\n",
      "batch 73 g_loss : 1.231063\n",
      "batch 74 d_loss : 0.406440\n",
      "batch 74 g1_loss : 0.532702\n",
      "batch 74 g_loss : 1.264565\n",
      "batch 75 d_loss : 0.426363\n",
      "batch 75 g1_loss : 0.570271\n",
      "batch 75 g_loss : 1.237112\n",
      "batch 76 d_loss : 0.351818\n",
      "batch 76 g1_loss : 0.538036\n",
      "batch 76 g_loss : 1.251281\n",
      "batch 77 d_loss : 0.377429\n",
      "batch 77 g1_loss : 0.525072\n",
      "batch 77 g_loss : 1.368276\n",
      "batch 78 d_loss : 0.361778\n",
      "batch 78 g1_loss : 0.542371\n",
      "batch 78 g_loss : 1.319102\n",
      "batch 79 d_loss : 0.389520\n",
      "batch 79 g1_loss : 0.553943\n",
      "batch 79 g_loss : 1.360878\n",
      "batch 80 d_loss : 0.397827\n",
      "batch 80 g1_loss : 0.543088\n",
      "batch 80 g_loss : 1.402907\n",
      "batch 81 d_loss : 0.324865\n",
      "batch 81 g1_loss : 0.545896\n",
      "batch 81 g_loss : 1.420276\n",
      "batch 82 d_loss : 0.385532\n",
      "batch 82 g1_loss : 0.548272\n",
      "batch 82 g_loss : 1.371725\n",
      "batch 83 d_loss : 0.412582\n",
      "batch 83 g1_loss : 0.518065\n",
      "batch 83 g_loss : 1.144377\n",
      "batch 84 d_loss : 0.380076\n",
      "batch 84 g1_loss : 0.537870\n",
      "batch 84 g_loss : 1.301625\n",
      "batch 85 d_loss : 0.407104\n",
      "batch 85 g1_loss : 0.551157\n",
      "batch 85 g_loss : 1.244877\n",
      "batch 86 d_loss : 0.381111\n",
      "batch 86 g1_loss : 0.519238\n",
      "batch 86 g_loss : 1.299022\n",
      "batch 87 d_loss : 0.338174\n",
      "batch 87 g1_loss : 0.521747\n",
      "batch 87 g_loss : 1.421793\n",
      "batch 88 d_loss : 0.385686\n",
      "batch 88 g1_loss : 0.551156\n",
      "batch 88 g_loss : 1.391162\n",
      "batch 89 d_loss : 0.402675\n",
      "batch 89 g1_loss : 0.544194\n",
      "batch 89 g_loss : 1.218027\n",
      "batch 90 d_loss : 0.425344\n",
      "batch 90 g1_loss : 0.547094\n",
      "batch 90 g_loss : 1.123729\n",
      "batch 91 d_loss : 0.413679\n",
      "batch 91 g1_loss : 0.552082\n",
      "batch 91 g_loss : 1.172444\n",
      "batch 92 d_loss : 0.377714\n",
      "batch 92 g1_loss : 0.545818\n",
      "batch 92 g_loss : 1.350548\n",
      "batch 93 d_loss : 0.387201\n",
      "batch 93 g1_loss : 0.545828\n",
      "batch 93 g_loss : 1.385988\n",
      "batch 94 d_loss : 0.407784\n",
      "batch 94 g1_loss : 0.560913\n",
      "batch 94 g_loss : 1.304822\n",
      "batch 95 d_loss : 0.415101\n",
      "batch 95 g1_loss : 0.568044\n",
      "batch 95 g_loss : 1.318047\n",
      "batch 96 d_loss : 0.442439\n",
      "batch 96 g1_loss : 0.552019\n",
      "batch 96 g_loss : 1.130884\n",
      "batch 97 d_loss : 0.392130\n",
      "batch 97 g1_loss : 0.555924\n",
      "batch 97 g_loss : 1.143900\n",
      "batch 98 d_loss : 0.370563\n",
      "batch 98 g1_loss : 0.552925\n",
      "batch 98 g_loss : 1.333683\n",
      "batch 99 d_loss : 0.399727\n",
      "batch 99 g1_loss : 0.541367\n",
      "batch 99 g_loss : 1.330168\n",
      "batch 100 d_loss : 0.404798\n",
      "batch 100 g1_loss : 0.550297\n",
      "batch 100 g_loss : 1.223366\n",
      "batch 101 d_loss : 0.453539\n",
      "batch 101 g1_loss : 0.556314\n",
      "batch 101 g_loss : 1.213737\n",
      "batch 102 d_loss : 0.418335\n",
      "batch 102 g1_loss : 0.556267\n",
      "batch 102 g_loss : 1.256793\n",
      "batch 103 d_loss : 0.422374\n",
      "batch 103 g1_loss : 0.551259\n",
      "batch 103 g_loss : 1.241732\n",
      "batch 104 d_loss : 0.390933\n",
      "batch 104 g1_loss : 0.526652\n",
      "batch 104 g_loss : 1.431644\n",
      "batch 105 d_loss : 0.346672\n",
      "batch 105 g1_loss : 0.546692\n",
      "batch 105 g_loss : 1.446377\n",
      "batch 106 d_loss : 0.432081\n",
      "batch 106 g1_loss : 0.544068\n",
      "batch 106 g_loss : 1.193199\n",
      "batch 107 d_loss : 0.414902\n",
      "batch 107 g1_loss : 0.572349\n",
      "batch 107 g_loss : 1.161532\n",
      "batch 108 d_loss : 0.441818\n",
      "batch 108 g1_loss : 0.556620\n",
      "batch 108 g_loss : 1.187152\n",
      "batch 109 d_loss : 0.456237\n",
      "batch 109 g1_loss : 0.541431\n",
      "batch 109 g_loss : 1.162956\n",
      "batch 110 d_loss : 0.495430\n",
      "batch 110 g1_loss : 0.558969\n",
      "batch 110 g_loss : 1.157491\n",
      "batch 111 d_loss : 0.431582\n",
      "batch 111 g1_loss : 0.548758\n",
      "batch 111 g_loss : 1.170782\n",
      "batch 112 d_loss : 0.391497\n",
      "batch 112 g1_loss : 0.557709\n",
      "batch 112 g_loss : 1.285829\n",
      "batch 113 d_loss : 0.460682\n",
      "batch 113 g1_loss : 0.565774\n",
      "batch 113 g_loss : 1.234473\n",
      "batch 114 d_loss : 0.483463\n",
      "batch 114 g1_loss : 0.538489\n",
      "batch 114 g_loss : 1.133750\n",
      "batch 115 d_loss : 0.552513\n",
      "batch 115 g1_loss : 0.552386\n",
      "batch 115 g_loss : 1.011993\n",
      "batch 116 d_loss : 0.415438\n",
      "batch 116 g1_loss : 0.558966\n",
      "batch 116 g_loss : 1.155407\n",
      "batch 117 d_loss : 0.376560\n",
      "batch 117 g1_loss : 0.538350\n",
      "batch 117 g_loss : 1.389318\n",
      "batch 118 d_loss : 0.411858\n",
      "batch 118 g1_loss : 0.546387\n",
      "batch 118 g_loss : 1.300563\n",
      "batch 119 d_loss : 0.349368\n",
      "batch 119 g1_loss : 0.547629\n",
      "batch 119 g_loss : 1.300246\n",
      "batch 120 d_loss : 0.438106\n",
      "batch 120 g1_loss : 0.560426\n",
      "batch 120 g_loss : 1.214856\n",
      "batch 121 d_loss : 0.430641\n",
      "batch 121 g1_loss : 0.552528\n",
      "batch 121 g_loss : 1.168173\n",
      "batch 122 d_loss : 0.374654\n",
      "batch 122 g1_loss : 0.548573\n",
      "batch 122 g_loss : 1.191071\n",
      "batch 123 d_loss : 0.417346\n",
      "batch 123 g1_loss : 0.556508\n",
      "batch 123 g_loss : 1.224705\n",
      "batch 124 d_loss : 0.439193\n",
      "batch 124 g1_loss : 0.546868\n",
      "batch 124 g_loss : 1.252020\n",
      "batch 125 d_loss : 0.411481\n",
      "batch 125 g1_loss : 0.546325\n",
      "batch 125 g_loss : 1.231797\n",
      "batch 126 d_loss : 0.393799\n",
      "batch 126 g1_loss : 0.572952\n",
      "batch 126 g_loss : 1.336245\n",
      "batch 127 d_loss : 0.367043\n",
      "batch 127 g1_loss : 0.542065\n",
      "batch 127 g_loss : 1.385954\n",
      "batch 128 d_loss : 0.349517\n",
      "batch 128 g1_loss : 0.551461\n",
      "batch 128 g_loss : 1.395995\n",
      "batch 129 d_loss : 0.358466\n",
      "batch 129 g1_loss : 0.544504\n",
      "batch 129 g_loss : 1.324470\n",
      "batch 130 d_loss : 0.367246\n",
      "batch 130 g1_loss : 0.528187\n",
      "batch 130 g_loss : 1.335054\n",
      "batch 131 d_loss : 0.413619\n",
      "batch 131 g1_loss : 0.546027\n",
      "batch 131 g_loss : 1.162558\n",
      "batch 132 d_loss : 0.427410\n",
      "batch 132 g1_loss : 0.566448\n",
      "batch 132 g_loss : 1.176999\n",
      "batch 133 d_loss : 0.394265\n",
      "batch 133 g1_loss : 0.547050\n",
      "batch 133 g_loss : 1.193482\n",
      "batch 134 d_loss : 0.392042\n",
      "batch 134 g1_loss : 0.570118\n",
      "batch 134 g_loss : 1.264436\n",
      "batch 135 d_loss : 0.368497\n",
      "batch 135 g1_loss : 0.559497\n",
      "batch 135 g_loss : 1.418117\n",
      "batch 136 d_loss : 0.408137\n",
      "batch 136 g1_loss : 0.548021\n",
      "batch 136 g_loss : 1.270075\n",
      "batch 137 d_loss : 0.470508\n",
      "batch 137 g1_loss : 0.564863\n",
      "batch 137 g_loss : 1.027415\n",
      "batch 138 d_loss : 0.436835\n",
      "batch 138 g1_loss : 0.544087\n",
      "batch 138 g_loss : 1.277501\n",
      "batch 139 d_loss : 0.424670\n",
      "batch 139 g1_loss : 0.537148\n",
      "batch 139 g_loss : 1.334222\n",
      "batch 140 d_loss : 0.349437\n",
      "batch 140 g1_loss : 0.526250\n",
      "batch 140 g_loss : 1.416261\n",
      "batch 141 d_loss : 0.353543\n",
      "batch 141 g1_loss : 0.526725\n",
      "batch 141 g_loss : 1.394862\n",
      "batch 142 d_loss : 0.411824\n",
      "batch 142 g1_loss : 0.519819\n",
      "batch 142 g_loss : 1.341509\n",
      "batch 143 d_loss : 0.393669\n",
      "batch 143 g1_loss : 0.542648\n",
      "batch 143 g_loss : 1.303750\n",
      "batch 144 d_loss : 0.402357\n",
      "batch 144 g1_loss : 0.560010\n",
      "batch 144 g_loss : 1.223809\n",
      "batch 145 d_loss : 0.377302\n",
      "batch 145 g1_loss : 0.552320\n",
      "batch 145 g_loss : 1.331723\n",
      "batch 146 d_loss : 0.367416\n",
      "batch 146 g1_loss : 0.556087\n",
      "batch 146 g_loss : 1.369951\n",
      "batch 147 d_loss : 0.393091\n",
      "batch 147 g1_loss : 0.534629\n",
      "batch 147 g_loss : 1.370728\n",
      "batch 148 d_loss : 0.383192\n",
      "batch 148 g1_loss : 0.529807\n",
      "batch 148 g_loss : 1.348308\n",
      "batch 149 d_loss : 0.378237\n",
      "batch 149 g1_loss : 0.537361\n",
      "batch 149 g_loss : 1.363836\n",
      "batch 150 d_loss : 0.394832\n",
      "batch 150 g1_loss : 0.541533\n",
      "batch 150 g_loss : 1.293455\n",
      "batch 151 d_loss : 0.419773\n",
      "batch 151 g1_loss : 0.540025\n",
      "batch 151 g_loss : 1.359016\n",
      "batch 152 d_loss : 0.416009\n",
      "batch 152 g1_loss : 0.514179\n",
      "batch 152 g_loss : 1.260769\n",
      "batch 153 d_loss : 0.384872\n",
      "batch 153 g1_loss : 0.551389\n",
      "batch 153 g_loss : 1.366812\n",
      "batch 154 d_loss : 0.338389\n",
      "batch 154 g1_loss : 0.517880\n",
      "batch 154 g_loss : 1.494423\n",
      "batch 155 d_loss : 0.428766\n",
      "batch 155 g1_loss : 0.525741\n",
      "batch 155 g_loss : 1.444232\n",
      "batch 156 d_loss : 0.424890\n",
      "batch 156 g1_loss : 0.521138\n",
      "batch 156 g_loss : 1.305295\n",
      "batch 157 d_loss : 0.402912\n",
      "batch 157 g1_loss : 0.495017\n",
      "batch 157 g_loss : 1.249961\n",
      "batch 158 d_loss : 0.424904\n",
      "batch 158 g1_loss : 0.545074\n",
      "batch 158 g_loss : 1.239234\n",
      "batch 159 d_loss : 0.342119\n",
      "batch 159 g1_loss : 0.508626\n",
      "batch 159 g_loss : 1.422682\n",
      "batch 160 d_loss : 0.337025\n",
      "batch 160 g1_loss : 0.527850\n",
      "batch 160 g_loss : 1.434958\n",
      "batch 161 d_loss : 0.344393\n",
      "batch 161 g1_loss : 0.531675\n",
      "batch 161 g_loss : 1.496116\n",
      "batch 162 d_loss : 0.366210\n",
      "batch 162 g1_loss : 0.518811\n",
      "batch 162 g_loss : 1.378081\n",
      "batch 163 d_loss : 0.402686\n",
      "batch 163 g1_loss : 0.540223\n",
      "batch 163 g_loss : 1.279383\n",
      "batch 164 d_loss : 0.370367\n",
      "batch 164 g1_loss : 0.524135\n",
      "batch 164 g_loss : 1.264775\n",
      "batch 165 d_loss : 0.341645\n",
      "batch 165 g1_loss : 0.518448\n",
      "batch 165 g_loss : 1.315251\n",
      "batch 166 d_loss : 0.377472\n",
      "batch 166 g1_loss : 0.535492\n",
      "batch 166 g_loss : 1.428011\n",
      "batch 167 d_loss : 0.398082\n",
      "batch 167 g1_loss : 0.521186\n",
      "batch 167 g_loss : 1.358032\n",
      "batch 168 d_loss : 0.345306\n",
      "batch 168 g1_loss : 0.547750\n",
      "batch 168 g_loss : 1.402386\n",
      "batch 169 d_loss : 0.380576\n",
      "batch 169 g1_loss : 0.552512\n",
      "batch 169 g_loss : 1.280722\n",
      "batch 170 d_loss : 0.349582\n",
      "batch 170 g1_loss : 0.525385\n",
      "batch 170 g_loss : 1.426926\n",
      "batch 171 d_loss : 0.383782\n",
      "batch 171 g1_loss : 0.539122\n",
      "batch 171 g_loss : 1.430092\n",
      "batch 172 d_loss : 0.419070\n",
      "batch 172 g1_loss : 0.515328\n",
      "batch 172 g_loss : 1.307639\n",
      "batch 173 d_loss : 0.380607\n",
      "batch 173 g1_loss : 0.534220\n",
      "batch 173 g_loss : 1.203561\n",
      "batch 174 d_loss : 0.363334\n",
      "batch 174 g1_loss : 0.539034\n",
      "batch 174 g_loss : 1.459030\n",
      "batch 175 d_loss : 0.419272\n",
      "batch 175 g1_loss : 0.551988\n",
      "batch 175 g_loss : 1.272624\n",
      "batch 176 d_loss : 0.433282\n",
      "batch 176 g1_loss : 0.542656\n",
      "batch 176 g_loss : 1.170208\n",
      "batch 177 d_loss : 0.430387\n",
      "batch 177 g1_loss : 0.553485\n",
      "batch 177 g_loss : 1.355303\n",
      "batch 178 d_loss : 0.433623\n",
      "batch 178 g1_loss : 0.561030\n",
      "batch 178 g_loss : 1.357008\n",
      "batch 179 d_loss : 0.405605\n",
      "batch 179 g1_loss : 0.556517\n",
      "batch 179 g_loss : 1.384621\n",
      "batch 180 d_loss : 0.390946\n",
      "batch 180 g1_loss : 0.555593\n",
      "batch 180 g_loss : 1.498335\n",
      "batch 181 d_loss : 0.388800\n",
      "batch 181 g1_loss : 0.544351\n",
      "batch 181 g_loss : 1.320364\n",
      "batch 182 d_loss : 0.400415\n",
      "batch 182 g1_loss : 0.537744\n",
      "batch 182 g_loss : 1.365049\n",
      "batch 183 d_loss : 0.390011\n",
      "batch 183 g1_loss : 0.571606\n",
      "batch 183 g_loss : 1.281060\n",
      "batch 184 d_loss : 0.374485\n",
      "batch 184 g1_loss : 0.544928\n",
      "batch 184 g_loss : 1.322760\n",
      "batch 185 d_loss : 0.394563\n",
      "batch 185 g1_loss : 0.544230\n",
      "batch 185 g_loss : 1.339242\n",
      "batch 186 d_loss : 0.417568\n",
      "batch 186 g1_loss : 0.555925\n",
      "batch 186 g_loss : 1.202718\n",
      "batch 187 d_loss : 0.361703\n",
      "batch 187 g1_loss : 0.530642\n",
      "batch 187 g_loss : 1.426839\n",
      "batch 188 d_loss : 0.383625\n",
      "batch 188 g1_loss : 0.562386\n",
      "batch 188 g_loss : 1.415641\n",
      "batch 189 d_loss : 0.416307\n",
      "batch 189 g1_loss : 0.572962\n",
      "batch 189 g_loss : 1.274072\n",
      "batch 190 d_loss : 0.371862\n",
      "batch 190 g1_loss : 0.560502\n",
      "batch 190 g_loss : 1.304865\n",
      "batch 191 d_loss : 0.421693\n",
      "batch 191 g1_loss : 0.575436\n",
      "batch 191 g_loss : 1.285350\n",
      "batch 192 d_loss : 0.404432\n",
      "batch 192 g1_loss : 0.589084\n",
      "batch 192 g_loss : 1.203379\n",
      "batch 193 d_loss : 0.349529\n",
      "batch 193 g1_loss : 0.557806\n",
      "batch 193 g_loss : 1.387681\n",
      "batch 194 d_loss : 0.396149\n",
      "batch 194 g1_loss : 0.568783\n",
      "batch 194 g_loss : 1.242615\n",
      "batch 195 d_loss : 0.371917\n",
      "batch 195 g1_loss : 0.549294\n",
      "batch 195 g_loss : 1.285550\n",
      "batch 196 d_loss : 0.368278\n",
      "batch 196 g1_loss : 0.563404\n",
      "batch 196 g_loss : 1.376148\n",
      "batch 197 d_loss : 0.389146\n",
      "batch 197 g1_loss : 0.565532\n",
      "batch 197 g_loss : 1.408535\n",
      "batch 198 d_loss : 0.394053\n",
      "batch 198 g1_loss : 0.534555\n",
      "batch 198 g_loss : 1.403370\n",
      "batch 199 d_loss : 0.367471\n",
      "batch 199 g1_loss : 0.553108\n",
      "batch 199 g_loss : 1.412890\n",
      "batch 200 d_loss : 0.355830\n",
      "batch 200 g1_loss : 0.565671\n",
      "batch 200 g_loss : 1.303871\n",
      "batch 201 d_loss : 0.376008\n",
      "batch 201 g1_loss : 0.575456\n",
      "batch 201 g_loss : 1.209818\n",
      "batch 202 d_loss : 0.382994\n",
      "batch 202 g1_loss : 0.565526\n",
      "batch 202 g_loss : 1.225643\n",
      "batch 203 d_loss : 0.410298\n",
      "batch 203 g1_loss : 0.557819\n",
      "batch 203 g_loss : 1.385746\n",
      "batch 204 d_loss : 0.379074\n",
      "batch 204 g1_loss : 0.567702\n",
      "batch 204 g_loss : 1.337822\n",
      "batch 205 d_loss : 0.354847\n",
      "batch 205 g1_loss : 0.554041\n",
      "batch 205 g_loss : 1.365974\n",
      "batch 206 d_loss : 0.372822\n",
      "batch 206 g1_loss : 0.554284\n",
      "batch 206 g_loss : 1.245484\n",
      "batch 207 d_loss : 0.445870\n",
      "batch 207 g1_loss : 0.582566\n",
      "batch 207 g_loss : 1.154052\n",
      "batch 208 d_loss : 0.376564\n",
      "batch 208 g1_loss : 0.572534\n",
      "batch 208 g_loss : 1.260196\n",
      "batch 209 d_loss : 0.359953\n",
      "batch 209 g1_loss : 0.546630\n",
      "batch 209 g_loss : 1.519803\n",
      "batch 210 d_loss : 0.344025\n",
      "batch 210 g1_loss : 0.556083\n",
      "batch 210 g_loss : 1.432568\n",
      "batch 211 d_loss : 0.375454\n",
      "batch 211 g1_loss : 0.544793\n",
      "batch 211 g_loss : 1.468640\n",
      "batch 212 d_loss : 0.390093\n",
      "batch 212 g1_loss : 0.531886\n",
      "batch 212 g_loss : 1.270811\n",
      "batch 213 d_loss : 0.414001\n",
      "batch 213 g1_loss : 0.576788\n",
      "batch 213 g_loss : 1.265571\n",
      "batch 214 d_loss : 0.411085\n",
      "batch 214 g1_loss : 0.526905\n",
      "batch 214 g_loss : 1.331497\n",
      "batch 215 d_loss : 0.340288\n",
      "batch 215 g1_loss : 0.573371\n",
      "batch 215 g_loss : 1.440686\n",
      "batch 216 d_loss : 0.371402\n",
      "batch 216 g1_loss : 0.541652\n",
      "batch 216 g_loss : 1.353964\n",
      "batch 217 d_loss : 0.405245\n",
      "batch 217 g1_loss : 0.529266\n",
      "batch 217 g_loss : 1.269534\n",
      "batch 218 d_loss : 0.357145\n",
      "batch 218 g1_loss : 0.548928\n",
      "batch 218 g_loss : 1.453846\n",
      "batch 219 d_loss : 0.358003\n",
      "batch 219 g1_loss : 0.552188\n",
      "batch 219 g_loss : 1.411758\n",
      "batch 220 d_loss : 0.397701\n",
      "batch 220 g1_loss : 0.552397\n",
      "batch 220 g_loss : 1.321124\n",
      "batch 221 d_loss : 0.427301\n",
      "batch 221 g1_loss : 0.518699\n",
      "batch 221 g_loss : 1.192915\n",
      "batch 222 d_loss : 0.423601\n",
      "batch 222 g1_loss : 0.527046\n",
      "batch 222 g_loss : 1.304754\n",
      "batch 223 d_loss : 0.428767\n",
      "batch 223 g1_loss : 0.555183\n",
      "batch 223 g_loss : 1.364213\n",
      "batch 224 d_loss : 0.363259\n",
      "batch 224 g1_loss : 0.550991\n",
      "batch 224 g_loss : 1.494498\n",
      "batch 225 d_loss : 0.411676\n",
      "batch 225 g1_loss : 0.569055\n",
      "batch 225 g_loss : 1.337824\n",
      "batch 226 d_loss : 0.380513\n",
      "batch 226 g1_loss : 0.529073\n",
      "batch 226 g_loss : 1.337302\n",
      "batch 227 d_loss : 0.422564\n",
      "batch 227 g1_loss : 0.527961\n",
      "batch 227 g_loss : 1.230468\n",
      "batch 228 d_loss : 0.407362\n",
      "batch 228 g1_loss : 0.530093\n",
      "batch 228 g_loss : 1.267665\n",
      "batch 229 d_loss : 0.389775\n",
      "batch 229 g1_loss : 0.538295\n",
      "batch 229 g_loss : 1.484694\n",
      "batch 230 d_loss : 0.339750\n",
      "batch 230 g1_loss : 0.565309\n",
      "batch 230 g_loss : 1.546690\n",
      "batch 231 d_loss : 0.341918\n",
      "batch 231 g1_loss : 0.522317\n",
      "batch 231 g_loss : 1.433878\n",
      "batch 232 d_loss : 0.383965\n",
      "batch 232 g1_loss : 0.533990\n",
      "batch 232 g_loss : 1.290953\n",
      "batch 233 d_loss : 0.421880\n",
      "batch 233 g1_loss : 0.514674\n",
      "batch 233 g_loss : 1.164542\n",
      "batch 234 d_loss : 0.414279\n",
      "batch 234 g1_loss : 0.528792\n",
      "batch 234 g_loss : 1.172472\n",
      "batch 235 d_loss : 0.460058\n",
      "batch 235 g1_loss : 0.527349\n",
      "batch 235 g_loss : 1.140600\n",
      "batch 236 d_loss : 0.348875\n",
      "batch 236 g1_loss : 0.526787\n",
      "batch 236 g_loss : 1.501958\n",
      "batch 237 d_loss : 0.385958\n",
      "batch 237 g1_loss : 0.519691\n",
      "batch 237 g_loss : 1.476759\n",
      "batch 238 d_loss : 0.346606\n",
      "batch 238 g1_loss : 0.525486\n",
      "batch 238 g_loss : 1.426022\n",
      "batch 239 d_loss : 0.436172\n",
      "batch 239 g1_loss : 0.512279\n",
      "batch 239 g_loss : 1.113924\n",
      "batch 240 d_loss : 0.400795\n",
      "batch 240 g1_loss : 0.554195\n",
      "batch 240 g_loss : 1.185650\n",
      "batch 241 d_loss : 0.338542\n",
      "batch 241 g1_loss : 0.526667\n",
      "batch 241 g_loss : 1.565606\n",
      "batch 242 d_loss : 0.335952\n",
      "batch 242 g1_loss : 0.535809\n",
      "batch 242 g_loss : 1.489146\n",
      "batch 243 d_loss : 0.380105\n",
      "batch 243 g1_loss : 0.518842\n",
      "batch 243 g_loss : 1.257755\n",
      "batch 244 d_loss : 0.359762\n",
      "batch 244 g1_loss : 0.501780\n",
      "batch 244 g_loss : 1.387971\n",
      "batch 245 d_loss : 0.356908\n",
      "batch 245 g1_loss : 0.503165\n",
      "batch 245 g_loss : 1.380226\n",
      "batch 246 d_loss : 0.359919\n",
      "batch 246 g1_loss : 0.516689\n",
      "batch 246 g_loss : 1.353517\n",
      "batch 247 d_loss : 0.407430\n",
      "batch 247 g1_loss : 0.520527\n",
      "batch 247 g_loss : 1.334343\n",
      "batch 248 d_loss : 0.366611\n",
      "batch 248 g1_loss : 0.503811\n",
      "batch 248 g_loss : 1.433533\n",
      "batch 249 d_loss : 0.349443\n",
      "batch 249 g1_loss : 0.525902\n",
      "batch 249 g_loss : 1.499935\n",
      "batch 250 d_loss : 0.379730\n",
      "batch 250 g1_loss : 0.516478\n",
      "batch 250 g_loss : 1.539818\n",
      "batch 251 d_loss : 0.384300\n",
      "batch 251 g1_loss : 0.529394\n",
      "batch 251 g_loss : 1.260794\n",
      "batch 252 d_loss : 0.424562\n",
      "batch 252 g1_loss : 0.507548\n",
      "batch 252 g_loss : 1.297533\n",
      "batch 253 d_loss : 0.443645\n",
      "batch 253 g1_loss : 0.518031\n",
      "batch 253 g_loss : 1.276429\n",
      "batch 254 d_loss : 0.374038\n",
      "batch 254 g1_loss : 0.525907\n",
      "batch 254 g_loss : 1.302968\n",
      "batch 255 d_loss : 0.352896\n",
      "batch 255 g1_loss : 0.516407\n",
      "batch 255 g_loss : 1.320007\n",
      "batch 256 d_loss : 0.344797\n",
      "batch 256 g1_loss : 0.530935\n",
      "batch 256 g_loss : 1.499202\n",
      "batch 257 d_loss : 0.308208\n",
      "batch 257 g1_loss : 0.501824\n",
      "batch 257 g_loss : 1.691111\n",
      "batch 258 d_loss : 0.390098\n",
      "batch 258 g1_loss : 0.517047\n",
      "batch 258 g_loss : 1.326042\n",
      "batch 259 d_loss : 0.331488\n",
      "batch 259 g1_loss : 0.507822\n",
      "batch 259 g_loss : 1.401257\n",
      "batch 260 d_loss : 0.392141\n",
      "batch 260 g1_loss : 0.491984\n",
      "batch 260 g_loss : 1.354174\n",
      "batch 261 d_loss : 0.344733\n",
      "batch 261 g1_loss : 0.499790\n",
      "batch 261 g_loss : 1.524994\n",
      "batch 262 d_loss : 0.395376\n",
      "batch 262 g1_loss : 0.499661\n",
      "batch 262 g_loss : 1.429815\n",
      "batch 263 d_loss : 0.347228\n",
      "batch 263 g1_loss : 0.491704\n",
      "batch 263 g_loss : 1.432602\n",
      "batch 264 d_loss : 0.361522\n",
      "batch 264 g1_loss : 0.533226\n",
      "batch 264 g_loss : 1.479822\n",
      "batch 265 d_loss : 0.347676\n",
      "batch 265 g1_loss : 0.501000\n",
      "batch 265 g_loss : 1.392512\n",
      "batch 266 d_loss : 0.386214\n",
      "batch 266 g1_loss : 0.491467\n",
      "batch 266 g_loss : 1.504189\n",
      "batch 267 d_loss : 0.317210\n",
      "batch 267 g1_loss : 0.507156\n",
      "batch 267 g_loss : 1.432391\n",
      "batch 268 d_loss : 0.340093\n",
      "batch 268 g1_loss : 0.498060\n",
      "batch 268 g_loss : 1.442698\n",
      "batch 269 d_loss : 0.339919\n",
      "batch 269 g1_loss : 0.509949\n",
      "batch 269 g_loss : 1.362559\n",
      "batch 270 d_loss : 0.352527\n",
      "batch 270 g1_loss : 0.511107\n",
      "batch 270 g_loss : 1.382283\n",
      "batch 271 d_loss : 0.406515\n",
      "batch 271 g1_loss : 0.505904\n",
      "batch 271 g_loss : 1.300011\n",
      "batch 272 d_loss : 0.394656\n",
      "batch 272 g1_loss : 0.511345\n",
      "batch 272 g_loss : 1.422843\n",
      "batch 273 d_loss : 0.334489\n",
      "batch 273 g1_loss : 0.493157\n",
      "batch 273 g_loss : 1.707435\n",
      "batch 274 d_loss : 0.363117\n",
      "batch 274 g1_loss : 0.510884\n",
      "batch 274 g_loss : 1.543997\n",
      "batch 275 d_loss : 0.365899\n",
      "batch 275 g1_loss : 0.520791\n",
      "batch 275 g_loss : 1.410791\n",
      "batch 276 d_loss : 0.366134\n",
      "batch 276 g1_loss : 0.508522\n",
      "batch 276 g_loss : 1.415428\n",
      "batch 277 d_loss : 0.373917\n",
      "batch 277 g1_loss : 0.517088\n",
      "batch 277 g_loss : 1.490953\n",
      "batch 278 d_loss : 0.339329\n",
      "batch 278 g1_loss : 0.548113\n",
      "batch 278 g_loss : 1.409865\n",
      "batch 279 d_loss : 0.331035\n",
      "batch 279 g1_loss : 0.505305\n",
      "batch 279 g_loss : 1.442395\n",
      "batch 280 d_loss : 0.433735\n",
      "batch 280 g1_loss : 0.518586\n",
      "batch 280 g_loss : 1.213820\n",
      "batch 281 d_loss : 0.393423\n",
      "batch 281 g1_loss : 0.526364\n",
      "batch 281 g_loss : 1.301704\n",
      "batch 282 d_loss : 0.398197\n",
      "batch 282 g1_loss : 0.510601\n",
      "batch 282 g_loss : 1.466844\n",
      "batch 283 d_loss : 0.400903\n",
      "batch 283 g1_loss : 0.508504\n",
      "batch 283 g_loss : 1.467178\n",
      "batch 284 d_loss : 0.327182\n",
      "batch 284 g1_loss : 0.500684\n",
      "batch 284 g_loss : 1.562789\n",
      "batch 285 d_loss : 0.350730\n",
      "batch 285 g1_loss : 0.499497\n",
      "batch 285 g_loss : 1.595681\n",
      "batch 286 d_loss : 0.356217\n",
      "batch 286 g1_loss : 0.534612\n",
      "batch 286 g_loss : 1.474318\n",
      "batch 287 d_loss : 0.343755\n",
      "batch 287 g1_loss : 0.514061\n",
      "batch 287 g_loss : 1.625817\n",
      "batch 288 d_loss : 0.318296\n",
      "batch 288 g1_loss : 0.526203\n",
      "batch 288 g_loss : 1.568810\n",
      "batch 289 d_loss : 0.368760\n",
      "batch 289 g1_loss : 0.494832\n",
      "batch 289 g_loss : 1.350856\n",
      "batch 290 d_loss : 0.373434\n",
      "batch 290 g1_loss : 0.530910\n",
      "batch 290 g_loss : 1.343254\n",
      "batch 291 d_loss : 0.364276\n",
      "batch 291 g1_loss : 0.518166\n",
      "batch 291 g_loss : 1.403259\n",
      "batch 292 d_loss : 0.366180\n",
      "batch 292 g1_loss : 0.538553\n",
      "batch 292 g_loss : 1.294263\n",
      "batch 293 d_loss : 0.404985\n",
      "batch 293 g1_loss : 0.515431\n",
      "batch 293 g_loss : 1.063841\n",
      "batch 294 d_loss : 0.376960\n",
      "batch 294 g1_loss : 0.516724\n",
      "batch 294 g_loss : 1.233205\n",
      "batch 295 d_loss : 0.366095\n",
      "batch 295 g1_loss : 0.528554\n",
      "batch 295 g_loss : 1.462425\n",
      "batch 296 d_loss : 0.376390\n",
      "batch 296 g1_loss : 0.527503\n",
      "batch 296 g_loss : 1.422141\n",
      "batch 297 d_loss : 0.343197\n",
      "batch 297 g1_loss : 0.502813\n",
      "batch 297 g_loss : 1.481654\n",
      "batch 298 d_loss : 0.354286\n",
      "batch 298 g1_loss : 0.518611\n",
      "batch 298 g_loss : 1.386062\n",
      "batch 299 d_loss : 0.398980\n",
      "batch 299 g1_loss : 0.519966\n",
      "batch 299 g_loss : 1.258550\n",
      "batch 300 d_loss : 0.377153\n",
      "batch 300 g1_loss : 0.522462\n",
      "batch 300 g_loss : 1.372565\n",
      "batch 301 d_loss : 0.366813\n",
      "batch 301 g1_loss : 0.508996\n",
      "batch 301 g_loss : 1.525349\n",
      "batch 302 d_loss : 0.339018\n",
      "batch 302 g1_loss : 0.525378\n",
      "batch 302 g_loss : 1.463658\n",
      "batch 303 d_loss : 0.341616\n",
      "batch 303 g1_loss : 0.521887\n",
      "batch 303 g_loss : 1.679559\n",
      "batch 304 d_loss : 0.346747\n",
      "batch 304 g1_loss : 0.508040\n",
      "batch 304 g_loss : 1.352758\n",
      "batch 305 d_loss : 0.366197\n",
      "batch 305 g1_loss : 0.502937\n",
      "batch 305 g_loss : 1.258906\n",
      "batch 306 d_loss : 0.344508\n",
      "batch 306 g1_loss : 0.524205\n",
      "batch 306 g_loss : 1.384958\n",
      "batch 307 d_loss : 0.428173\n",
      "batch 307 g1_loss : 0.533424\n",
      "batch 307 g_loss : 1.289825\n",
      "batch 308 d_loss : 0.424950\n",
      "batch 308 g1_loss : 0.540409\n",
      "batch 308 g_loss : 1.333203\n",
      "batch 309 d_loss : 0.351337\n",
      "batch 309 g1_loss : 0.536786\n",
      "batch 309 g_loss : 1.342973\n",
      "batch 310 d_loss : 0.381198\n",
      "batch 310 g1_loss : 0.518866\n",
      "batch 310 g_loss : 1.247131\n",
      "batch 311 d_loss : 0.376613\n",
      "batch 311 g1_loss : 0.516185\n",
      "batch 311 g_loss : 1.348649\n",
      "batch 312 d_loss : 0.343698\n",
      "batch 312 g1_loss : 0.509690\n",
      "batch 312 g_loss : 1.510972\n",
      "batch 313 d_loss : 0.375394\n",
      "batch 313 g1_loss : 0.525803\n",
      "batch 313 g_loss : 1.404050\n",
      "batch 314 d_loss : 0.331441\n",
      "batch 314 g1_loss : 0.533439\n",
      "batch 314 g_loss : 1.626487\n",
      "batch 315 d_loss : 0.311260\n",
      "batch 315 g1_loss : 0.518345\n",
      "batch 315 g_loss : 1.501909\n",
      "batch 316 d_loss : 0.415853\n",
      "batch 316 g1_loss : 0.521134\n",
      "batch 316 g_loss : 1.308560\n",
      "batch 317 d_loss : 0.379035\n",
      "batch 317 g1_loss : 0.531043\n",
      "batch 317 g_loss : 1.360794\n",
      "batch 318 d_loss : 0.328849\n",
      "batch 318 g1_loss : 0.538961\n",
      "batch 318 g_loss : 1.385141\n",
      "batch 319 d_loss : 0.351762\n",
      "batch 319 g1_loss : 0.518267\n",
      "batch 319 g_loss : 1.494460\n",
      "batch 320 d_loss : 0.347210\n",
      "batch 320 g1_loss : 0.520355\n",
      "batch 320 g_loss : 1.440611\n",
      "batch 321 d_loss : 0.331623\n",
      "batch 321 g1_loss : 0.505178\n",
      "batch 321 g_loss : 1.559627\n",
      "batch 322 d_loss : 0.396110\n",
      "batch 322 g1_loss : 0.512140\n",
      "batch 322 g_loss : 1.313649\n",
      "batch 323 d_loss : 0.391006\n",
      "batch 323 g1_loss : 0.509763\n",
      "batch 323 g_loss : 1.292047\n",
      "batch 324 d_loss : 0.392097\n",
      "batch 324 g1_loss : 0.533100\n",
      "batch 324 g_loss : 1.273387\n",
      "batch 325 d_loss : 0.417869\n",
      "batch 325 g1_loss : 0.525690\n",
      "batch 325 g_loss : 1.188702\n",
      "batch 326 d_loss : 0.408324\n",
      "batch 326 g1_loss : 0.532695\n",
      "batch 326 g_loss : 1.290842\n",
      "batch 327 d_loss : 0.388459\n",
      "batch 327 g1_loss : 0.485111\n",
      "batch 327 g_loss : 1.533436\n",
      "batch 328 d_loss : 0.349276\n",
      "batch 328 g1_loss : 0.512025\n",
      "batch 328 g_loss : 1.414536\n",
      "batch 329 d_loss : 0.369043\n",
      "batch 329 g1_loss : 0.497900\n",
      "batch 329 g_loss : 1.442881\n",
      "batch 330 d_loss : 0.410953\n",
      "batch 330 g1_loss : 0.492324\n",
      "batch 330 g_loss : 1.051762\n",
      "batch 331 d_loss : 0.384263\n",
      "batch 331 g1_loss : 0.509835\n",
      "batch 331 g_loss : 1.193635\n",
      "batch 332 d_loss : 0.363573\n",
      "batch 332 g1_loss : 0.496384\n",
      "batch 332 g_loss : 1.339327\n",
      "batch 333 d_loss : 0.365873\n",
      "batch 333 g1_loss : 0.519424\n",
      "batch 333 g_loss : 1.477249\n",
      "batch 334 d_loss : 0.303042\n",
      "batch 334 g1_loss : 0.492786\n",
      "batch 334 g_loss : 1.629988\n",
      "batch 335 d_loss : 0.331027\n",
      "batch 335 g1_loss : 0.497674\n",
      "batch 335 g_loss : 1.556767\n",
      "batch 336 d_loss : 0.308394\n",
      "batch 336 g1_loss : 0.504602\n",
      "batch 336 g_loss : 1.381436\n",
      "batch 337 d_loss : 0.293983\n",
      "batch 337 g1_loss : 0.492317\n",
      "batch 337 g_loss : 1.652136\n",
      "batch 338 d_loss : 0.317508\n",
      "batch 338 g1_loss : 0.508010\n",
      "batch 338 g_loss : 1.448157\n",
      "batch 339 d_loss : 0.307515\n",
      "batch 339 g1_loss : 0.495348\n",
      "batch 339 g_loss : 1.518691\n",
      "batch 340 d_loss : 0.338647\n",
      "batch 340 g1_loss : 0.496484\n",
      "batch 340 g_loss : 1.444862\n",
      "batch 341 d_loss : 0.333768\n",
      "batch 341 g1_loss : 0.488296\n",
      "batch 341 g_loss : 1.560697\n",
      "batch 342 d_loss : 0.339977\n",
      "batch 342 g1_loss : 0.469193\n",
      "batch 342 g_loss : 1.504581\n",
      "batch 343 d_loss : 0.320386\n",
      "batch 343 g1_loss : 0.484742\n",
      "batch 343 g_loss : 1.383215\n",
      "batch 344 d_loss : 0.333635\n",
      "batch 344 g1_loss : 0.494947\n",
      "batch 344 g_loss : 1.436522\n",
      "batch 345 d_loss : 0.355737\n",
      "batch 345 g1_loss : 0.472869\n",
      "batch 345 g_loss : 1.508453\n",
      "batch 346 d_loss : 0.332588\n",
      "batch 346 g1_loss : 0.494465\n",
      "batch 346 g_loss : 1.501028\n",
      "batch 347 d_loss : 0.364698\n",
      "batch 347 g1_loss : 0.517849\n",
      "batch 347 g_loss : 1.418512\n",
      "batch 348 d_loss : 0.337787\n",
      "batch 348 g1_loss : 0.482888\n",
      "batch 348 g_loss : 1.591219\n",
      "batch 349 d_loss : 0.333467\n",
      "batch 349 g1_loss : 0.491885\n",
      "batch 349 g_loss : 1.377468\n",
      "batch 350 d_loss : 0.361699\n",
      "batch 350 g1_loss : 0.486001\n",
      "batch 350 g_loss : 1.292532\n",
      "batch 351 d_loss : 0.341517\n",
      "batch 351 g1_loss : 0.472790\n",
      "batch 351 g_loss : 1.604162\n",
      "batch 352 d_loss : 0.358613\n",
      "batch 352 g1_loss : 0.511577\n",
      "batch 352 g_loss : 1.450521\n",
      "batch 353 d_loss : 0.334419\n",
      "batch 353 g1_loss : 0.468102\n",
      "batch 353 g_loss : 1.383587\n",
      "batch 354 d_loss : 0.354027\n",
      "batch 354 g1_loss : 0.504974\n",
      "batch 354 g_loss : 1.455352\n",
      "batch 355 d_loss : 0.369246\n",
      "batch 355 g1_loss : 0.465759\n",
      "batch 355 g_loss : 1.425514\n",
      "batch 356 d_loss : 0.347979\n",
      "batch 356 g1_loss : 0.470255\n",
      "batch 356 g_loss : 1.539041\n",
      "batch 357 d_loss : 0.348976\n",
      "batch 357 g1_loss : 0.489868\n",
      "batch 357 g_loss : 1.249969\n",
      "batch 358 d_loss : 0.383534\n",
      "batch 358 g1_loss : 0.480014\n",
      "batch 358 g_loss : 1.448306\n",
      "batch 359 d_loss : 0.471822\n",
      "batch 359 g1_loss : 0.475993\n",
      "batch 359 g_loss : 0.902271\n",
      "batch 360 d_loss : 0.418748\n",
      "batch 360 g1_loss : 0.479750\n",
      "batch 360 g_loss : 1.724978\n",
      "batch 361 d_loss : 0.309220\n",
      "batch 361 g1_loss : 0.489994\n",
      "batch 361 g_loss : 1.404280\n",
      "batch 362 d_loss : 0.345811\n",
      "batch 362 g1_loss : 0.495542\n",
      "batch 362 g_loss : 1.586168\n",
      "batch 363 d_loss : 0.321901\n",
      "batch 363 g1_loss : 0.460087\n",
      "batch 363 g_loss : 1.470212\n",
      "batch 364 d_loss : 0.335595\n",
      "batch 364 g1_loss : 0.483117\n",
      "batch 364 g_loss : 1.483267\n",
      "batch 365 d_loss : 0.293954\n",
      "batch 365 g1_loss : 0.460699\n",
      "batch 365 g_loss : 1.778052\n",
      "batch 366 d_loss : 0.348493\n",
      "batch 366 g1_loss : 0.486278\n",
      "batch 366 g_loss : 1.456958\n",
      "batch 367 d_loss : 0.381756\n",
      "batch 367 g1_loss : 0.464717\n",
      "batch 367 g_loss : 1.231584\n",
      "batch 368 d_loss : 0.374603\n",
      "batch 368 g1_loss : 0.490226\n",
      "batch 368 g_loss : 1.481107\n",
      "batch 369 d_loss : 0.357561\n",
      "batch 369 g1_loss : 0.475123\n",
      "batch 369 g_loss : 1.284309\n",
      "batch 370 d_loss : 0.374995\n",
      "batch 370 g1_loss : 0.514122\n",
      "batch 370 g_loss : 1.415198\n",
      "batch 371 d_loss : 0.375853\n",
      "batch 371 g1_loss : 0.490761\n",
      "batch 371 g_loss : 1.469193\n",
      "batch 372 d_loss : 0.339596\n",
      "batch 372 g1_loss : 0.468317\n",
      "batch 372 g_loss : 1.637370\n",
      "batch 373 d_loss : 0.351900\n",
      "batch 373 g1_loss : 0.493839\n",
      "batch 373 g_loss : 1.418871\n",
      "batch 374 d_loss : 0.356833\n",
      "batch 374 g1_loss : 0.488862\n",
      "batch 374 g_loss : 1.354233\n",
      "batch 375 d_loss : 0.359709\n",
      "batch 375 g1_loss : 0.468518\n",
      "batch 375 g_loss : 1.581385\n",
      "batch 376 d_loss : 0.339451\n",
      "batch 376 g1_loss : 0.478957\n",
      "batch 376 g_loss : 1.540861\n",
      "batch 377 d_loss : 0.386400\n",
      "batch 377 g1_loss : 0.478240\n",
      "batch 377 g_loss : 1.335410\n",
      "batch 378 d_loss : 0.341801\n",
      "batch 378 g1_loss : 0.470570\n",
      "batch 378 g_loss : 1.308050\n",
      "batch 379 d_loss : 0.351223\n",
      "batch 379 g1_loss : 0.477673\n",
      "batch 379 g_loss : 1.561537\n",
      "batch 380 d_loss : 0.315388\n",
      "batch 380 g1_loss : 0.497141\n",
      "batch 380 g_loss : 1.508840\n",
      "batch 381 d_loss : 0.347344\n",
      "batch 381 g1_loss : 0.483248\n",
      "batch 381 g_loss : 1.461655\n",
      "batch 382 d_loss : 0.398001\n",
      "batch 382 g1_loss : 0.508838\n",
      "batch 382 g_loss : 1.253412\n",
      "batch 383 d_loss : 0.459150\n",
      "batch 383 g1_loss : 0.483925\n",
      "batch 383 g_loss : 1.217106\n",
      "batch 384 d_loss : 0.379270\n",
      "batch 384 g1_loss : 0.491775\n",
      "batch 384 g_loss : 1.495720\n",
      "batch 385 d_loss : 0.335934\n",
      "batch 385 g1_loss : 0.486646\n",
      "batch 385 g_loss : 1.657483\n",
      "batch 386 d_loss : 0.410636\n",
      "batch 386 g1_loss : 0.492023\n",
      "batch 386 g_loss : 1.353009\n",
      "batch 387 d_loss : 0.364592\n",
      "batch 387 g1_loss : 0.494217\n",
      "batch 387 g_loss : 1.262000\n",
      "batch 388 d_loss : 0.314373\n",
      "batch 388 g1_loss : 0.516485\n",
      "batch 388 g_loss : 1.769471\n",
      "batch 389 d_loss : 0.381179\n",
      "batch 389 g1_loss : 0.491240\n",
      "batch 389 g_loss : 1.140723\n",
      "batch 390 d_loss : 0.394047\n",
      "batch 390 g1_loss : 0.498953\n",
      "batch 390 g_loss : 1.296847\n",
      "batch 391 d_loss : 0.328996\n",
      "batch 391 g1_loss : 0.500285\n",
      "batch 391 g_loss : 1.508014\n",
      "batch 392 d_loss : 0.336349\n",
      "batch 392 g1_loss : 0.492558\n",
      "batch 392 g_loss : 1.506586\n",
      "batch 393 d_loss : 0.388521\n",
      "batch 393 g1_loss : 0.506888\n",
      "batch 393 g_loss : 1.215157\n",
      "batch 394 d_loss : 0.389973\n",
      "batch 394 g1_loss : 0.485079\n",
      "batch 394 g_loss : 1.259651\n",
      "batch 395 d_loss : 0.353247\n",
      "batch 395 g1_loss : 0.499342\n",
      "batch 395 g_loss : 1.361756\n",
      "batch 396 d_loss : 0.322233\n",
      "batch 396 g1_loss : 0.489921\n",
      "batch 396 g_loss : 1.579343\n",
      "batch 397 d_loss : 0.348710\n",
      "batch 397 g1_loss : 0.493406\n",
      "batch 397 g_loss : 1.430482\n",
      "batch 398 d_loss : 0.297674\n",
      "batch 398 g1_loss : 0.498428\n",
      "batch 398 g_loss : 1.594950\n",
      "batch 399 d_loss : 0.373338\n",
      "batch 399 g1_loss : 0.490502\n",
      "batch 399 g_loss : 1.316137\n",
      "batch 400 d_loss : 0.404152\n",
      "batch 400 g1_loss : 0.515887\n",
      "batch 400 g_loss : 1.202879\n",
      "batch 401 d_loss : 0.354523\n",
      "batch 401 g1_loss : 0.501540\n",
      "batch 401 g_loss : 1.594941\n",
      "batch 402 d_loss : 0.341803\n",
      "batch 402 g1_loss : 0.545530\n",
      "batch 402 g_loss : 1.339652\n",
      "batch 403 d_loss : 0.321941\n",
      "batch 403 g1_loss : 0.507256\n",
      "batch 403 g_loss : 1.491669\n",
      "batch 404 d_loss : 0.379817\n",
      "batch 404 g1_loss : 0.494821\n",
      "batch 404 g_loss : 1.204045\n",
      "batch 405 d_loss : 0.345051\n",
      "batch 405 g1_loss : 0.530708\n",
      "batch 405 g_loss : 1.648781\n",
      "batch 406 d_loss : 0.384556\n",
      "batch 406 g1_loss : 0.474632\n",
      "batch 406 g_loss : 0.980853\n",
      "batch 407 d_loss : 0.401495\n",
      "batch 407 g1_loss : 0.538593\n",
      "batch 407 g_loss : 1.243791\n",
      "batch 408 d_loss : 0.347365\n",
      "batch 408 g1_loss : 0.525257\n",
      "batch 408 g_loss : 1.574438\n",
      "batch 409 d_loss : 0.349879\n",
      "batch 409 g1_loss : 0.496422\n",
      "batch 409 g_loss : 1.403314\n",
      "batch 410 d_loss : 0.287651\n",
      "batch 410 g1_loss : 0.518766\n",
      "batch 410 g_loss : 1.634027\n",
      "batch 411 d_loss : 0.363905\n",
      "batch 411 g1_loss : 0.521020\n",
      "batch 411 g_loss : 1.300761\n",
      "batch 412 d_loss : 0.351789\n",
      "batch 412 g1_loss : 0.494261\n",
      "batch 412 g_loss : 1.570866\n",
      "batch 413 d_loss : 0.352548\n",
      "batch 413 g1_loss : 0.498846\n",
      "batch 413 g_loss : 1.454129\n",
      "batch 414 d_loss : 0.331940\n",
      "batch 414 g1_loss : 0.511538\n",
      "batch 414 g_loss : 1.403888\n",
      "batch 415 d_loss : 0.334442\n",
      "batch 415 g1_loss : 0.480134\n",
      "batch 415 g_loss : 1.457695\n",
      "batch 416 d_loss : 0.365685\n",
      "batch 416 g1_loss : 0.506819\n",
      "batch 416 g_loss : 1.371128\n",
      "batch 417 d_loss : 0.348903\n",
      "batch 417 g1_loss : 0.512406\n",
      "batch 417 g_loss : 1.484222\n",
      "batch 418 d_loss : 0.323946\n",
      "batch 418 g1_loss : 0.526890\n",
      "batch 418 g_loss : 1.362080\n",
      "batch 419 d_loss : 0.309183\n",
      "batch 419 g1_loss : 0.518747\n",
      "batch 419 g_loss : 1.501794\n",
      "batch 420 d_loss : 0.323290\n",
      "batch 420 g1_loss : 0.484775\n",
      "batch 420 g_loss : 1.665031\n",
      "batch 421 d_loss : 0.340906\n",
      "batch 421 g1_loss : 0.496367\n",
      "batch 421 g_loss : 1.236229\n",
      "batch 422 d_loss : 0.346940\n",
      "batch 422 g1_loss : 0.484779\n",
      "batch 422 g_loss : 1.473632\n",
      "batch 423 d_loss : 0.301155\n",
      "batch 423 g1_loss : 0.498972\n",
      "batch 423 g_loss : 1.341646\n",
      "batch 424 d_loss : 0.351772\n",
      "batch 424 g1_loss : 0.494468\n",
      "batch 424 g_loss : 1.448825\n",
      "batch 425 d_loss : 0.328223\n",
      "batch 425 g1_loss : 0.511844\n",
      "batch 425 g_loss : 1.497550\n",
      "batch 426 d_loss : 0.328701\n",
      "batch 426 g1_loss : 0.500268\n",
      "batch 426 g_loss : 1.509093\n",
      "batch 427 d_loss : 0.349928\n",
      "batch 427 g1_loss : 0.485874\n",
      "batch 427 g_loss : 1.495782\n",
      "batch 428 d_loss : 0.385564\n",
      "batch 428 g1_loss : 0.487781\n",
      "batch 428 g_loss : 1.255353\n",
      "batch 429 d_loss : 0.377894\n",
      "batch 429 g1_loss : 0.491744\n",
      "batch 429 g_loss : 1.317472\n",
      "batch 430 d_loss : 0.351370\n",
      "batch 430 g1_loss : 0.480915\n",
      "batch 430 g_loss : 1.657447\n",
      "batch 431 d_loss : 0.349988\n",
      "batch 431 g1_loss : 0.479734\n",
      "batch 431 g_loss : 1.485792\n",
      "batch 432 d_loss : 0.340504\n",
      "batch 432 g1_loss : 0.486574\n",
      "batch 432 g_loss : 1.533699\n",
      "batch 433 d_loss : 0.368104\n",
      "batch 433 g1_loss : 0.480011\n",
      "batch 433 g_loss : 1.642700\n",
      "batch 434 d_loss : 0.378574\n",
      "batch 434 g1_loss : 0.466704\n",
      "batch 434 g_loss : 1.384201\n",
      "batch 435 d_loss : 0.361109\n",
      "batch 435 g1_loss : 0.491642\n",
      "batch 435 g_loss : 1.588850\n",
      "batch 436 d_loss : 0.319938\n",
      "batch 436 g1_loss : 0.505588\n",
      "batch 436 g_loss : 1.689634\n",
      "batch 437 d_loss : 0.337703\n",
      "batch 437 g1_loss : 0.509465\n",
      "batch 437 g_loss : 1.274534\n",
      "batch 438 d_loss : 0.354523\n",
      "batch 438 g1_loss : 0.472540\n",
      "batch 438 g_loss : 1.483787\n",
      "batch 439 d_loss : 0.364351\n",
      "batch 439 g1_loss : 0.491862\n",
      "batch 439 g_loss : 1.397944\n",
      "batch 440 d_loss : 0.363050\n",
      "batch 440 g1_loss : 0.483032\n",
      "batch 440 g_loss : 1.449577\n",
      "batch 441 d_loss : 0.421504\n",
      "batch 441 g1_loss : 0.483602\n",
      "batch 441 g_loss : 1.034666\n",
      "batch 442 d_loss : 0.418820\n",
      "batch 442 g1_loss : 0.481416\n",
      "batch 442 g_loss : 1.494949\n",
      "batch 443 d_loss : 0.389015\n",
      "batch 443 g1_loss : 0.456682\n",
      "batch 443 g_loss : 1.489457\n",
      "batch 444 d_loss : 0.339993\n",
      "batch 444 g1_loss : 0.483949\n",
      "batch 444 g_loss : 1.563090\n",
      "batch 445 d_loss : 0.419050\n",
      "batch 445 g1_loss : 0.509503\n",
      "batch 445 g_loss : 1.150573\n",
      "batch 446 d_loss : 0.375706\n",
      "batch 446 g1_loss : 0.520391\n",
      "batch 446 g_loss : 1.390497\n",
      "batch 447 d_loss : 0.330210\n",
      "batch 447 g1_loss : 0.506785\n",
      "batch 447 g_loss : 1.432045\n",
      "batch 448 d_loss : 0.339382\n",
      "batch 448 g1_loss : 0.510783\n",
      "batch 448 g_loss : 1.368532\n",
      "batch 449 d_loss : 0.345770\n",
      "batch 449 g1_loss : 0.498150\n",
      "batch 449 g_loss : 1.645378\n",
      "batch 450 d_loss : 0.338084\n",
      "batch 450 g1_loss : 0.503708\n",
      "batch 450 g_loss : 1.348577\n",
      "batch 451 d_loss : 0.346271\n",
      "batch 451 g1_loss : 0.512088\n",
      "batch 451 g_loss : 1.533026\n",
      "batch 452 d_loss : 0.387877\n",
      "batch 452 g1_loss : 0.494454\n",
      "batch 452 g_loss : 1.171129\n",
      "batch 453 d_loss : 0.371969\n",
      "batch 453 g1_loss : 0.499424\n",
      "batch 453 g_loss : 1.582938\n",
      "batch 454 d_loss : 0.327906\n",
      "batch 454 g1_loss : 0.506659\n",
      "batch 454 g_loss : 1.442733\n",
      "batch 455 d_loss : 0.310143\n",
      "batch 455 g1_loss : 0.494552\n",
      "batch 455 g_loss : 1.663000\n",
      "batch 456 d_loss : 0.360571\n",
      "batch 456 g1_loss : 0.511120\n",
      "batch 456 g_loss : 1.412939\n",
      "batch 457 d_loss : 0.335705\n",
      "batch 457 g1_loss : 0.484905\n",
      "batch 457 g_loss : 1.499243\n",
      "batch 458 d_loss : 0.268351\n",
      "batch 458 g1_loss : 0.513697\n",
      "batch 458 g_loss : 1.840255\n",
      "batch 459 d_loss : 0.338155\n",
      "batch 459 g1_loss : 0.486330\n",
      "batch 459 g_loss : 1.285119\n",
      "batch 460 d_loss : 0.320961\n",
      "batch 460 g1_loss : 0.497953\n",
      "batch 460 g_loss : 1.671436\n",
      "batch 461 d_loss : 0.261296\n",
      "batch 461 g1_loss : 0.507905\n",
      "batch 461 g_loss : 1.724238\n",
      "batch 462 d_loss : 0.294459\n",
      "batch 462 g1_loss : 0.492768\n",
      "batch 462 g_loss : 1.471853\n",
      "batch 463 d_loss : 0.403439\n",
      "batch 463 g1_loss : 0.503246\n",
      "batch 463 g_loss : 1.549101\n",
      "batch 464 d_loss : 0.469650\n",
      "batch 464 g1_loss : 0.488916\n",
      "batch 464 g_loss : 1.459311\n",
      "batch 465 d_loss : 0.269948\n",
      "batch 465 g1_loss : 0.477358\n",
      "batch 465 g_loss : 1.741158\n",
      "batch 466 d_loss : 0.328510\n",
      "batch 466 g1_loss : 0.490369\n",
      "batch 466 g_loss : 1.315323\n",
      "batch 467 d_loss : 0.339484\n",
      "batch 467 g1_loss : 0.479692\n",
      "batch 467 g_loss : 1.519633\n",
      "('Epoch is', 3)\n",
      "('Number of batches', 468)\n",
      "batch 0 d_loss : 0.375877\n",
      "batch 0 g1_loss : 0.501213\n",
      "batch 0 g_loss : 1.328211\n",
      "batch 1 d_loss : 0.383434\n",
      "batch 1 g1_loss : 0.484405\n",
      "batch 1 g_loss : 1.310137\n",
      "batch 2 d_loss : 0.355730\n",
      "batch 2 g1_loss : 0.498321\n",
      "batch 2 g_loss : 1.547747\n",
      "batch 3 d_loss : 0.405160\n",
      "batch 3 g1_loss : 0.461886\n",
      "batch 3 g_loss : 1.354537\n",
      "batch 4 d_loss : 0.379270\n",
      "batch 4 g1_loss : 0.498099\n",
      "batch 4 g_loss : 1.482808\n",
      "batch 5 d_loss : 0.411549\n",
      "batch 5 g1_loss : 0.497509\n",
      "batch 5 g_loss : 1.555320\n",
      "batch 6 d_loss : 0.352854\n",
      "batch 6 g1_loss : 0.472578\n",
      "batch 6 g_loss : 1.501459\n",
      "batch 7 d_loss : 0.359894\n",
      "batch 7 g1_loss : 0.473988\n",
      "batch 7 g_loss : 1.473230\n",
      "batch 8 d_loss : 0.401492\n",
      "batch 8 g1_loss : 0.480949\n",
      "batch 8 g_loss : 1.100286\n",
      "batch 9 d_loss : 0.449391\n",
      "batch 9 g1_loss : 0.485858\n",
      "batch 9 g_loss : 1.593344\n",
      "batch 10 d_loss : 0.371266\n",
      "batch 10 g1_loss : 0.502230\n",
      "batch 10 g_loss : 1.543382\n",
      "batch 11 d_loss : 0.407087\n",
      "batch 11 g1_loss : 0.485558\n",
      "batch 11 g_loss : 1.408319\n",
      "batch 12 d_loss : 0.358346\n",
      "batch 12 g1_loss : 0.482426\n",
      "batch 12 g_loss : 1.440461\n",
      "batch 13 d_loss : 0.346338\n",
      "batch 13 g1_loss : 0.493432\n",
      "batch 13 g_loss : 1.426807\n",
      "batch 14 d_loss : 0.413999\n",
      "batch 14 g1_loss : 0.496825\n",
      "batch 14 g_loss : 1.151090\n",
      "batch 15 d_loss : 0.429817\n",
      "batch 15 g1_loss : 0.513209\n",
      "batch 15 g_loss : 1.415984\n",
      "batch 16 d_loss : 0.346829\n",
      "batch 16 g1_loss : 0.508570\n",
      "batch 16 g_loss : 1.532397\n",
      "batch 17 d_loss : 0.353097\n",
      "batch 17 g1_loss : 0.493377\n",
      "batch 17 g_loss : 1.420064\n",
      "batch 18 d_loss : 0.384775\n",
      "batch 18 g1_loss : 0.515171\n",
      "batch 18 g_loss : 1.180702\n",
      "batch 19 d_loss : 0.355274\n",
      "batch 19 g1_loss : 0.515295\n",
      "batch 19 g_loss : 1.613273\n",
      "batch 20 d_loss : 0.345792\n",
      "batch 20 g1_loss : 0.505494\n",
      "batch 20 g_loss : 1.476695\n",
      "batch 21 d_loss : 0.441869\n",
      "batch 21 g1_loss : 0.515769\n",
      "batch 21 g_loss : 0.910631\n",
      "batch 22 d_loss : 0.453655\n",
      "batch 22 g1_loss : 0.508751\n",
      "batch 22 g_loss : 1.411737\n",
      "batch 23 d_loss : 0.336284\n",
      "batch 23 g1_loss : 0.497578\n",
      "batch 23 g_loss : 1.798735\n",
      "batch 24 d_loss : 0.312002\n",
      "batch 24 g1_loss : 0.498296\n",
      "batch 24 g_loss : 1.290995\n",
      "batch 25 d_loss : 0.364223\n",
      "batch 25 g1_loss : 0.502823\n",
      "batch 25 g_loss : 1.261806\n",
      "batch 26 d_loss : 0.362529\n",
      "batch 26 g1_loss : 0.498667\n",
      "batch 26 g_loss : 1.456713\n",
      "batch 27 d_loss : 0.385918\n",
      "batch 27 g1_loss : 0.513361\n",
      "batch 27 g_loss : 1.503118\n",
      "batch 28 d_loss : 0.439963\n",
      "batch 28 g1_loss : 0.502655\n",
      "batch 28 g_loss : 1.162605\n",
      "batch 29 d_loss : 0.393288\n",
      "batch 29 g1_loss : 0.510116\n",
      "batch 29 g_loss : 1.410758\n",
      "batch 30 d_loss : 0.310257\n",
      "batch 30 g1_loss : 0.501133\n",
      "batch 30 g_loss : 1.552576\n",
      "batch 31 d_loss : 0.398023\n",
      "batch 31 g1_loss : 0.490880\n",
      "batch 31 g_loss : 1.317855\n",
      "batch 32 d_loss : 0.391070\n",
      "batch 32 g1_loss : 0.496749\n",
      "batch 32 g_loss : 1.261807\n",
      "batch 33 d_loss : 0.340278\n",
      "batch 33 g1_loss : 0.487987\n",
      "batch 33 g_loss : 1.605163\n",
      "batch 34 d_loss : 0.377480\n",
      "batch 34 g1_loss : 0.493078\n",
      "batch 34 g_loss : 1.116026\n",
      "batch 35 d_loss : 0.431550\n",
      "batch 35 g1_loss : 0.469391\n",
      "batch 35 g_loss : 1.510310\n",
      "batch 36 d_loss : 0.454314\n",
      "batch 36 g1_loss : 0.472800\n",
      "batch 36 g_loss : 1.102376\n",
      "batch 37 d_loss : 0.438426\n",
      "batch 37 g1_loss : 0.484666\n",
      "batch 37 g_loss : 1.340990\n",
      "batch 38 d_loss : 0.386795\n",
      "batch 38 g1_loss : 0.465713\n",
      "batch 38 g_loss : 1.523278\n",
      "batch 39 d_loss : 0.390543\n",
      "batch 39 g1_loss : 0.450267\n",
      "batch 39 g_loss : 1.291542\n",
      "batch 40 d_loss : 0.359361\n",
      "batch 40 g1_loss : 0.450498\n",
      "batch 40 g_loss : 1.335229\n",
      "batch 41 d_loss : 0.399279\n",
      "batch 41 g1_loss : 0.473636\n",
      "batch 41 g_loss : 1.276163\n",
      "batch 42 d_loss : 0.416487\n",
      "batch 42 g1_loss : 0.460257\n",
      "batch 42 g_loss : 1.355621\n",
      "batch 43 d_loss : 0.358252\n",
      "batch 43 g1_loss : 0.467751\n",
      "batch 43 g_loss : 1.465727\n",
      "batch 44 d_loss : 0.401523\n",
      "batch 44 g1_loss : 0.440533\n",
      "batch 44 g_loss : 1.302369\n",
      "batch 45 d_loss : 0.389134\n",
      "batch 45 g1_loss : 0.452315\n",
      "batch 45 g_loss : 1.367901\n",
      "batch 46 d_loss : 0.386668\n",
      "batch 46 g1_loss : 0.464153\n",
      "batch 46 g_loss : 1.472640\n",
      "batch 47 d_loss : 0.445991\n",
      "batch 47 g1_loss : 0.461109\n",
      "batch 47 g_loss : 1.256052\n",
      "batch 48 d_loss : 0.418456\n",
      "batch 48 g1_loss : 0.427734\n",
      "batch 48 g_loss : 1.707217\n",
      "batch 49 d_loss : 0.394115\n",
      "batch 49 g1_loss : 0.444496\n",
      "batch 49 g_loss : 1.426775\n",
      "batch 50 d_loss : 0.392602\n",
      "batch 50 g1_loss : 0.437537\n",
      "batch 50 g_loss : 1.161903\n",
      "batch 51 d_loss : 0.389697\n",
      "batch 51 g1_loss : 0.446874\n",
      "batch 51 g_loss : 1.929707\n",
      "batch 52 d_loss : 0.528272\n",
      "batch 52 g1_loss : 0.463003\n",
      "batch 52 g_loss : 0.653725\n",
      "batch 53 d_loss : 0.530370\n",
      "batch 53 g1_loss : 0.450294\n",
      "batch 53 g_loss : 1.779176\n",
      "batch 54 d_loss : 0.423013\n",
      "batch 54 g1_loss : 0.464985\n",
      "batch 54 g_loss : 1.322871\n",
      "batch 55 d_loss : 0.370587\n",
      "batch 55 g1_loss : 0.435355\n",
      "batch 55 g_loss : 1.304908\n",
      "batch 56 d_loss : 0.507835\n",
      "batch 56 g1_loss : 0.469260\n",
      "batch 56 g_loss : 0.837068\n",
      "batch 57 d_loss : 0.546267\n",
      "batch 57 g1_loss : 0.456962\n",
      "batch 57 g_loss : 1.079503\n",
      "batch 58 d_loss : 0.388991\n",
      "batch 58 g1_loss : 0.437417\n",
      "batch 58 g_loss : 1.905858\n",
      "batch 59 d_loss : 0.461942\n",
      "batch 59 g1_loss : 0.485822\n",
      "batch 59 g_loss : 0.848475\n",
      "batch 60 d_loss : 0.450170\n",
      "batch 60 g1_loss : 0.451629\n",
      "batch 60 g_loss : 1.616598\n",
      "batch 61 d_loss : 0.463706\n",
      "batch 61 g1_loss : 0.430565\n",
      "batch 61 g_loss : 1.059801\n",
      "batch 62 d_loss : 0.476667\n",
      "batch 62 g1_loss : 0.460188\n",
      "batch 62 g_loss : 1.541415\n",
      "batch 63 d_loss : 0.415342\n",
      "batch 63 g1_loss : 0.449003\n",
      "batch 63 g_loss : 1.147505\n",
      "batch 64 d_loss : 0.410142\n",
      "batch 64 g1_loss : 0.464358\n",
      "batch 64 g_loss : 1.463179\n",
      "batch 65 d_loss : 0.472520\n",
      "batch 65 g1_loss : 0.468997\n",
      "batch 65 g_loss : 0.841523\n",
      "batch 66 d_loss : 0.531859\n",
      "batch 66 g1_loss : 0.453514\n",
      "batch 66 g_loss : 1.519841\n",
      "batch 67 d_loss : 0.485162\n",
      "batch 67 g1_loss : 0.474806\n",
      "batch 67 g_loss : 1.065038\n",
      "batch 68 d_loss : 0.411628\n",
      "batch 68 g1_loss : 0.463389\n",
      "batch 68 g_loss : 1.370811\n",
      "batch 69 d_loss : 0.407867\n",
      "batch 69 g1_loss : 0.463837\n",
      "batch 69 g_loss : 1.114277\n",
      "batch 70 d_loss : 0.388786\n",
      "batch 70 g1_loss : 0.464570\n",
      "batch 70 g_loss : 1.524910\n",
      "batch 71 d_loss : 0.411899\n",
      "batch 71 g1_loss : 0.456859\n",
      "batch 71 g_loss : 0.985142\n",
      "batch 72 d_loss : 0.464048\n",
      "batch 72 g1_loss : 0.476674\n",
      "batch 72 g_loss : 1.344185\n",
      "batch 73 d_loss : 0.373191\n",
      "batch 73 g1_loss : 0.474834\n",
      "batch 73 g_loss : 1.448021\n",
      "batch 74 d_loss : 0.456672\n",
      "batch 74 g1_loss : 0.434356\n",
      "batch 74 g_loss : 1.157966\n",
      "batch 75 d_loss : 0.426389\n",
      "batch 75 g1_loss : 0.465225\n",
      "batch 75 g_loss : 1.261010\n",
      "batch 76 d_loss : 0.393950\n",
      "batch 76 g1_loss : 0.456802\n",
      "batch 76 g_loss : 1.375921\n",
      "batch 77 d_loss : 0.398267\n",
      "batch 77 g1_loss : 0.465929\n",
      "batch 77 g_loss : 1.205969\n",
      "batch 78 d_loss : 0.398939\n",
      "batch 78 g1_loss : 0.452131\n",
      "batch 78 g_loss : 1.303857\n",
      "batch 79 d_loss : 0.429969\n",
      "batch 79 g1_loss : 0.445887\n",
      "batch 79 g_loss : 1.184747\n",
      "batch 80 d_loss : 0.445714\n",
      "batch 80 g1_loss : 0.439895\n",
      "batch 80 g_loss : 1.369912\n",
      "batch 81 d_loss : 0.403677\n",
      "batch 81 g1_loss : 0.462942\n",
      "batch 81 g_loss : 1.346567\n",
      "batch 82 d_loss : 0.406012\n",
      "batch 82 g1_loss : 0.445737\n",
      "batch 82 g_loss : 1.147787\n",
      "batch 83 d_loss : 0.430904\n",
      "batch 83 g1_loss : 0.467563\n",
      "batch 83 g_loss : 1.245168\n",
      "batch 84 d_loss : 0.398633\n",
      "batch 84 g1_loss : 0.446728\n",
      "batch 84 g_loss : 1.257389\n",
      "batch 85 d_loss : 0.449285\n",
      "batch 85 g1_loss : 0.422546\n",
      "batch 85 g_loss : 1.215021\n",
      "batch 86 d_loss : 0.448577\n",
      "batch 86 g1_loss : 0.426374\n",
      "batch 86 g_loss : 1.305634\n",
      "batch 87 d_loss : 0.397486\n",
      "batch 87 g1_loss : 0.460068\n",
      "batch 87 g_loss : 1.267568\n",
      "batch 88 d_loss : 0.435701\n",
      "batch 88 g1_loss : 0.462710\n",
      "batch 88 g_loss : 1.083111\n",
      "batch 89 d_loss : 0.433815\n",
      "batch 89 g1_loss : 0.441961\n",
      "batch 89 g_loss : 1.084281\n",
      "batch 90 d_loss : 0.483034\n",
      "batch 90 g1_loss : 0.442395\n",
      "batch 90 g_loss : 1.178550\n",
      "batch 91 d_loss : 0.458539\n",
      "batch 91 g1_loss : 0.417642\n",
      "batch 91 g_loss : 1.020788\n",
      "batch 92 d_loss : 0.430555\n",
      "batch 92 g1_loss : 0.470976\n",
      "batch 92 g_loss : 1.565290\n",
      "batch 93 d_loss : 0.495230\n",
      "batch 93 g1_loss : 0.457088\n",
      "batch 93 g_loss : 0.931702\n",
      "batch 94 d_loss : 0.461892\n",
      "batch 94 g1_loss : 0.453140\n",
      "batch 94 g_loss : 1.341032\n",
      "batch 95 d_loss : 0.421836\n",
      "batch 95 g1_loss : 0.433293\n",
      "batch 95 g_loss : 1.065288\n",
      "batch 96 d_loss : 0.477249\n",
      "batch 96 g1_loss : 0.437733\n",
      "batch 96 g_loss : 1.152964\n",
      "batch 97 d_loss : 0.424829\n",
      "batch 97 g1_loss : 0.428903\n",
      "batch 97 g_loss : 1.494952\n",
      "batch 98 d_loss : 0.367991\n",
      "batch 98 g1_loss : 0.439250\n",
      "batch 98 g_loss : 1.085719\n",
      "batch 99 d_loss : 0.388277\n",
      "batch 99 g1_loss : 0.432869\n",
      "batch 99 g_loss : 1.352811\n",
      "batch 100 d_loss : 0.428796\n",
      "batch 100 g1_loss : 0.441825\n",
      "batch 100 g_loss : 1.092435\n",
      "batch 101 d_loss : 0.536729\n",
      "batch 101 g1_loss : 0.449081\n",
      "batch 101 g_loss : 1.041416\n",
      "batch 102 d_loss : 0.483871\n",
      "batch 102 g1_loss : 0.419810\n",
      "batch 102 g_loss : 1.278017\n",
      "batch 103 d_loss : 0.439412\n",
      "batch 103 g1_loss : 0.431904\n",
      "batch 103 g_loss : 1.148823\n",
      "batch 104 d_loss : 0.428591\n",
      "batch 104 g1_loss : 0.417194\n",
      "batch 104 g_loss : 1.347788\n",
      "batch 105 d_loss : 0.387904\n",
      "batch 105 g1_loss : 0.446295\n",
      "batch 105 g_loss : 1.348086\n",
      "batch 106 d_loss : 0.477559\n",
      "batch 106 g1_loss : 0.426446\n",
      "batch 106 g_loss : 0.776557\n",
      "batch 107 d_loss : 0.451051\n",
      "batch 107 g1_loss : 0.429071\n",
      "batch 107 g_loss : 1.812991\n",
      "batch 108 d_loss : 0.456789\n",
      "batch 108 g1_loss : 0.447955\n",
      "batch 108 g_loss : 0.938363\n",
      "batch 109 d_loss : 0.536362\n",
      "batch 109 g1_loss : 0.455302\n",
      "batch 109 g_loss : 1.271062\n",
      "batch 110 d_loss : 0.528855\n",
      "batch 110 g1_loss : 0.439899\n",
      "batch 110 g_loss : 1.041713\n",
      "batch 111 d_loss : 0.499767\n",
      "batch 111 g1_loss : 0.438126\n",
      "batch 111 g_loss : 1.021286\n",
      "batch 112 d_loss : 0.433183\n",
      "batch 112 g1_loss : 0.465796\n",
      "batch 112 g_loss : 1.308685\n",
      "batch 113 d_loss : 0.454804\n",
      "batch 113 g1_loss : 0.455220\n",
      "batch 113 g_loss : 0.955503\n",
      "batch 114 d_loss : 0.467562\n",
      "batch 114 g1_loss : 0.424751\n",
      "batch 114 g_loss : 1.321709\n",
      "batch 115 d_loss : 0.523037\n",
      "batch 115 g1_loss : 0.427722\n",
      "batch 115 g_loss : 0.824242\n",
      "batch 116 d_loss : 0.436345\n",
      "batch 116 g1_loss : 0.441287\n",
      "batch 116 g_loss : 1.745266\n",
      "batch 117 d_loss : 0.409144\n",
      "batch 117 g1_loss : 0.472707\n",
      "batch 117 g_loss : 0.994489\n",
      "batch 118 d_loss : 0.426520\n",
      "batch 118 g1_loss : 0.436539\n",
      "batch 118 g_loss : 1.867517\n",
      "batch 119 d_loss : 0.391895\n",
      "batch 119 g1_loss : 0.441503\n",
      "batch 119 g_loss : 0.946280\n",
      "batch 120 d_loss : 0.404387\n",
      "batch 120 g1_loss : 0.420338\n",
      "batch 120 g_loss : 1.681441\n",
      "batch 121 d_loss : 0.390199\n",
      "batch 121 g1_loss : 0.420613\n",
      "batch 121 g_loss : 0.990010\n",
      "batch 122 d_loss : 0.387225\n",
      "batch 122 g1_loss : 0.422027\n",
      "batch 122 g_loss : 2.106378\n",
      "batch 123 d_loss : 0.408065\n",
      "batch 123 g1_loss : 0.420999\n",
      "batch 123 g_loss : 0.878632\n",
      "batch 124 d_loss : 0.544584\n",
      "batch 124 g1_loss : 0.412130\n",
      "batch 124 g_loss : 1.443985\n",
      "batch 125 d_loss : 0.527911\n",
      "batch 125 g1_loss : 0.432985\n",
      "batch 125 g_loss : 0.794610\n",
      "batch 126 d_loss : 0.495469\n",
      "batch 126 g1_loss : 0.424626\n",
      "batch 126 g_loss : 1.747152\n",
      "batch 127 d_loss : 0.418705\n",
      "batch 127 g1_loss : 0.404686\n",
      "batch 127 g_loss : 0.989237\n",
      "batch 128 d_loss : 0.367934\n",
      "batch 128 g1_loss : 0.400691\n",
      "batch 128 g_loss : 1.756547\n",
      "batch 129 d_loss : 0.353993\n",
      "batch 129 g1_loss : 0.395577\n",
      "batch 129 g_loss : 1.159716\n",
      "batch 130 d_loss : 0.391666\n",
      "batch 130 g1_loss : 0.382977\n",
      "batch 130 g_loss : 1.392226\n",
      "batch 131 d_loss : 0.354590\n",
      "batch 131 g1_loss : 0.388961\n",
      "batch 131 g_loss : 1.387362\n",
      "batch 132 d_loss : 0.427549\n",
      "batch 132 g1_loss : 0.373384\n",
      "batch 132 g_loss : 1.138848\n",
      "batch 133 d_loss : 0.411693\n",
      "batch 133 g1_loss : 0.385393\n",
      "batch 133 g_loss : 1.562730\n",
      "batch 134 d_loss : 0.385424\n",
      "batch 134 g1_loss : 0.384698\n",
      "batch 134 g_loss : 1.286784\n",
      "batch 135 d_loss : 0.372551\n",
      "batch 135 g1_loss : 0.376717\n",
      "batch 135 g_loss : 1.732859\n",
      "batch 136 d_loss : 0.402752\n",
      "batch 136 g1_loss : 0.378532\n",
      "batch 136 g_loss : 0.971257\n",
      "batch 137 d_loss : 0.402127\n",
      "batch 137 g1_loss : 0.365654\n",
      "batch 137 g_loss : 1.552948\n",
      "batch 138 d_loss : 0.379630\n",
      "batch 138 g1_loss : 0.365882\n",
      "batch 138 g_loss : 1.185867\n",
      "batch 139 d_loss : 0.401236\n",
      "batch 139 g1_loss : 0.369320\n",
      "batch 139 g_loss : 1.582325\n",
      "batch 140 d_loss : 0.366583\n",
      "batch 140 g1_loss : 0.361305\n",
      "batch 140 g_loss : 1.389649\n",
      "batch 141 d_loss : 0.348765\n",
      "batch 141 g1_loss : 0.379414\n",
      "batch 141 g_loss : 1.630975\n",
      "batch 142 d_loss : 0.428506\n",
      "batch 142 g1_loss : 0.391106\n",
      "batch 142 g_loss : 0.989519\n",
      "batch 143 d_loss : 0.453388\n",
      "batch 143 g1_loss : 0.389380\n",
      "batch 143 g_loss : 2.086011\n",
      "batch 144 d_loss : 0.475487\n",
      "batch 144 g1_loss : 0.401702\n",
      "batch 144 g_loss : 1.015373\n",
      "batch 145 d_loss : 0.385638\n",
      "batch 145 g1_loss : 0.414701\n",
      "batch 145 g_loss : 2.362153\n",
      "batch 146 d_loss : 0.417398\n",
      "batch 146 g1_loss : 0.400149\n",
      "batch 146 g_loss : 1.112716\n",
      "batch 147 d_loss : 0.399360\n",
      "batch 147 g1_loss : 0.417848\n",
      "batch 147 g_loss : 1.797232\n",
      "batch 148 d_loss : 0.391538\n",
      "batch 148 g1_loss : 0.392438\n",
      "batch 148 g_loss : 0.928110\n",
      "batch 149 d_loss : 0.431446\n",
      "batch 149 g1_loss : 0.438629\n",
      "batch 149 g_loss : 2.095595\n",
      "batch 150 d_loss : 0.484112\n",
      "batch 150 g1_loss : 0.447548\n",
      "batch 150 g_loss : 0.984514\n",
      "batch 151 d_loss : 0.470756\n",
      "batch 151 g1_loss : 0.413086\n",
      "batch 151 g_loss : 1.716670\n",
      "batch 152 d_loss : 0.509891\n",
      "batch 152 g1_loss : 0.466609\n",
      "batch 152 g_loss : 0.896582\n",
      "batch 153 d_loss : 0.466309\n",
      "batch 153 g1_loss : 0.451658\n",
      "batch 153 g_loss : 1.613150\n",
      "batch 154 d_loss : 0.393392\n",
      "batch 154 g1_loss : 0.445382\n",
      "batch 154 g_loss : 1.508291\n",
      "batch 155 d_loss : 0.418170\n",
      "batch 155 g1_loss : 0.462777\n",
      "batch 155 g_loss : 1.125016\n",
      "batch 156 d_loss : 0.430544\n",
      "batch 156 g1_loss : 0.471037\n",
      "batch 156 g_loss : 1.308839\n",
      "batch 157 d_loss : 0.396690\n",
      "batch 157 g1_loss : 0.469059\n",
      "batch 157 g_loss : 1.364341\n",
      "batch 158 d_loss : 0.429367\n",
      "batch 158 g1_loss : 0.460054\n",
      "batch 158 g_loss : 1.148813\n",
      "batch 159 d_loss : 0.394303\n",
      "batch 159 g1_loss : 0.485502\n",
      "batch 159 g_loss : 1.471223\n",
      "batch 160 d_loss : 0.391139\n",
      "batch 160 g1_loss : 0.483214\n",
      "batch 160 g_loss : 1.383460\n",
      "batch 161 d_loss : 0.412099\n",
      "batch 161 g1_loss : 0.468504\n",
      "batch 161 g_loss : 1.079159\n",
      "batch 162 d_loss : 0.419182\n",
      "batch 162 g1_loss : 0.466876\n",
      "batch 162 g_loss : 1.292523\n",
      "batch 163 d_loss : 0.450488\n",
      "batch 163 g1_loss : 0.499736\n",
      "batch 163 g_loss : 1.085701\n",
      "batch 164 d_loss : 0.383611\n",
      "batch 164 g1_loss : 0.503547\n",
      "batch 164 g_loss : 1.545411\n",
      "batch 165 d_loss : 0.354210\n",
      "batch 165 g1_loss : 0.505072\n",
      "batch 165 g_loss : 1.323137\n",
      "batch 166 d_loss : 0.370782\n",
      "batch 166 g1_loss : 0.472830\n",
      "batch 166 g_loss : 1.436058\n",
      "batch 167 d_loss : 0.388190\n",
      "batch 167 g1_loss : 0.474295\n",
      "batch 167 g_loss : 1.213904\n",
      "batch 168 d_loss : 0.341457\n",
      "batch 168 g1_loss : 0.489953\n",
      "batch 168 g_loss : 1.802411\n",
      "batch 169 d_loss : 0.327119\n",
      "batch 169 g1_loss : 0.488354\n",
      "batch 169 g_loss : 1.125889\n",
      "batch 170 d_loss : 0.499758\n",
      "batch 170 g1_loss : 0.505987\n",
      "batch 170 g_loss : 1.180657\n",
      "batch 171 d_loss : 0.483063\n",
      "batch 171 g1_loss : 0.479497\n",
      "batch 171 g_loss : 1.357956\n",
      "batch 172 d_loss : 0.351553\n",
      "batch 172 g1_loss : 0.473109\n",
      "batch 172 g_loss : 1.658189\n",
      "batch 173 d_loss : 0.364382\n",
      "batch 173 g1_loss : 0.485507\n",
      "batch 173 g_loss : 1.285665\n",
      "batch 174 d_loss : 0.332944\n",
      "batch 174 g1_loss : 0.486229\n",
      "batch 174 g_loss : 1.485861\n",
      "batch 175 d_loss : 0.448663\n",
      "batch 175 g1_loss : 0.482773\n",
      "batch 175 g_loss : 0.909394\n",
      "batch 176 d_loss : 0.582015\n",
      "batch 176 g1_loss : 0.471913\n",
      "batch 176 g_loss : 1.531445\n",
      "batch 177 d_loss : 0.589409\n",
      "batch 177 g1_loss : 0.463862\n",
      "batch 177 g_loss : 0.938756\n",
      "batch 178 d_loss : 0.495144\n",
      "batch 178 g1_loss : 0.460681\n",
      "batch 178 g_loss : 1.336079\n",
      "batch 179 d_loss : 0.454300\n",
      "batch 179 g1_loss : 0.453048\n",
      "batch 179 g_loss : 1.109785\n",
      "batch 180 d_loss : 0.430183\n",
      "batch 180 g1_loss : 0.451249\n",
      "batch 180 g_loss : 1.547796\n",
      "batch 181 d_loss : 0.417571\n",
      "batch 181 g1_loss : 0.443715\n",
      "batch 181 g_loss : 1.123299\n",
      "batch 182 d_loss : 0.412376\n",
      "batch 182 g1_loss : 0.445463\n",
      "batch 182 g_loss : 1.486097\n",
      "batch 183 d_loss : 0.391502\n",
      "batch 183 g1_loss : 0.437668\n",
      "batch 183 g_loss : 1.093726\n",
      "batch 184 d_loss : 0.395701\n",
      "batch 184 g1_loss : 0.464538\n",
      "batch 184 g_loss : 1.736220\n",
      "batch 185 d_loss : 0.428975\n",
      "batch 185 g1_loss : 0.451474\n",
      "batch 185 g_loss : 0.909617\n",
      "batch 186 d_loss : 0.410979\n",
      "batch 186 g1_loss : 0.465288\n",
      "batch 186 g_loss : 1.695813\n",
      "batch 187 d_loss : 0.436031\n",
      "batch 187 g1_loss : 0.450446\n",
      "batch 187 g_loss : 1.018396\n",
      "batch 188 d_loss : 0.470921\n",
      "batch 188 g1_loss : 0.453452\n",
      "batch 188 g_loss : 1.640289\n",
      "batch 189 d_loss : 0.435135\n",
      "batch 189 g1_loss : 0.447179\n",
      "batch 189 g_loss : 0.882644\n",
      "batch 190 d_loss : 0.419480\n",
      "batch 190 g1_loss : 0.444173\n",
      "batch 190 g_loss : 1.839343\n",
      "batch 191 d_loss : 0.461664\n",
      "batch 191 g1_loss : 0.449755\n",
      "batch 191 g_loss : 0.824338\n",
      "batch 192 d_loss : 0.468035\n",
      "batch 192 g1_loss : 0.464672\n",
      "batch 192 g_loss : 1.828729\n",
      "batch 193 d_loss : 0.493502\n",
      "batch 193 g1_loss : 0.472129\n",
      "batch 193 g_loss : 0.699154\n",
      "batch 194 d_loss : 0.467730\n",
      "batch 194 g1_loss : 0.450991\n",
      "batch 194 g_loss : 2.031412\n",
      "batch 195 d_loss : 0.450492\n",
      "batch 195 g1_loss : 0.461471\n",
      "batch 195 g_loss : 0.705246\n",
      "batch 196 d_loss : 0.461524\n",
      "batch 196 g1_loss : 0.468292\n",
      "batch 196 g_loss : 2.268150\n",
      "batch 197 d_loss : 0.542373\n",
      "batch 197 g1_loss : 0.466138\n",
      "batch 197 g_loss : 0.893338\n",
      "batch 198 d_loss : 0.488594\n",
      "batch 198 g1_loss : 0.463781\n",
      "batch 198 g_loss : 1.660463\n",
      "batch 199 d_loss : 0.451114\n",
      "batch 199 g1_loss : 0.473333\n",
      "batch 199 g_loss : 0.977732\n",
      "batch 200 d_loss : 0.382774\n",
      "batch 200 g1_loss : 0.472520\n",
      "batch 200 g_loss : 1.691315\n",
      "batch 201 d_loss : 0.391987\n",
      "batch 201 g1_loss : 0.479995\n",
      "batch 201 g_loss : 0.957714\n",
      "batch 202 d_loss : 0.362152\n",
      "batch 202 g1_loss : 0.452738\n",
      "batch 202 g_loss : 1.920048\n",
      "batch 203 d_loss : 0.469938\n",
      "batch 203 g1_loss : 0.470917\n",
      "batch 203 g_loss : 0.829008\n",
      "batch 204 d_loss : 0.468023\n",
      "batch 204 g1_loss : 0.483006\n",
      "batch 204 g_loss : 2.068777\n",
      "batch 205 d_loss : 0.396747\n",
      "batch 205 g1_loss : 0.434386\n",
      "batch 205 g_loss : 0.965483\n",
      "batch 206 d_loss : 0.406849\n",
      "batch 206 g1_loss : 0.468564\n",
      "batch 206 g_loss : 1.945796\n",
      "batch 207 d_loss : 0.421795\n",
      "batch 207 g1_loss : 0.462337\n",
      "batch 207 g_loss : 0.726972\n",
      "batch 208 d_loss : 0.537963\n",
      "batch 208 g1_loss : 0.458936\n",
      "batch 208 g_loss : 2.268215\n",
      "batch 209 d_loss : 0.561596\n",
      "batch 209 g1_loss : 0.451375\n",
      "batch 209 g_loss : 0.674250\n",
      "batch 210 d_loss : 0.502087\n",
      "batch 210 g1_loss : 0.430229\n",
      "batch 210 g_loss : 2.744299\n",
      "batch 211 d_loss : 0.557750\n",
      "batch 211 g1_loss : 0.443405\n",
      "batch 211 g_loss : 0.789372\n",
      "batch 212 d_loss : 0.462457\n",
      "batch 212 g1_loss : 0.430612\n",
      "batch 212 g_loss : 2.054190\n",
      "batch 213 d_loss : 0.383154\n",
      "batch 213 g1_loss : 0.441058\n",
      "batch 213 g_loss : 0.911583\n",
      "batch 214 d_loss : 0.382653\n",
      "batch 214 g1_loss : 0.428217\n",
      "batch 214 g_loss : 2.027383\n",
      "batch 215 d_loss : 0.366480\n",
      "batch 215 g1_loss : 0.425046\n",
      "batch 215 g_loss : 1.061180\n",
      "batch 216 d_loss : 0.358445\n",
      "batch 216 g1_loss : 0.430399\n",
      "batch 216 g_loss : 1.967474\n",
      "batch 217 d_loss : 0.378053\n",
      "batch 217 g1_loss : 0.415122\n",
      "batch 217 g_loss : 0.819765\n",
      "batch 218 d_loss : 0.495399\n",
      "batch 218 g1_loss : 0.420721\n",
      "batch 218 g_loss : 1.940992\n",
      "batch 219 d_loss : 0.494257\n",
      "batch 219 g1_loss : 0.397415\n",
      "batch 219 g_loss : 0.838107\n",
      "batch 220 d_loss : 0.494999\n",
      "batch 220 g1_loss : 0.398714\n",
      "batch 220 g_loss : 2.107381\n",
      "batch 221 d_loss : 0.534245\n",
      "batch 221 g1_loss : 0.405020\n",
      "batch 221 g_loss : 0.816203\n",
      "batch 222 d_loss : 0.437087\n",
      "batch 222 g1_loss : 0.411492\n",
      "batch 222 g_loss : 1.924107\n",
      "batch 223 d_loss : 0.489049\n",
      "batch 223 g1_loss : 0.411916\n",
      "batch 223 g_loss : 0.744665\n",
      "batch 224 d_loss : 0.432286\n",
      "batch 224 g1_loss : 0.402409\n",
      "batch 224 g_loss : 2.179676\n",
      "batch 225 d_loss : 0.477367\n",
      "batch 225 g1_loss : 0.416088\n",
      "batch 225 g_loss : 0.886643\n",
      "batch 226 d_loss : 0.480537\n",
      "batch 226 g1_loss : 0.443796\n",
      "batch 226 g_loss : 2.096513\n",
      "batch 227 d_loss : 0.526089\n",
      "batch 227 g1_loss : 0.408472\n",
      "batch 227 g_loss : 0.577924\n",
      "batch 228 d_loss : 0.591111\n",
      "batch 228 g1_loss : 0.442501\n",
      "batch 228 g_loss : 2.543162\n",
      "batch 229 d_loss : 0.521129\n",
      "batch 229 g1_loss : 0.426857\n",
      "batch 229 g_loss : 1.103982\n",
      "batch 230 d_loss : 0.404495\n",
      "batch 230 g1_loss : 0.434770\n",
      "batch 230 g_loss : 1.893776\n",
      "batch 231 d_loss : 0.393949\n",
      "batch 231 g1_loss : 0.437200\n",
      "batch 231 g_loss : 1.092765\n",
      "batch 232 d_loss : 0.418232\n",
      "batch 232 g1_loss : 0.438144\n",
      "batch 232 g_loss : 1.470325\n",
      "batch 233 d_loss : 0.399140\n",
      "batch 233 g1_loss : 0.450115\n",
      "batch 233 g_loss : 1.043220\n",
      "batch 234 d_loss : 0.456647\n",
      "batch 234 g1_loss : 0.478572\n",
      "batch 234 g_loss : 1.578112\n",
      "batch 235 d_loss : 0.474454\n",
      "batch 235 g1_loss : 0.460355\n",
      "batch 235 g_loss : 0.753520\n",
      "batch 236 d_loss : 0.437837\n",
      "batch 236 g1_loss : 0.445187\n",
      "batch 236 g_loss : 2.122216\n",
      "batch 237 d_loss : 0.443394\n",
      "batch 237 g1_loss : 0.451466\n",
      "batch 237 g_loss : 1.040868\n",
      "batch 238 d_loss : 0.409423\n",
      "batch 238 g1_loss : 0.478905\n",
      "batch 238 g_loss : 1.757308\n",
      "batch 239 d_loss : 0.358950\n",
      "batch 239 g1_loss : 0.448611\n",
      "batch 239 g_loss : 1.075196\n",
      "batch 240 d_loss : 0.389990\n",
      "batch 240 g1_loss : 0.448535\n",
      "batch 240 g_loss : 1.790633\n",
      "batch 241 d_loss : 0.331847\n",
      "batch 241 g1_loss : 0.460292\n",
      "batch 241 g_loss : 1.380431\n",
      "batch 242 d_loss : 0.305491\n",
      "batch 242 g1_loss : 0.453968\n",
      "batch 242 g_loss : 1.653323\n",
      "batch 243 d_loss : 0.278725\n",
      "batch 243 g1_loss : 0.450636\n",
      "batch 243 g_loss : 1.559258\n",
      "batch 244 d_loss : 0.364755\n",
      "batch 244 g1_loss : 0.463131\n",
      "batch 244 g_loss : 1.466154\n",
      "batch 245 d_loss : 0.361036\n",
      "batch 245 g1_loss : 0.459005\n",
      "batch 245 g_loss : 1.829752\n",
      "batch 246 d_loss : 0.273256\n",
      "batch 246 g1_loss : 0.433666\n",
      "batch 246 g_loss : 1.477144\n",
      "batch 247 d_loss : 0.338246\n",
      "batch 247 g1_loss : 0.454312\n",
      "batch 247 g_loss : 1.670620\n",
      "batch 248 d_loss : 0.342956\n",
      "batch 248 g1_loss : 0.459841\n",
      "batch 248 g_loss : 1.371256\n",
      "batch 249 d_loss : 0.395593\n",
      "batch 249 g1_loss : 0.432556\n",
      "batch 249 g_loss : 1.778603\n",
      "batch 250 d_loss : 0.525591\n",
      "batch 250 g1_loss : 0.423018\n",
      "batch 250 g_loss : 0.811503\n",
      "batch 251 d_loss : 0.498941\n",
      "batch 251 g1_loss : 0.429296\n",
      "batch 251 g_loss : 2.272858\n",
      "batch 252 d_loss : 0.660904\n",
      "batch 252 g1_loss : 0.405384\n",
      "batch 252 g_loss : 0.645057\n",
      "batch 253 d_loss : 0.670917\n",
      "batch 253 g1_loss : 0.415814\n",
      "batch 253 g_loss : 2.228351\n",
      "batch 254 d_loss : 0.419416\n",
      "batch 254 g1_loss : 0.401492\n",
      "batch 254 g_loss : 0.952694\n",
      "batch 255 d_loss : 0.363947\n",
      "batch 255 g1_loss : 0.357350\n",
      "batch 255 g_loss : 2.597327\n",
      "batch 256 d_loss : 0.406524\n",
      "batch 256 g1_loss : 0.403254\n",
      "batch 256 g_loss : 0.854889\n",
      "batch 257 d_loss : 0.407470\n",
      "batch 257 g1_loss : 0.397062\n",
      "batch 257 g_loss : 2.996671\n",
      "batch 258 d_loss : 0.574483\n",
      "batch 258 g1_loss : 0.364901\n",
      "batch 258 g_loss : 0.716241\n",
      "batch 259 d_loss : 0.514482\n",
      "batch 259 g1_loss : 0.394353\n",
      "batch 259 g_loss : 3.224132\n",
      "batch 260 d_loss : 0.519832\n",
      "batch 260 g1_loss : 0.385153\n",
      "batch 260 g_loss : 1.040671\n",
      "batch 261 d_loss : 0.415916\n",
      "batch 261 g1_loss : 0.391748\n",
      "batch 261 g_loss : 2.421849\n",
      "batch 262 d_loss : 0.431621\n",
      "batch 262 g1_loss : 0.394420\n",
      "batch 262 g_loss : 0.956963\n",
      "batch 263 d_loss : 0.430471\n",
      "batch 263 g1_loss : 0.401093\n",
      "batch 263 g_loss : 2.055146\n",
      "batch 264 d_loss : 0.428786\n",
      "batch 264 g1_loss : 0.414309\n",
      "batch 264 g_loss : 1.411849\n",
      "batch 265 d_loss : 0.347850\n",
      "batch 265 g1_loss : 0.420194\n",
      "batch 265 g_loss : 1.464865\n",
      "batch 266 d_loss : 0.380813\n",
      "batch 266 g1_loss : 0.443361\n",
      "batch 266 g_loss : 1.497612\n",
      "batch 267 d_loss : 0.416169\n",
      "batch 267 g1_loss : 0.429510\n",
      "batch 267 g_loss : 1.389499\n",
      "batch 268 d_loss : 0.421582\n",
      "batch 268 g1_loss : 0.416550\n",
      "batch 268 g_loss : 1.731371\n",
      "batch 269 d_loss : 0.331669\n",
      "batch 269 g1_loss : 0.458615\n",
      "batch 269 g_loss : 1.576496\n",
      "batch 270 d_loss : 0.392003\n",
      "batch 270 g1_loss : 0.454255\n",
      "batch 270 g_loss : 1.349238\n",
      "batch 271 d_loss : 0.430489\n",
      "batch 271 g1_loss : 0.469649\n",
      "batch 271 g_loss : 1.364906\n",
      "batch 272 d_loss : 0.427753\n",
      "batch 272 g1_loss : 0.482197\n",
      "batch 272 g_loss : 1.314215\n",
      "batch 273 d_loss : 0.357583\n",
      "batch 273 g1_loss : 0.483558\n",
      "batch 273 g_loss : 1.420940\n",
      "batch 274 d_loss : 0.347852\n",
      "batch 274 g1_loss : 0.480120\n",
      "batch 274 g_loss : 1.306772\n",
      "batch 275 d_loss : 0.337234\n",
      "batch 275 g1_loss : 0.491178\n",
      "batch 275 g_loss : 1.725082\n",
      "batch 276 d_loss : 0.389852\n",
      "batch 276 g1_loss : 0.485855\n",
      "batch 276 g_loss : 0.978353\n",
      "batch 277 d_loss : 0.392544\n",
      "batch 277 g1_loss : 0.477485\n",
      "batch 277 g_loss : 1.942057\n",
      "batch 278 d_loss : 0.348192\n",
      "batch 278 g1_loss : 0.504491\n",
      "batch 278 g_loss : 1.113905\n",
      "batch 279 d_loss : 0.351047\n",
      "batch 279 g1_loss : 0.487213\n",
      "batch 279 g_loss : 1.862296\n",
      "batch 280 d_loss : 0.316573\n",
      "batch 280 g1_loss : 0.494431\n",
      "batch 280 g_loss : 1.343235\n",
      "batch 281 d_loss : 0.294787\n",
      "batch 281 g1_loss : 0.485586\n",
      "batch 281 g_loss : 1.991061\n",
      "batch 282 d_loss : 0.546811\n",
      "batch 282 g1_loss : 0.489542\n",
      "batch 282 g_loss : 1.106596\n",
      "batch 283 d_loss : 0.448148\n",
      "batch 283 g1_loss : 0.490925\n",
      "batch 283 g_loss : 1.322624\n",
      "batch 284 d_loss : 0.308373\n",
      "batch 284 g1_loss : 0.479103\n",
      "batch 284 g_loss : 1.676843\n",
      "batch 285 d_loss : 0.457916\n",
      "batch 285 g1_loss : 0.460923\n",
      "batch 285 g_loss : 1.310308\n",
      "batch 286 d_loss : 0.577814\n",
      "batch 286 g1_loss : 0.488280\n",
      "batch 286 g_loss : 1.236788\n",
      "batch 287 d_loss : 0.464131\n",
      "batch 287 g1_loss : 0.480169\n",
      "batch 287 g_loss : 1.634857\n",
      "batch 288 d_loss : 0.346025\n",
      "batch 288 g1_loss : 0.457070\n",
      "batch 288 g_loss : 1.210132\n",
      "batch 289 d_loss : 0.411110\n",
      "batch 289 g1_loss : 0.454089\n",
      "batch 289 g_loss : 1.376423\n",
      "batch 290 d_loss : 0.480723\n",
      "batch 290 g1_loss : 0.484287\n",
      "batch 290 g_loss : 1.018962\n",
      "batch 291 d_loss : 0.407492\n",
      "batch 291 g1_loss : 0.456821\n",
      "batch 291 g_loss : 1.826077\n",
      "batch 292 d_loss : 0.424092\n",
      "batch 292 g1_loss : 0.476176\n",
      "batch 292 g_loss : 0.885217\n",
      "batch 293 d_loss : 0.437347\n",
      "batch 293 g1_loss : 0.462120\n",
      "batch 293 g_loss : 1.704831\n",
      "batch 294 d_loss : 0.396249\n",
      "batch 294 g1_loss : 0.456798\n",
      "batch 294 g_loss : 1.184033\n",
      "batch 295 d_loss : 0.377891\n",
      "batch 295 g1_loss : 0.471461\n",
      "batch 295 g_loss : 1.586179\n",
      "batch 296 d_loss : 0.419531\n",
      "batch 296 g1_loss : 0.471775\n",
      "batch 296 g_loss : 1.053475\n",
      "batch 297 d_loss : 0.361758\n",
      "batch 297 g1_loss : 0.456965\n",
      "batch 297 g_loss : 1.659240\n",
      "batch 298 d_loss : 0.345031\n",
      "batch 298 g1_loss : 0.476330\n",
      "batch 298 g_loss : 1.087249\n",
      "batch 299 d_loss : 0.406095\n",
      "batch 299 g1_loss : 0.485197\n",
      "batch 299 g_loss : 1.431181\n",
      "batch 300 d_loss : 0.367624\n",
      "batch 300 g1_loss : 0.477934\n",
      "batch 300 g_loss : 1.216874\n",
      "batch 301 d_loss : 0.362354\n",
      "batch 301 g1_loss : 0.465689\n",
      "batch 301 g_loss : 1.454410\n",
      "batch 302 d_loss : 0.326785\n",
      "batch 302 g1_loss : 0.479688\n",
      "batch 302 g_loss : 1.422200\n",
      "batch 303 d_loss : 0.354367\n",
      "batch 303 g1_loss : 0.463277\n",
      "batch 303 g_loss : 1.260607\n",
      "batch 304 d_loss : 0.317501\n",
      "batch 304 g1_loss : 0.482267\n",
      "batch 304 g_loss : 1.820238\n",
      "batch 305 d_loss : 0.458560\n",
      "batch 305 g1_loss : 0.456982\n",
      "batch 305 g_loss : 0.818608\n",
      "batch 306 d_loss : 0.495686\n",
      "batch 306 g1_loss : 0.468982\n",
      "batch 306 g_loss : 2.017809\n",
      "batch 307 d_loss : 0.588287\n",
      "batch 307 g1_loss : 0.467272\n",
      "batch 307 g_loss : 0.649174\n",
      "batch 308 d_loss : 0.619695\n",
      "batch 308 g1_loss : 0.445333\n",
      "batch 308 g_loss : 2.210686\n",
      "batch 309 d_loss : 0.560539\n",
      "batch 309 g1_loss : 0.453630\n",
      "batch 309 g_loss : 0.587475\n",
      "batch 310 d_loss : 0.485791\n",
      "batch 310 g1_loss : 0.438856\n",
      "batch 310 g_loss : 2.675965\n",
      "batch 311 d_loss : 0.531725\n",
      "batch 311 g1_loss : 0.439644\n",
      "batch 311 g_loss : 0.551695\n",
      "batch 312 d_loss : 0.521272\n",
      "batch 312 g1_loss : 0.444491\n",
      "batch 312 g_loss : 2.690576\n",
      "batch 313 d_loss : 0.599959\n",
      "batch 313 g1_loss : 0.442277\n",
      "batch 313 g_loss : 0.583548\n",
      "batch 314 d_loss : 0.505522\n",
      "batch 314 g1_loss : 0.447699\n",
      "batch 314 g_loss : 2.751772\n",
      "batch 315 d_loss : 0.488535\n",
      "batch 315 g1_loss : 0.467400\n",
      "batch 315 g_loss : 0.820641\n",
      "batch 316 d_loss : 0.456452\n",
      "batch 316 g1_loss : 0.442071\n",
      "batch 316 g_loss : 1.735961\n",
      "batch 317 d_loss : 0.394704\n",
      "batch 317 g1_loss : 0.436569\n",
      "batch 317 g_loss : 1.124234\n",
      "batch 318 d_loss : 0.345027\n",
      "batch 318 g1_loss : 0.432775\n",
      "batch 318 g_loss : 1.934628\n",
      "batch 319 d_loss : 0.390268\n",
      "batch 319 g1_loss : 0.457779\n",
      "batch 319 g_loss : 0.949894\n",
      "batch 320 d_loss : 0.366412\n",
      "batch 320 g1_loss : 0.456384\n",
      "batch 320 g_loss : 2.104517\n",
      "batch 321 d_loss : 0.363062\n",
      "batch 321 g1_loss : 0.460175\n",
      "batch 321 g_loss : 1.100248\n",
      "batch 322 d_loss : 0.380306\n",
      "batch 322 g1_loss : 0.457325\n",
      "batch 322 g_loss : 1.751865\n",
      "batch 323 d_loss : 0.381734\n",
      "batch 323 g1_loss : 0.425746\n",
      "batch 323 g_loss : 1.017753\n",
      "batch 324 d_loss : 0.412938\n",
      "batch 324 g1_loss : 0.459377\n",
      "batch 324 g_loss : 1.742554\n",
      "batch 325 d_loss : 0.368893\n",
      "batch 325 g1_loss : 0.456714\n",
      "batch 325 g_loss : 0.973425\n",
      "batch 326 d_loss : 0.383669\n",
      "batch 326 g1_loss : 0.471343\n",
      "batch 326 g_loss : 1.818327\n",
      "batch 327 d_loss : 0.418653\n",
      "batch 327 g1_loss : 0.459975\n",
      "batch 327 g_loss : 0.966991\n",
      "batch 328 d_loss : 0.453532\n",
      "batch 328 g1_loss : 0.451285\n",
      "batch 328 g_loss : 1.771983\n",
      "batch 329 d_loss : 0.494399\n",
      "batch 329 g1_loss : 0.464920\n",
      "batch 329 g_loss : 0.737230\n",
      "batch 330 d_loss : 0.481134\n",
      "batch 330 g1_loss : 0.440762\n",
      "batch 330 g_loss : 2.299915\n",
      "batch 331 d_loss : 0.406638\n",
      "batch 331 g1_loss : 0.456562\n",
      "batch 331 g_loss : 1.039491\n",
      "batch 332 d_loss : 0.394169\n",
      "batch 332 g1_loss : 0.446566\n",
      "batch 332 g_loss : 1.905305\n",
      "batch 333 d_loss : 0.451710\n",
      "batch 333 g1_loss : 0.440227\n",
      "batch 333 g_loss : 0.980670\n",
      "batch 334 d_loss : 0.382080\n",
      "batch 334 g1_loss : 0.452553\n",
      "batch 334 g_loss : 2.002027\n",
      "batch 335 d_loss : 0.333023\n",
      "batch 335 g1_loss : 0.441814\n",
      "batch 335 g_loss : 1.058256\n",
      "batch 336 d_loss : 0.374003\n",
      "batch 336 g1_loss : 0.430969\n",
      "batch 336 g_loss : 1.785335\n",
      "batch 337 d_loss : 0.333806\n",
      "batch 337 g1_loss : 0.453529\n",
      "batch 337 g_loss : 1.336934\n",
      "batch 338 d_loss : 0.314218\n",
      "batch 338 g1_loss : 0.442615\n",
      "batch 338 g_loss : 1.662099\n",
      "batch 339 d_loss : 0.301746\n",
      "batch 339 g1_loss : 0.429156\n",
      "batch 339 g_loss : 1.490478\n",
      "batch 340 d_loss : 0.322926\n",
      "batch 340 g1_loss : 0.442411\n",
      "batch 340 g_loss : 1.690779\n",
      "batch 341 d_loss : 0.398588\n",
      "batch 341 g1_loss : 0.452874\n",
      "batch 341 g_loss : 1.017775\n",
      "batch 342 d_loss : 0.365913\n",
      "batch 342 g1_loss : 0.443661\n",
      "batch 342 g_loss : 1.950397\n",
      "batch 343 d_loss : 0.350905\n",
      "batch 343 g1_loss : 0.451673\n",
      "batch 343 g_loss : 1.092190\n",
      "batch 344 d_loss : 0.331765\n",
      "batch 344 g1_loss : 0.436172\n",
      "batch 344 g_loss : 2.142806\n",
      "batch 345 d_loss : 0.335486\n",
      "batch 345 g1_loss : 0.437512\n",
      "batch 345 g_loss : 1.179875\n",
      "batch 346 d_loss : 0.333669\n",
      "batch 346 g1_loss : 0.443012\n",
      "batch 346 g_loss : 1.663188\n",
      "batch 347 d_loss : 0.319909\n",
      "batch 347 g1_loss : 0.447480\n",
      "batch 347 g_loss : 1.438924\n",
      "batch 348 d_loss : 0.277677\n",
      "batch 348 g1_loss : 0.436251\n",
      "batch 348 g_loss : 1.646428\n",
      "batch 349 d_loss : 0.274110\n",
      "batch 349 g1_loss : 0.457511\n",
      "batch 349 g_loss : 1.575010\n",
      "batch 350 d_loss : 0.310700\n",
      "batch 350 g1_loss : 0.464668\n",
      "batch 350 g_loss : 1.306696\n",
      "batch 351 d_loss : 0.362367\n",
      "batch 351 g1_loss : 0.457916\n",
      "batch 351 g_loss : 1.542731\n",
      "batch 352 d_loss : 0.326262\n",
      "batch 352 g1_loss : 0.459921\n",
      "batch 352 g_loss : 1.443942\n",
      "batch 353 d_loss : 0.282411\n",
      "batch 353 g1_loss : 0.443077\n",
      "batch 353 g_loss : 1.906665\n",
      "batch 354 d_loss : 0.318381\n",
      "batch 354 g1_loss : 0.432234\n",
      "batch 354 g_loss : 1.353551\n",
      "batch 355 d_loss : 0.285500\n",
      "batch 355 g1_loss : 0.440812\n",
      "batch 355 g_loss : 1.784869\n",
      "batch 356 d_loss : 0.328687\n",
      "batch 356 g1_loss : 0.440332\n",
      "batch 356 g_loss : 1.259133\n",
      "batch 357 d_loss : 0.321947\n",
      "batch 357 g1_loss : 0.443928\n",
      "batch 357 g_loss : 1.745666\n",
      "batch 358 d_loss : 0.303659\n",
      "batch 358 g1_loss : 0.446752\n",
      "batch 358 g_loss : 1.334733\n",
      "batch 359 d_loss : 0.351735\n",
      "batch 359 g1_loss : 0.452214\n",
      "batch 359 g_loss : 1.510603\n",
      "batch 360 d_loss : 0.269232\n",
      "batch 360 g1_loss : 0.439463\n",
      "batch 360 g_loss : 1.469476\n",
      "batch 361 d_loss : 0.292319\n",
      "batch 361 g1_loss : 0.448252\n",
      "batch 361 g_loss : 1.691504\n",
      "batch 362 d_loss : 0.308961\n",
      "batch 362 g1_loss : 0.461514\n",
      "batch 362 g_loss : 1.699777\n",
      "batch 363 d_loss : 0.283987\n",
      "batch 363 g1_loss : 0.438783\n",
      "batch 363 g_loss : 1.306376\n",
      "batch 364 d_loss : 0.343877\n",
      "batch 364 g1_loss : 0.443370\n",
      "batch 364 g_loss : 2.000620\n",
      "batch 365 d_loss : 0.310858\n",
      "batch 365 g1_loss : 0.443626\n",
      "batch 365 g_loss : 1.481497\n",
      "batch 366 d_loss : 0.329664\n",
      "batch 366 g1_loss : 0.450373\n",
      "batch 366 g_loss : 1.607268\n",
      "batch 367 d_loss : 0.333206\n",
      "batch 367 g1_loss : 0.479285\n",
      "batch 367 g_loss : 1.454722\n",
      "batch 368 d_loss : 0.297051\n",
      "batch 368 g1_loss : 0.421054\n",
      "batch 368 g_loss : 1.928660\n",
      "batch 369 d_loss : 0.340707\n",
      "batch 369 g1_loss : 0.429067\n",
      "batch 369 g_loss : 1.234165\n",
      "batch 370 d_loss : 0.407464\n",
      "batch 370 g1_loss : 0.425630\n",
      "batch 370 g_loss : 1.796184\n",
      "batch 371 d_loss : 0.363921\n",
      "batch 371 g1_loss : 0.444300\n",
      "batch 371 g_loss : 1.138586\n",
      "batch 372 d_loss : 0.355365\n",
      "batch 372 g1_loss : 0.439261\n",
      "batch 372 g_loss : 2.139717\n",
      "batch 373 d_loss : 0.349572\n",
      "batch 373 g1_loss : 0.433026\n",
      "batch 373 g_loss : 1.221631\n",
      "batch 374 d_loss : 0.356670\n",
      "batch 374 g1_loss : 0.462544\n",
      "batch 374 g_loss : 2.004290\n",
      "batch 375 d_loss : 0.384233\n",
      "batch 375 g1_loss : 0.438030\n",
      "batch 375 g_loss : 1.059997\n",
      "batch 376 d_loss : 0.393564\n",
      "batch 376 g1_loss : 0.441582\n",
      "batch 376 g_loss : 2.308013\n",
      "batch 377 d_loss : 0.377018\n",
      "batch 377 g1_loss : 0.453445\n",
      "batch 377 g_loss : 1.140138\n",
      "batch 378 d_loss : 0.381450\n",
      "batch 378 g1_loss : 0.462311\n",
      "batch 378 g_loss : 2.026062\n",
      "batch 379 d_loss : 0.379741\n",
      "batch 379 g1_loss : 0.452074\n",
      "batch 379 g_loss : 1.135558\n",
      "batch 380 d_loss : 0.362009\n",
      "batch 380 g1_loss : 0.493920\n",
      "batch 380 g_loss : 2.150012\n",
      "batch 381 d_loss : 0.381904\n",
      "batch 381 g1_loss : 0.473850\n",
      "batch 381 g_loss : 1.282227\n",
      "batch 382 d_loss : 0.379152\n",
      "batch 382 g1_loss : 0.496647\n",
      "batch 382 g_loss : 1.148055\n",
      "batch 383 d_loss : 0.454911\n",
      "batch 383 g1_loss : 0.511842\n",
      "batch 383 g_loss : 1.703070\n",
      "batch 384 d_loss : 0.381205\n",
      "batch 384 g1_loss : 0.483621\n",
      "batch 384 g_loss : 1.389024\n",
      "batch 385 d_loss : 0.338916\n",
      "batch 385 g1_loss : 0.516933\n",
      "batch 385 g_loss : 1.475399\n",
      "batch 386 d_loss : 0.368500\n",
      "batch 386 g1_loss : 0.505775\n",
      "batch 386 g_loss : 1.117370\n",
      "batch 387 d_loss : 0.363618\n",
      "batch 387 g1_loss : 0.530766\n",
      "batch 387 g_loss : 1.602990\n",
      "batch 388 d_loss : 0.284332\n",
      "batch 388 g1_loss : 0.513875\n",
      "batch 388 g_loss : 1.553860\n",
      "batch 389 d_loss : 0.275945\n",
      "batch 389 g1_loss : 0.556939\n",
      "batch 389 g_loss : 1.716948\n",
      "batch 390 d_loss : 0.280219\n",
      "batch 390 g1_loss : 0.516374\n",
      "batch 390 g_loss : 1.388769\n",
      "batch 391 d_loss : 0.297387\n",
      "batch 391 g1_loss : 0.527156\n",
      "batch 391 g_loss : 1.556374\n",
      "batch 392 d_loss : 0.265743\n",
      "batch 392 g1_loss : 0.512317\n",
      "batch 392 g_loss : 1.880058\n",
      "batch 393 d_loss : 0.315419\n",
      "batch 393 g1_loss : 0.513135\n",
      "batch 393 g_loss : 1.345106\n",
      "batch 394 d_loss : 0.303729\n",
      "batch 394 g1_loss : 0.526529\n",
      "batch 394 g_loss : 1.769502\n",
      "batch 395 d_loss : 0.230380\n",
      "batch 395 g1_loss : 0.512273\n",
      "batch 395 g_loss : 1.809598\n",
      "batch 396 d_loss : 0.381655\n",
      "batch 396 g1_loss : 0.505700\n",
      "batch 396 g_loss : 1.456512\n",
      "batch 397 d_loss : 0.402734\n",
      "batch 397 g1_loss : 0.539927\n",
      "batch 397 g_loss : 1.284334\n",
      "batch 398 d_loss : 0.298551\n",
      "batch 398 g1_loss : 0.494039\n",
      "batch 398 g_loss : 2.426077\n",
      "batch 399 d_loss : 0.540962\n",
      "batch 399 g1_loss : 0.507364\n",
      "batch 399 g_loss : 0.916360\n",
      "batch 400 d_loss : 0.540179\n",
      "batch 400 g1_loss : 0.512556\n",
      "batch 400 g_loss : 1.623421\n",
      "batch 401 d_loss : 0.337223\n",
      "batch 401 g1_loss : 0.487331\n",
      "batch 401 g_loss : 1.903921\n",
      "batch 402 d_loss : 0.274875\n",
      "batch 402 g1_loss : 0.485113\n",
      "batch 402 g_loss : 1.599554\n",
      "batch 403 d_loss : 0.257226\n",
      "batch 403 g1_loss : 0.481155\n",
      "batch 403 g_loss : 1.665101\n",
      "batch 404 d_loss : 0.281517\n",
      "batch 404 g1_loss : 0.492992\n",
      "batch 404 g_loss : 1.288889\n",
      "batch 405 d_loss : 0.309391\n",
      "batch 405 g1_loss : 0.462675\n",
      "batch 405 g_loss : 1.745724\n",
      "batch 406 d_loss : 0.290143\n",
      "batch 406 g1_loss : 0.475034\n",
      "batch 406 g_loss : 1.238657\n",
      "batch 407 d_loss : 0.319604\n",
      "batch 407 g1_loss : 0.441698\n",
      "batch 407 g_loss : 2.176776\n",
      "batch 408 d_loss : 0.363183\n",
      "batch 408 g1_loss : 0.448007\n",
      "batch 408 g_loss : 0.747043\n",
      "batch 409 d_loss : 0.436596\n",
      "batch 409 g1_loss : 0.457242\n",
      "batch 409 g_loss : 2.966862\n",
      "batch 410 d_loss : 0.420855\n",
      "batch 410 g1_loss : 0.450738\n",
      "batch 410 g_loss : 0.949672\n",
      "batch 411 d_loss : 0.357419\n",
      "batch 411 g1_loss : 0.443883\n",
      "batch 411 g_loss : 2.664830\n",
      "batch 412 d_loss : 0.373716\n",
      "batch 412 g1_loss : 0.439040\n",
      "batch 412 g_loss : 0.787158\n",
      "batch 413 d_loss : 0.444485\n",
      "batch 413 g1_loss : 0.440145\n",
      "batch 413 g_loss : 2.679414\n",
      "batch 414 d_loss : 0.401148\n",
      "batch 414 g1_loss : 0.461321\n",
      "batch 414 g_loss : 0.948829\n",
      "batch 415 d_loss : 0.381772\n",
      "batch 415 g1_loss : 0.461241\n",
      "batch 415 g_loss : 2.593493\n",
      "batch 416 d_loss : 0.338391\n",
      "batch 416 g1_loss : 0.456304\n",
      "batch 416 g_loss : 0.973863\n",
      "batch 417 d_loss : 0.323217\n",
      "batch 417 g1_loss : 0.443898\n",
      "batch 417 g_loss : 2.289067\n",
      "batch 418 d_loss : 0.275979\n",
      "batch 418 g1_loss : 0.419970\n",
      "batch 418 g_loss : 1.288313\n",
      "batch 419 d_loss : 0.278067\n",
      "batch 419 g1_loss : 0.421922\n",
      "batch 419 g_loss : 2.215028\n",
      "batch 420 d_loss : 0.275613\n",
      "batch 420 g1_loss : 0.455602\n",
      "batch 420 g_loss : 1.424428\n",
      "batch 421 d_loss : 0.266808\n",
      "batch 421 g1_loss : 0.444448\n",
      "batch 421 g_loss : 2.020619\n",
      "batch 422 d_loss : 0.274904\n",
      "batch 422 g1_loss : 0.446808\n",
      "batch 422 g_loss : 1.229362\n",
      "batch 423 d_loss : 0.293957\n",
      "batch 423 g1_loss : 0.453003\n",
      "batch 423 g_loss : 1.968956\n",
      "batch 424 d_loss : 0.307865\n",
      "batch 424 g1_loss : 0.427890\n",
      "batch 424 g_loss : 1.297835\n",
      "batch 425 d_loss : 0.307393\n",
      "batch 425 g1_loss : 0.458692\n",
      "batch 425 g_loss : 2.021968\n",
      "batch 426 d_loss : 0.320272\n",
      "batch 426 g1_loss : 0.436665\n",
      "batch 426 g_loss : 1.199901\n",
      "batch 427 d_loss : 0.357256\n",
      "batch 427 g1_loss : 0.453816\n",
      "batch 427 g_loss : 1.944826\n",
      "batch 428 d_loss : 0.344092\n",
      "batch 428 g1_loss : 0.426776\n",
      "batch 428 g_loss : 1.045327\n",
      "batch 429 d_loss : 0.357910\n",
      "batch 429 g1_loss : 0.451355\n",
      "batch 429 g_loss : 2.348120\n",
      "batch 430 d_loss : 0.327006\n",
      "batch 430 g1_loss : 0.434548\n",
      "batch 430 g_loss : 1.196200\n",
      "batch 431 d_loss : 0.310092\n",
      "batch 431 g1_loss : 0.447473\n",
      "batch 431 g_loss : 2.060462\n",
      "batch 432 d_loss : 0.326282\n",
      "batch 432 g1_loss : 0.459091\n",
      "batch 432 g_loss : 1.111389\n",
      "batch 433 d_loss : 0.354823\n",
      "batch 433 g1_loss : 0.450363\n",
      "batch 433 g_loss : 2.046206\n",
      "batch 434 d_loss : 0.392114\n",
      "batch 434 g1_loss : 0.456621\n",
      "batch 434 g_loss : 1.135041\n",
      "batch 435 d_loss : 0.377967\n",
      "batch 435 g1_loss : 0.451246\n",
      "batch 435 g_loss : 2.125393\n",
      "batch 436 d_loss : 0.283595\n",
      "batch 436 g1_loss : 0.458006\n",
      "batch 436 g_loss : 1.454792\n",
      "batch 437 d_loss : 0.276861\n",
      "batch 437 g1_loss : 0.462588\n",
      "batch 437 g_loss : 2.074588\n",
      "batch 438 d_loss : 0.298677\n",
      "batch 438 g1_loss : 0.458398\n",
      "batch 438 g_loss : 1.355911\n",
      "batch 439 d_loss : 0.308524\n",
      "batch 439 g1_loss : 0.454153\n",
      "batch 439 g_loss : 1.504437\n",
      "batch 440 d_loss : 0.303488\n",
      "batch 440 g1_loss : 0.470802\n",
      "batch 440 g_loss : 1.545830\n",
      "batch 441 d_loss : 0.313851\n",
      "batch 441 g1_loss : 0.457841\n",
      "batch 441 g_loss : 1.716149\n",
      "batch 442 d_loss : 0.285760\n",
      "batch 442 g1_loss : 0.466046\n",
      "batch 442 g_loss : 1.494189\n",
      "batch 443 d_loss : 0.340577\n",
      "batch 443 g1_loss : 0.462940\n",
      "batch 443 g_loss : 1.394369\n",
      "batch 444 d_loss : 0.274334\n",
      "batch 444 g1_loss : 0.474792\n",
      "batch 444 g_loss : 2.045429\n",
      "batch 445 d_loss : 0.295736\n",
      "batch 445 g1_loss : 0.497336\n",
      "batch 445 g_loss : 1.183320\n",
      "batch 446 d_loss : 0.281022\n",
      "batch 446 g1_loss : 0.460533\n",
      "batch 446 g_loss : 2.234153\n",
      "batch 447 d_loss : 0.291188\n",
      "batch 447 g1_loss : 0.475436\n",
      "batch 447 g_loss : 1.348458\n",
      "batch 448 d_loss : 0.304601\n",
      "batch 448 g1_loss : 0.446390\n",
      "batch 448 g_loss : 2.145514\n",
      "batch 449 d_loss : 0.283486\n",
      "batch 449 g1_loss : 0.483053\n",
      "batch 449 g_loss : 1.404271\n",
      "batch 450 d_loss : 0.259530\n",
      "batch 450 g1_loss : 0.478166\n",
      "batch 450 g_loss : 2.300634\n",
      "batch 451 d_loss : 0.263322\n",
      "batch 451 g1_loss : 0.460620\n",
      "batch 451 g_loss : 1.309360\n",
      "batch 452 d_loss : 0.295867\n",
      "batch 452 g1_loss : 0.457405\n",
      "batch 452 g_loss : 2.124473\n",
      "batch 453 d_loss : 0.283474\n",
      "batch 453 g1_loss : 0.465766\n",
      "batch 453 g_loss : 1.390871\n",
      "batch 454 d_loss : 0.245783\n",
      "batch 454 g1_loss : 0.444150\n",
      "batch 454 g_loss : 2.480150\n",
      "batch 455 d_loss : 0.293522\n",
      "batch 455 g1_loss : 0.465892\n",
      "batch 455 g_loss : 1.284264\n",
      "batch 456 d_loss : 0.334603\n",
      "batch 456 g1_loss : 0.454968\n",
      "batch 456 g_loss : 2.095172\n",
      "batch 457 d_loss : 0.228432\n",
      "batch 457 g1_loss : 0.432808\n",
      "batch 457 g_loss : 1.514879\n",
      "batch 458 d_loss : 0.230069\n",
      "batch 458 g1_loss : 0.440213\n",
      "batch 458 g_loss : 2.388913\n",
      "batch 459 d_loss : 0.247470\n",
      "batch 459 g1_loss : 0.444833\n",
      "batch 459 g_loss : 1.333300\n",
      "batch 460 d_loss : 0.272685\n",
      "batch 460 g1_loss : 0.436519\n",
      "batch 460 g_loss : 2.251354\n",
      "batch 461 d_loss : 0.194241\n",
      "batch 461 g1_loss : 0.438098\n",
      "batch 461 g_loss : 1.777095\n",
      "batch 462 d_loss : 0.211328\n",
      "batch 462 g1_loss : 0.432730\n",
      "batch 462 g_loss : 2.061658\n",
      "batch 463 d_loss : 0.395675\n",
      "batch 463 g1_loss : 0.404960\n",
      "batch 463 g_loss : 1.512961\n",
      "batch 464 d_loss : 0.489984\n",
      "batch 464 g1_loss : 0.442113\n",
      "batch 464 g_loss : 1.895118\n",
      "batch 465 d_loss : 0.197946\n",
      "batch 465 g1_loss : 0.415960\n",
      "batch 465 g_loss : 2.309993\n",
      "batch 466 d_loss : 0.273752\n",
      "batch 466 g1_loss : 0.418270\n",
      "batch 466 g_loss : 1.419168\n",
      "batch 467 d_loss : 0.327996\n",
      "batch 467 g1_loss : 0.412581\n",
      "batch 467 g_loss : 2.077800\n",
      "('Epoch is', 4)\n",
      "('Number of batches', 468)\n",
      "batch 0 d_loss : 0.312339\n",
      "batch 0 g1_loss : 0.424332\n",
      "batch 0 g_loss : 1.131994\n",
      "batch 1 d_loss : 0.373264\n",
      "batch 1 g1_loss : 0.415342\n",
      "batch 1 g_loss : 2.746082\n",
      "batch 2 d_loss : 0.357767\n",
      "batch 2 g1_loss : 0.431471\n",
      "batch 2 g_loss : 1.114675\n",
      "batch 3 d_loss : 0.374295\n",
      "batch 3 g1_loss : 0.458784\n",
      "batch 3 g_loss : 2.190542\n",
      "batch 4 d_loss : 0.325487\n",
      "batch 4 g1_loss : 0.451574\n",
      "batch 4 g_loss : 1.155524\n",
      "batch 5 d_loss : 0.336123\n",
      "batch 5 g1_loss : 0.435943\n",
      "batch 5 g_loss : 2.465983\n",
      "batch 6 d_loss : 0.358673\n",
      "batch 6 g1_loss : 0.450061\n",
      "batch 6 g_loss : 1.171752\n",
      "batch 7 d_loss : 0.350175\n",
      "batch 7 g1_loss : 0.462804\n",
      "batch 7 g_loss : 2.400166\n",
      "batch 8 d_loss : 0.422911\n",
      "batch 8 g1_loss : 0.451982\n",
      "batch 8 g_loss : 0.598661\n",
      "batch 9 d_loss : 0.576395\n",
      "batch 9 g1_loss : 0.493917\n",
      "batch 9 g_loss : 2.828112\n",
      "batch 10 d_loss : 0.551063\n",
      "batch 10 g1_loss : 0.472784\n",
      "batch 10 g_loss : 0.893678\n",
      "batch 11 d_loss : 0.380052\n",
      "batch 11 g1_loss : 0.475549\n",
      "batch 11 g_loss : 2.401294\n",
      "batch 12 d_loss : 0.364552\n",
      "batch 12 g1_loss : 0.488593\n",
      "batch 12 g_loss : 0.953298\n",
      "batch 13 d_loss : 0.356784\n",
      "batch 13 g1_loss : 0.483829\n",
      "batch 13 g_loss : 2.675405\n",
      "batch 14 d_loss : 0.471175\n",
      "batch 14 g1_loss : 0.506235\n",
      "batch 14 g_loss : 0.795096\n",
      "batch 15 d_loss : 0.470371\n",
      "batch 15 g1_loss : 0.527390\n",
      "batch 15 g_loss : 2.389866\n",
      "batch 16 d_loss : 0.342098\n",
      "batch 16 g1_loss : 0.520550\n",
      "batch 16 g_loss : 1.174622\n",
      "batch 17 d_loss : 0.311120\n",
      "batch 17 g1_loss : 0.515861\n",
      "batch 17 g_loss : 2.177507\n",
      "batch 18 d_loss : 0.301901\n",
      "batch 18 g1_loss : 0.510856\n",
      "batch 18 g_loss : 1.053874\n",
      "batch 19 d_loss : 0.298255\n",
      "batch 19 g1_loss : 0.495214\n",
      "batch 19 g_loss : 2.213504\n",
      "batch 20 d_loss : 0.253109\n",
      "batch 20 g1_loss : 0.516789\n",
      "batch 20 g_loss : 1.495945\n",
      "batch 21 d_loss : 0.267397\n",
      "batch 21 g1_loss : 0.498014\n",
      "batch 21 g_loss : 1.780064\n",
      "batch 22 d_loss : 0.334934\n",
      "batch 22 g1_loss : 0.514521\n",
      "batch 22 g_loss : 1.386159\n",
      "batch 23 d_loss : 0.259769\n",
      "batch 23 g1_loss : 0.490465\n",
      "batch 23 g_loss : 2.604612\n",
      "batch 24 d_loss : 0.302039\n",
      "batch 24 g1_loss : 0.519884\n",
      "batch 24 g_loss : 1.265338\n",
      "batch 25 d_loss : 0.295653\n",
      "batch 25 g1_loss : 0.503432\n",
      "batch 25 g_loss : 2.079482\n",
      "batch 26 d_loss : 0.265510\n",
      "batch 26 g1_loss : 0.506604\n",
      "batch 26 g_loss : 1.636816\n",
      "batch 27 d_loss : 0.251005\n",
      "batch 27 g1_loss : 0.514413\n",
      "batch 27 g_loss : 2.407438\n",
      "batch 28 d_loss : 0.286375\n",
      "batch 28 g1_loss : 0.492336\n",
      "batch 28 g_loss : 1.453674\n",
      "batch 29 d_loss : 0.237004\n",
      "batch 29 g1_loss : 0.496065\n",
      "batch 29 g_loss : 2.428331\n",
      "batch 30 d_loss : 0.266169\n",
      "batch 30 g1_loss : 0.491734\n",
      "batch 30 g_loss : 1.582308\n",
      "batch 31 d_loss : 0.278962\n",
      "batch 31 g1_loss : 0.456463\n",
      "batch 31 g_loss : 2.050028\n",
      "batch 32 d_loss : 0.271779\n",
      "batch 32 g1_loss : 0.493128\n",
      "batch 32 g_loss : 1.492440\n",
      "batch 33 d_loss : 0.262715\n",
      "batch 33 g1_loss : 0.461819\n",
      "batch 33 g_loss : 2.500513\n",
      "batch 34 d_loss : 0.304651\n",
      "batch 34 g1_loss : 0.483341\n",
      "batch 34 g_loss : 1.210720\n",
      "batch 35 d_loss : 0.344469\n",
      "batch 35 g1_loss : 0.445425\n",
      "batch 35 g_loss : 2.374586\n",
      "batch 36 d_loss : 0.403191\n",
      "batch 36 g1_loss : 0.466772\n",
      "batch 36 g_loss : 0.941113\n",
      "batch 37 d_loss : 0.354745\n",
      "batch 37 g1_loss : 0.463606\n",
      "batch 37 g_loss : 2.930928\n",
      "batch 38 d_loss : 0.387641\n",
      "batch 38 g1_loss : 0.459901\n",
      "batch 38 g_loss : 1.072257\n",
      "batch 39 d_loss : 0.346363\n",
      "batch 39 g1_loss : 0.464568\n",
      "batch 39 g_loss : 2.798070\n",
      "batch 40 d_loss : 0.327943\n",
      "batch 40 g1_loss : 0.440603\n",
      "batch 40 g_loss : 1.077158\n",
      "batch 41 d_loss : 0.314768\n",
      "batch 41 g1_loss : 0.451145\n",
      "batch 41 g_loss : 2.311728\n",
      "batch 42 d_loss : 0.361577\n",
      "batch 42 g1_loss : 0.469440\n",
      "batch 42 g_loss : 1.317695\n",
      "batch 43 d_loss : 0.318310\n",
      "batch 43 g1_loss : 0.478454\n",
      "batch 43 g_loss : 2.139953\n",
      "batch 44 d_loss : 0.342138\n",
      "batch 44 g1_loss : 0.451868\n",
      "batch 44 g_loss : 1.441236\n",
      "batch 45 d_loss : 0.321734\n",
      "batch 45 g1_loss : 0.470888\n",
      "batch 45 g_loss : 1.768741\n",
      "batch 46 d_loss : 0.304676\n",
      "batch 46 g1_loss : 0.464163\n",
      "batch 46 g_loss : 1.598726\n",
      "batch 47 d_loss : 0.357225\n",
      "batch 47 g1_loss : 0.467971\n",
      "batch 47 g_loss : 1.735661\n",
      "batch 48 d_loss : 0.333997\n",
      "batch 48 g1_loss : 0.457398\n",
      "batch 48 g_loss : 1.514991\n",
      "batch 49 d_loss : 0.305508\n",
      "batch 49 g1_loss : 0.452378\n",
      "batch 49 g_loss : 1.778997\n",
      "batch 50 d_loss : 0.337378\n",
      "batch 50 g1_loss : 0.478138\n",
      "batch 50 g_loss : 1.890253\n",
      "batch 51 d_loss : 0.260596\n",
      "batch 51 g1_loss : 0.488350\n",
      "batch 51 g_loss : 1.797282\n",
      "batch 52 d_loss : 0.338423\n",
      "batch 52 g1_loss : 0.472132\n",
      "batch 52 g_loss : 1.447041\n",
      "batch 53 d_loss : 0.378757\n",
      "batch 53 g1_loss : 0.503806\n",
      "batch 53 g_loss : 1.463684\n",
      "batch 54 d_loss : 0.303274\n",
      "batch 54 g1_loss : 0.453846\n",
      "batch 54 g_loss : 1.812239\n",
      "batch 55 d_loss : 0.252158\n",
      "batch 55 g1_loss : 0.501380\n",
      "batch 55 g_loss : 1.853109\n",
      "batch 56 d_loss : 0.323278\n",
      "batch 56 g1_loss : 0.510740\n",
      "batch 56 g_loss : 0.895344\n",
      "batch 57 d_loss : 0.367661\n",
      "batch 57 g1_loss : 0.503861\n",
      "batch 57 g_loss : 2.438809\n",
      "batch 58 d_loss : 0.321681\n",
      "batch 58 g1_loss : 0.485057\n",
      "batch 58 g_loss : 1.092257\n",
      "batch 59 d_loss : 0.317799\n",
      "batch 59 g1_loss : 0.470407\n",
      "batch 59 g_loss : 2.560167\n",
      "batch 60 d_loss : 0.348977\n",
      "batch 60 g1_loss : 0.499827\n",
      "batch 60 g_loss : 0.929094\n",
      "batch 61 d_loss : 0.443246\n",
      "batch 61 g1_loss : 0.530267\n",
      "batch 61 g_loss : 2.625263\n",
      "batch 62 d_loss : 0.496748\n",
      "batch 62 g1_loss : 0.527282\n",
      "batch 62 g_loss : 0.667984\n",
      "batch 63 d_loss : 0.479598\n",
      "batch 63 g1_loss : 0.510597\n",
      "batch 63 g_loss : 3.397905\n",
      "batch 64 d_loss : 0.492784\n",
      "batch 64 g1_loss : 0.508229\n",
      "batch 64 g_loss : 0.800093\n",
      "batch 65 d_loss : 0.410167\n",
      "batch 65 g1_loss : 0.522077\n",
      "batch 65 g_loss : 2.806272\n",
      "batch 66 d_loss : 0.643933\n",
      "batch 66 g1_loss : 0.497804\n",
      "batch 66 g_loss : 0.647313\n",
      "batch 67 d_loss : 0.473179\n",
      "batch 67 g1_loss : 0.516909\n",
      "batch 67 g_loss : 2.523876\n",
      "batch 68 d_loss : 0.388365\n",
      "batch 68 g1_loss : 0.501785\n",
      "batch 68 g_loss : 0.880056\n",
      "batch 69 d_loss : 0.368467\n",
      "batch 69 g1_loss : 0.498096\n",
      "batch 69 g_loss : 2.666474\n",
      "batch 70 d_loss : 0.368324\n",
      "batch 70 g1_loss : 0.512042\n",
      "batch 70 g_loss : 1.094439\n",
      "batch 71 d_loss : 0.322420\n",
      "batch 71 g1_loss : 0.531053\n",
      "batch 71 g_loss : 1.794230\n",
      "batch 72 d_loss : 0.388148\n",
      "batch 72 g1_loss : 0.543867\n",
      "batch 72 g_loss : 0.960654\n",
      "batch 73 d_loss : 0.355575\n",
      "batch 73 g1_loss : 0.531833\n",
      "batch 73 g_loss : 2.533485\n",
      "batch 74 d_loss : 0.472610\n",
      "batch 74 g1_loss : 0.521276\n",
      "batch 74 g_loss : 0.736596\n",
      "batch 75 d_loss : 0.460668\n",
      "batch 75 g1_loss : 0.545854\n",
      "batch 75 g_loss : 2.996231\n",
      "batch 76 d_loss : 0.394496\n",
      "batch 76 g1_loss : 0.570792\n",
      "batch 76 g_loss : 1.359324\n",
      "batch 77 d_loss : 0.268205\n",
      "batch 77 g1_loss : 0.526335\n",
      "batch 77 g_loss : 1.960312\n",
      "batch 78 d_loss : 0.262743\n",
      "batch 78 g1_loss : 0.554502\n",
      "batch 78 g_loss : 1.542093\n",
      "batch 79 d_loss : 0.343660\n",
      "batch 79 g1_loss : 0.546796\n",
      "batch 79 g_loss : 1.776936\n",
      "batch 80 d_loss : 0.449635\n",
      "batch 80 g1_loss : 0.540169\n",
      "batch 80 g_loss : 1.665456\n",
      "batch 81 d_loss : 0.275161\n",
      "batch 81 g1_loss : 0.544821\n",
      "batch 81 g_loss : 1.748654\n",
      "batch 82 d_loss : 0.259502\n",
      "batch 82 g1_loss : 0.545421\n",
      "batch 82 g_loss : 2.005763\n",
      "batch 83 d_loss : 0.248066\n",
      "batch 83 g1_loss : 0.509339\n",
      "batch 83 g_loss : 1.569836\n",
      "batch 84 d_loss : 0.303356\n",
      "batch 84 g1_loss : 0.560618\n",
      "batch 84 g_loss : 1.532726\n",
      "batch 85 d_loss : 0.333719\n",
      "batch 85 g1_loss : 0.539757\n",
      "batch 85 g_loss : 1.623756\n",
      "batch 86 d_loss : 0.296181\n",
      "batch 86 g1_loss : 0.563398\n",
      "batch 86 g_loss : 1.648355\n",
      "batch 87 d_loss : 0.263734\n",
      "batch 87 g1_loss : 0.529666\n",
      "batch 87 g_loss : 1.780467\n",
      "batch 88 d_loss : 0.292846\n",
      "batch 88 g1_loss : 0.520772\n",
      "batch 88 g_loss : 1.402212\n",
      "batch 89 d_loss : 0.286792\n",
      "batch 89 g1_loss : 0.538301\n",
      "batch 89 g_loss : 1.857946\n",
      "batch 90 d_loss : 0.328954\n",
      "batch 90 g1_loss : 0.565182\n",
      "batch 90 g_loss : 1.253379\n",
      "batch 91 d_loss : 0.345827\n",
      "batch 91 g1_loss : 0.535919\n",
      "batch 91 g_loss : 1.969262\n",
      "batch 92 d_loss : 0.297072\n",
      "batch 92 g1_loss : 0.543424\n",
      "batch 92 g_loss : 1.411881\n",
      "batch 93 d_loss : 0.333214\n",
      "batch 93 g1_loss : 0.546442\n",
      "batch 93 g_loss : 1.611080\n",
      "batch 94 d_loss : 0.349503\n",
      "batch 94 g1_loss : 0.531735\n",
      "batch 94 g_loss : 1.149715\n",
      "batch 95 d_loss : 0.334714\n",
      "batch 95 g1_loss : 0.517761\n",
      "batch 95 g_loss : 2.369887\n",
      "batch 96 d_loss : 0.346990\n",
      "batch 96 g1_loss : 0.528669\n",
      "batch 96 g_loss : 1.062490\n",
      "batch 97 d_loss : 0.327700\n",
      "batch 97 g1_loss : 0.516964\n",
      "batch 97 g_loss : 2.628900\n",
      "batch 98 d_loss : 0.255848\n",
      "batch 98 g1_loss : 0.516625\n",
      "batch 98 g_loss : 1.471305\n",
      "batch 99 d_loss : 0.259601\n",
      "batch 99 g1_loss : 0.515889\n",
      "batch 99 g_loss : 1.877650\n",
      "batch 100 d_loss : 0.267179\n",
      "batch 100 g1_loss : 0.531078\n",
      "batch 100 g_loss : 1.354856\n",
      "batch 101 d_loss : 0.428891\n",
      "batch 101 g1_loss : 0.529542\n",
      "batch 101 g_loss : 1.326947\n",
      "batch 102 d_loss : 0.402249\n",
      "batch 102 g1_loss : 0.511136\n",
      "batch 102 g_loss : 1.577007\n",
      "batch 103 d_loss : 0.255046\n",
      "batch 103 g1_loss : 0.512903\n",
      "batch 103 g_loss : 2.117698\n",
      "batch 104 d_loss : 0.266014\n",
      "batch 104 g1_loss : 0.511059\n",
      "batch 104 g_loss : 1.672608\n",
      "batch 105 d_loss : 0.296184\n",
      "batch 105 g1_loss : 0.536949\n",
      "batch 105 g_loss : 1.811528\n",
      "batch 106 d_loss : 0.295721\n",
      "batch 106 g1_loss : 0.524741\n",
      "batch 106 g_loss : 1.223395\n",
      "batch 107 d_loss : 0.285948\n",
      "batch 107 g1_loss : 0.523806\n",
      "batch 107 g_loss : 2.397942\n",
      "batch 108 d_loss : 0.239987\n",
      "batch 108 g1_loss : 0.506765\n",
      "batch 108 g_loss : 1.760890\n",
      "batch 109 d_loss : 0.322321\n",
      "batch 109 g1_loss : 0.509324\n",
      "batch 109 g_loss : 1.285734\n",
      "batch 110 d_loss : 0.354994\n",
      "batch 110 g1_loss : 0.491125\n",
      "batch 110 g_loss : 1.934760\n",
      "batch 111 d_loss : 0.358210\n",
      "batch 111 g1_loss : 0.493712\n",
      "batch 111 g_loss : 1.402576\n",
      "batch 112 d_loss : 0.315391\n",
      "batch 112 g1_loss : 0.494457\n",
      "batch 112 g_loss : 2.286015\n",
      "batch 113 d_loss : 0.290569\n",
      "batch 113 g1_loss : 0.520389\n",
      "batch 113 g_loss : 1.434410\n",
      "batch 114 d_loss : 0.293968\n",
      "batch 114 g1_loss : 0.528992\n",
      "batch 114 g_loss : 2.011524\n",
      "batch 115 d_loss : 0.319492\n",
      "batch 115 g1_loss : 0.514627\n",
      "batch 115 g_loss : 1.311027\n",
      "batch 116 d_loss : 0.307235\n",
      "batch 116 g1_loss : 0.519758\n",
      "batch 116 g_loss : 2.210783\n",
      "batch 117 d_loss : 0.277455\n",
      "batch 117 g1_loss : 0.502046\n",
      "batch 117 g_loss : 1.623751\n",
      "batch 118 d_loss : 0.250845\n",
      "batch 118 g1_loss : 0.508333\n",
      "batch 118 g_loss : 2.231967\n",
      "batch 119 d_loss : 0.231785\n",
      "batch 119 g1_loss : 0.493238\n",
      "batch 119 g_loss : 1.698821\n",
      "batch 120 d_loss : 0.207095\n",
      "batch 120 g1_loss : 0.482936\n",
      "batch 120 g_loss : 2.232148\n",
      "batch 121 d_loss : 0.230803\n",
      "batch 121 g1_loss : 0.490731\n",
      "batch 121 g_loss : 1.586007\n",
      "batch 122 d_loss : 0.232844\n",
      "batch 122 g1_loss : 0.484778\n",
      "batch 122 g_loss : 2.405392\n",
      "batch 123 d_loss : 0.236163\n",
      "batch 123 g1_loss : 0.507012\n",
      "batch 123 g_loss : 1.538449\n",
      "batch 124 d_loss : 0.356202\n",
      "batch 124 g1_loss : 0.514264\n",
      "batch 124 g_loss : 1.491804\n",
      "batch 125 d_loss : 0.403797\n",
      "batch 125 g1_loss : 0.474058\n",
      "batch 125 g_loss : 1.802040\n",
      "batch 126 d_loss : 0.309094\n",
      "batch 126 g1_loss : 0.482413\n",
      "batch 126 g_loss : 1.755846\n",
      "batch 127 d_loss : 0.266673\n",
      "batch 127 g1_loss : 0.491800\n",
      "batch 127 g_loss : 1.868398\n",
      "batch 128 d_loss : 0.216222\n",
      "batch 128 g1_loss : 0.472098\n",
      "batch 128 g_loss : 2.156956\n",
      "batch 129 d_loss : 0.219621\n",
      "batch 129 g1_loss : 0.497590\n",
      "batch 129 g_loss : 1.830528\n",
      "batch 130 d_loss : 0.278278\n",
      "batch 130 g1_loss : 0.474382\n",
      "batch 130 g_loss : 1.527032\n",
      "batch 131 d_loss : 0.209812\n",
      "batch 131 g1_loss : 0.468142\n",
      "batch 131 g_loss : 2.588457\n",
      "batch 132 d_loss : 0.384483\n",
      "batch 132 g1_loss : 0.489973\n",
      "batch 132 g_loss : 0.607841\n",
      "batch 133 d_loss : 0.512373\n",
      "batch 133 g1_loss : 0.459989\n",
      "batch 133 g_loss : 4.192894\n",
      "batch 134 d_loss : 0.560494\n",
      "batch 134 g1_loss : 0.479118\n",
      "batch 134 g_loss : 0.934789\n",
      "batch 135 d_loss : 0.351937\n",
      "batch 135 g1_loss : 0.462236\n",
      "batch 135 g_loss : 3.401155\n",
      "batch 136 d_loss : 0.435113\n",
      "batch 136 g1_loss : 0.464248\n",
      "batch 136 g_loss : 0.591714\n",
      "batch 137 d_loss : 0.505328\n",
      "batch 137 g1_loss : 0.468854\n",
      "batch 137 g_loss : 3.667181\n",
      "batch 138 d_loss : 0.635251\n",
      "batch 138 g1_loss : 0.474814\n",
      "batch 138 g_loss : 0.334628\n",
      "batch 139 d_loss : 0.755497\n",
      "batch 139 g1_loss : 0.473775\n",
      "batch 139 g_loss : 4.606196\n",
      "batch 140 d_loss : 0.748231\n",
      "batch 140 g1_loss : 0.460631\n",
      "batch 140 g_loss : 0.584846\n",
      "batch 141 d_loss : 0.484003\n",
      "batch 141 g1_loss : 0.485083\n",
      "batch 141 g_loss : 3.742260\n",
      "batch 142 d_loss : 0.679214\n",
      "batch 142 g1_loss : 0.486331\n",
      "batch 142 g_loss : 0.439588\n",
      "batch 143 d_loss : 0.678653\n",
      "batch 143 g1_loss : 0.505263\n",
      "batch 143 g_loss : 4.227907\n",
      "batch 144 d_loss : 0.769067\n",
      "batch 144 g1_loss : 0.490782\n",
      "batch 144 g_loss : 0.625734\n",
      "batch 145 d_loss : 0.548106\n",
      "batch 145 g1_loss : 0.493290\n",
      "batch 145 g_loss : 3.718332\n",
      "batch 146 d_loss : 0.562946\n",
      "batch 146 g1_loss : 0.496932\n",
      "batch 146 g_loss : 0.851665\n",
      "batch 147 d_loss : 0.419791\n",
      "batch 147 g1_loss : 0.498151\n",
      "batch 147 g_loss : 2.953878\n",
      "batch 148 d_loss : 0.351897\n",
      "batch 148 g1_loss : 0.516525\n",
      "batch 148 g_loss : 1.065007\n",
      "batch 149 d_loss : 0.345994\n",
      "batch 149 g1_loss : 0.514678\n",
      "batch 149 g_loss : 2.516754\n",
      "batch 150 d_loss : 0.375762\n",
      "batch 150 g1_loss : 0.515136\n",
      "batch 150 g_loss : 1.270913\n",
      "batch 151 d_loss : 0.350991\n",
      "batch 151 g1_loss : 0.519188\n",
      "batch 151 g_loss : 2.108161\n",
      "batch 152 d_loss : 0.416131\n",
      "batch 152 g1_loss : 0.517218\n",
      "batch 152 g_loss : 1.120773\n",
      "batch 153 d_loss : 0.376685\n",
      "batch 153 g1_loss : 0.516415\n",
      "batch 153 g_loss : 2.287113\n",
      "batch 154 d_loss : 0.303933\n",
      "batch 154 g1_loss : 0.506854\n",
      "batch 154 g_loss : 1.704446\n",
      "batch 155 d_loss : 0.247376\n",
      "batch 155 g1_loss : 0.544325\n",
      "batch 155 g_loss : 2.181671\n",
      "batch 156 d_loss : 0.228291\n",
      "batch 156 g1_loss : 0.549386\n",
      "batch 156 g_loss : 1.640530\n",
      "batch 157 d_loss : 0.258046\n",
      "batch 157 g1_loss : 0.508907\n",
      "batch 157 g_loss : 2.069960\n",
      "batch 158 d_loss : 0.282930\n",
      "batch 158 g1_loss : 0.518102\n",
      "batch 158 g_loss : 1.598302\n",
      "batch 159 d_loss : 0.230147\n",
      "batch 159 g1_loss : 0.548648\n",
      "batch 159 g_loss : 1.955392\n",
      "batch 160 d_loss : 0.273405\n",
      "batch 160 g1_loss : 0.539282\n",
      "batch 160 g_loss : 1.762486\n",
      "batch 161 d_loss : 0.293614\n",
      "batch 161 g1_loss : 0.542484\n",
      "batch 161 g_loss : 1.503444\n",
      "batch 162 d_loss : 0.305107\n",
      "batch 162 g1_loss : 0.517711\n",
      "batch 162 g_loss : 1.970053\n",
      "batch 163 d_loss : 0.335036\n",
      "batch 163 g1_loss : 0.552949\n",
      "batch 163 g_loss : 1.285871\n",
      "batch 164 d_loss : 0.256817\n",
      "batch 164 g1_loss : 0.523995\n",
      "batch 164 g_loss : 2.141550\n",
      "batch 165 d_loss : 0.236383\n",
      "batch 165 g1_loss : 0.534467\n",
      "batch 165 g_loss : 1.806131\n",
      "batch 166 d_loss : 0.265104\n",
      "batch 166 g1_loss : 0.519245\n",
      "batch 166 g_loss : 1.691896\n",
      "batch 167 d_loss : 0.265405\n",
      "batch 167 g1_loss : 0.497920\n",
      "batch 167 g_loss : 2.200617\n",
      "batch 168 d_loss : 0.252946\n",
      "batch 168 g1_loss : 0.499411\n",
      "batch 168 g_loss : 1.529496\n",
      "batch 169 d_loss : 0.198198\n",
      "batch 169 g1_loss : 0.501425\n",
      "batch 169 g_loss : 2.174784\n",
      "batch 170 d_loss : 0.421055\n",
      "batch 170 g1_loss : 0.500463\n",
      "batch 170 g_loss : 1.349892\n",
      "batch 171 d_loss : 0.389418\n",
      "batch 171 g1_loss : 0.471998\n",
      "batch 171 g_loss : 2.153398\n",
      "batch 172 d_loss : 0.224547\n",
      "batch 172 g1_loss : 0.497965\n",
      "batch 172 g_loss : 2.020226\n",
      "batch 173 d_loss : 0.250670\n",
      "batch 173 g1_loss : 0.504739\n",
      "batch 173 g_loss : 1.736566\n",
      "batch 174 d_loss : 0.263115\n",
      "batch 174 g1_loss : 0.481753\n",
      "batch 174 g_loss : 2.016492\n",
      "batch 175 d_loss : 0.343923\n",
      "batch 175 g1_loss : 0.483464\n",
      "batch 175 g_loss : 1.179912\n",
      "batch 176 d_loss : 0.431003\n",
      "batch 176 g1_loss : 0.474895\n",
      "batch 176 g_loss : 1.986370\n",
      "batch 177 d_loss : 0.370394\n",
      "batch 177 g1_loss : 0.480367\n",
      "batch 177 g_loss : 1.373228\n",
      "batch 178 d_loss : 0.368741\n",
      "batch 178 g1_loss : 0.464622\n",
      "batch 178 g_loss : 2.064137\n",
      "batch 179 d_loss : 0.307669\n",
      "batch 179 g1_loss : 0.466030\n",
      "batch 179 g_loss : 1.587275\n",
      "batch 180 d_loss : 0.320361\n",
      "batch 180 g1_loss : 0.473084\n",
      "batch 180 g_loss : 1.875005\n",
      "batch 181 d_loss : 0.285908\n",
      "batch 181 g1_loss : 0.488127\n",
      "batch 181 g_loss : 1.594873\n",
      "batch 182 d_loss : 0.291754\n",
      "batch 182 g1_loss : 0.461858\n",
      "batch 182 g_loss : 1.825570\n",
      "batch 183 d_loss : 0.266214\n",
      "batch 183 g1_loss : 0.469611\n",
      "batch 183 g_loss : 2.089539\n",
      "batch 184 d_loss : 0.257164\n",
      "batch 184 g1_loss : 0.455819\n",
      "batch 184 g_loss : 1.466550\n",
      "batch 185 d_loss : 0.268079\n",
      "batch 185 g1_loss : 0.483430\n",
      "batch 185 g_loss : 2.232087\n",
      "batch 186 d_loss : 0.253758\n",
      "batch 186 g1_loss : 0.493705\n",
      "batch 186 g_loss : 1.406692\n",
      "batch 187 d_loss : 0.288247\n",
      "batch 187 g1_loss : 0.484499\n",
      "batch 187 g_loss : 1.677599\n",
      "batch 188 d_loss : 0.319536\n",
      "batch 188 g1_loss : 0.493277\n",
      "batch 188 g_loss : 1.300697\n",
      "batch 189 d_loss : 0.279845\n",
      "batch 189 g1_loss : 0.475458\n",
      "batch 189 g_loss : 2.122175\n",
      "batch 190 d_loss : 0.262826\n",
      "batch 190 g1_loss : 0.486275\n",
      "batch 190 g_loss : 1.754417\n",
      "batch 191 d_loss : 0.261289\n",
      "batch 191 g1_loss : 0.484706\n",
      "batch 191 g_loss : 1.743376\n",
      "batch 192 d_loss : 0.296756\n",
      "batch 192 g1_loss : 0.488721\n",
      "batch 192 g_loss : 1.709486\n",
      "batch 193 d_loss : 0.320124\n",
      "batch 193 g1_loss : 0.490471\n",
      "batch 193 g_loss : 1.609158\n",
      "batch 194 d_loss : 0.282007\n",
      "batch 194 g1_loss : 0.500715\n",
      "batch 194 g_loss : 1.986138\n",
      "batch 195 d_loss : 0.258900\n",
      "batch 195 g1_loss : 0.484398\n",
      "batch 195 g_loss : 1.667012\n",
      "batch 196 d_loss : 0.229464\n",
      "batch 196 g1_loss : 0.504880\n",
      "batch 196 g_loss : 2.042679\n",
      "batch 197 d_loss : 0.322948\n",
      "batch 197 g1_loss : 0.493505\n",
      "batch 197 g_loss : 1.463948\n",
      "batch 198 d_loss : 0.326025\n",
      "batch 198 g1_loss : 0.496292\n",
      "batch 198 g_loss : 1.785450\n",
      "batch 199 d_loss : 0.309439\n",
      "batch 199 g1_loss : 0.505674\n",
      "batch 199 g_loss : 1.391263\n",
      "batch 200 d_loss : 0.267711\n",
      "batch 200 g1_loss : 0.490029\n",
      "batch 200 g_loss : 2.470603\n",
      "batch 201 d_loss : 0.297127\n",
      "batch 201 g1_loss : 0.491487\n",
      "batch 201 g_loss : 1.100176\n",
      "batch 202 d_loss : 0.291000\n",
      "batch 202 g1_loss : 0.515470\n",
      "batch 202 g_loss : 2.633047\n",
      "batch 203 d_loss : 0.394939\n",
      "batch 203 g1_loss : 0.493948\n",
      "batch 203 g_loss : 0.928860\n",
      "batch 204 d_loss : 0.352772\n",
      "batch 204 g1_loss : 0.490779\n",
      "batch 204 g_loss : 2.425418\n",
      "batch 205 d_loss : 0.278146\n",
      "batch 205 g1_loss : 0.501265\n",
      "batch 205 g_loss : 1.439475\n",
      "batch 206 d_loss : 0.273474\n",
      "batch 206 g1_loss : 0.499936\n",
      "batch 206 g_loss : 2.140916\n",
      "batch 207 d_loss : 0.268195\n",
      "batch 207 g1_loss : 0.489308\n",
      "batch 207 g_loss : 1.445135\n",
      "batch 208 d_loss : 0.323539\n",
      "batch 208 g1_loss : 0.471143\n",
      "batch 208 g_loss : 2.146138\n",
      "batch 209 d_loss : 0.367721\n",
      "batch 209 g1_loss : 0.500805\n",
      "batch 209 g_loss : 1.108398\n",
      "batch 210 d_loss : 0.309559\n",
      "batch 210 g1_loss : 0.497655\n",
      "batch 210 g_loss : 2.719602\n",
      "batch 211 d_loss : 0.295706\n",
      "batch 211 g1_loss : 0.488779\n",
      "batch 211 g_loss : 1.508318\n",
      "batch 212 d_loss : 0.316984\n",
      "batch 212 g1_loss : 0.494557\n",
      "batch 212 g_loss : 2.441305\n",
      "batch 213 d_loss : 0.295333\n",
      "batch 213 g1_loss : 0.470521\n",
      "batch 213 g_loss : 1.290871\n",
      "batch 214 d_loss : 0.265475\n",
      "batch 214 g1_loss : 0.469592\n",
      "batch 214 g_loss : 2.367046\n",
      "batch 215 d_loss : 0.232032\n",
      "batch 215 g1_loss : 0.465340\n",
      "batch 215 g_loss : 1.733334\n",
      "batch 216 d_loss : 0.226283\n",
      "batch 216 g1_loss : 0.487570\n",
      "batch 216 g_loss : 2.074496\n",
      "batch 217 d_loss : 0.230863\n",
      "batch 217 g1_loss : 0.490017\n",
      "batch 217 g_loss : 1.661968\n",
      "batch 218 d_loss : 0.372402\n",
      "batch 218 g1_loss : 0.483194\n",
      "batch 218 g_loss : 1.371106\n",
      "batch 219 d_loss : 0.351478\n",
      "batch 219 g1_loss : 0.483420\n",
      "batch 219 g_loss : 1.795743\n",
      "batch 220 d_loss : 0.335817\n",
      "batch 220 g1_loss : 0.456582\n",
      "batch 220 g_loss : 1.322740\n",
      "batch 221 d_loss : 0.355516\n",
      "batch 221 g1_loss : 0.491204\n",
      "batch 221 g_loss : 2.319113\n",
      "batch 222 d_loss : 0.324500\n",
      "batch 222 g1_loss : 0.470721\n",
      "batch 222 g_loss : 1.371845\n",
      "batch 223 d_loss : 0.293042\n",
      "batch 223 g1_loss : 0.465161\n",
      "batch 223 g_loss : 1.859742\n",
      "batch 224 d_loss : 0.276888\n",
      "batch 224 g1_loss : 0.476609\n",
      "batch 224 g_loss : 1.625504\n",
      "batch 225 d_loss : 0.264788\n",
      "batch 225 g1_loss : 0.488092\n",
      "batch 225 g_loss : 2.018403\n",
      "batch 226 d_loss : 0.266238\n",
      "batch 226 g1_loss : 0.491289\n",
      "batch 226 g_loss : 1.705281\n",
      "batch 227 d_loss : 0.278526\n",
      "batch 227 g1_loss : 0.463616\n",
      "batch 227 g_loss : 1.426220\n",
      "batch 228 d_loss : 0.319236\n",
      "batch 228 g1_loss : 0.463351\n",
      "batch 228 g_loss : 1.840966\n",
      "batch 229 d_loss : 0.332069\n",
      "batch 229 g1_loss : 0.469995\n",
      "batch 229 g_loss : 1.540781\n",
      "batch 230 d_loss : 0.270023\n",
      "batch 230 g1_loss : 0.470641\n",
      "batch 230 g_loss : 1.996550\n",
      "batch 231 d_loss : 0.238531\n",
      "batch 231 g1_loss : 0.474207\n",
      "batch 231 g_loss : 1.746863\n",
      "batch 232 d_loss : 0.266131\n",
      "batch 232 g1_loss : 0.461523\n",
      "batch 232 g_loss : 1.456697\n",
      "batch 233 d_loss : 0.273252\n",
      "batch 233 g1_loss : 0.489480\n",
      "batch 233 g_loss : 2.507132\n",
      "batch 234 d_loss : 0.278395\n",
      "batch 234 g1_loss : 0.485186\n",
      "batch 234 g_loss : 1.099488\n",
      "batch 235 d_loss : 0.332641\n",
      "batch 235 g1_loss : 0.495914\n",
      "batch 235 g_loss : 3.067863\n",
      "batch 236 d_loss : 0.348590\n",
      "batch 236 g1_loss : 0.494878\n",
      "batch 236 g_loss : 1.198097\n",
      "batch 237 d_loss : 0.322308\n",
      "batch 237 g1_loss : 0.492499\n",
      "batch 237 g_loss : 2.777612\n",
      "batch 238 d_loss : 0.357565\n",
      "batch 238 g1_loss : 0.483056\n",
      "batch 238 g_loss : 0.956436\n",
      "batch 239 d_loss : 0.372588\n",
      "batch 239 g1_loss : 0.494455\n",
      "batch 239 g_loss : 3.571702\n",
      "batch 240 d_loss : 0.552696\n",
      "batch 240 g1_loss : 0.483722\n",
      "batch 240 g_loss : 0.518621\n",
      "batch 241 d_loss : 0.730862\n",
      "batch 241 g1_loss : 0.471529\n",
      "batch 241 g_loss : 5.136185\n",
      "batch 242 d_loss : 0.913186\n",
      "batch 242 g1_loss : 0.477635\n",
      "batch 242 g_loss : 0.643471\n",
      "batch 243 d_loss : 0.531867\n",
      "batch 243 g1_loss : 0.467789\n",
      "batch 243 g_loss : 4.117252\n",
      "batch 244 d_loss : 0.586907\n",
      "batch 244 g1_loss : 0.482178\n",
      "batch 244 g_loss : 0.655087\n",
      "batch 245 d_loss : 0.525179\n",
      "batch 245 g1_loss : 0.486390\n",
      "batch 245 g_loss : 3.800616\n",
      "batch 246 d_loss : 0.445602\n",
      "batch 246 g1_loss : 0.496146\n",
      "batch 246 g_loss : 0.942647\n",
      "batch 247 d_loss : 0.350933\n",
      "batch 247 g1_loss : 0.471051\n",
      "batch 247 g_loss : 3.165952\n",
      "batch 248 d_loss : 0.368109\n",
      "batch 248 g1_loss : 0.476444\n",
      "batch 248 g_loss : 1.017201\n",
      "batch 249 d_loss : 0.368366\n",
      "batch 249 g1_loss : 0.485183\n",
      "batch 249 g_loss : 2.537400\n",
      "batch 250 d_loss : 0.374495\n",
      "batch 250 g1_loss : 0.462655\n",
      "batch 250 g_loss : 1.191007\n",
      "batch 251 d_loss : 0.306863\n",
      "batch 251 g1_loss : 0.472665\n",
      "batch 251 g_loss : 2.935097\n",
      "batch 252 d_loss : 0.487331\n",
      "batch 252 g1_loss : 0.483773\n",
      "batch 252 g_loss : 0.972162\n",
      "batch 253 d_loss : 0.395089\n",
      "batch 253 g1_loss : 0.498075\n",
      "batch 253 g_loss : 2.515096\n",
      "batch 254 d_loss : 0.296773\n",
      "batch 254 g1_loss : 0.482365\n",
      "batch 254 g_loss : 1.587661\n",
      "batch 255 d_loss : 0.257769\n",
      "batch 255 g1_loss : 0.505999\n",
      "batch 255 g_loss : 2.023342\n",
      "batch 256 d_loss : 0.241883\n",
      "batch 256 g1_loss : 0.471713\n",
      "batch 256 g_loss : 1.786105\n",
      "batch 257 d_loss : 0.217180\n",
      "batch 257 g1_loss : 0.502393\n",
      "batch 257 g_loss : 2.300016\n",
      "batch 258 d_loss : 0.262778\n",
      "batch 258 g1_loss : 0.478179\n",
      "batch 258 g_loss : 1.449151\n",
      "batch 259 d_loss : 0.265502\n",
      "batch 259 g1_loss : 0.483386\n",
      "batch 259 g_loss : 2.504481\n",
      "batch 260 d_loss : 0.226015\n",
      "batch 260 g1_loss : 0.505845\n",
      "batch 260 g_loss : 1.749766\n",
      "batch 261 d_loss : 0.213308\n",
      "batch 261 g1_loss : 0.488961\n",
      "batch 261 g_loss : 2.036470\n",
      "batch 262 d_loss : 0.218103\n",
      "batch 262 g1_loss : 0.497359\n",
      "batch 262 g_loss : 1.762261\n",
      "batch 263 d_loss : 0.313447\n",
      "batch 263 g1_loss : 0.496640\n",
      "batch 263 g_loss : 1.808261\n",
      "batch 264 d_loss : 0.401742\n",
      "batch 264 g1_loss : 0.514282\n",
      "batch 264 g_loss : 1.119281\n",
      "batch 265 d_loss : 0.315480\n",
      "batch 265 g1_loss : 0.502424\n",
      "batch 265 g_loss : 3.027093\n",
      "batch 266 d_loss : 0.327979\n",
      "batch 266 g1_loss : 0.504109\n",
      "batch 266 g_loss : 1.411001\n",
      "batch 267 d_loss : 0.232984\n",
      "batch 267 g1_loss : 0.465319\n",
      "batch 267 g_loss : 2.533232\n",
      "batch 268 d_loss : 0.326376\n",
      "batch 268 g1_loss : 0.474801\n",
      "batch 268 g_loss : 1.200433\n",
      "batch 269 d_loss : 0.281350\n",
      "batch 269 g1_loss : 0.497995\n",
      "batch 269 g_loss : 3.153441\n",
      "batch 270 d_loss : 0.367008\n",
      "batch 270 g1_loss : 0.500429\n",
      "batch 270 g_loss : 1.160905\n",
      "batch 271 d_loss : 0.319599\n",
      "batch 271 g1_loss : 0.487843\n",
      "batch 271 g_loss : 2.654574\n",
      "batch 272 d_loss : 0.331430\n",
      "batch 272 g1_loss : 0.502042\n",
      "batch 272 g_loss : 1.205383\n",
      "batch 273 d_loss : 0.295386\n",
      "batch 273 g1_loss : 0.487346\n",
      "batch 273 g_loss : 2.620677\n",
      "batch 274 d_loss : 0.216297\n",
      "batch 274 g1_loss : 0.503780\n",
      "batch 274 g_loss : 1.755102\n",
      "batch 275 d_loss : 0.205675\n",
      "batch 275 g1_loss : 0.502633\n",
      "batch 275 g_loss : 2.307982\n",
      "batch 276 d_loss : 0.272739\n",
      "batch 276 g1_loss : 0.481138\n",
      "batch 276 g_loss : 1.629771\n",
      "batch 277 d_loss : 0.234378\n",
      "batch 277 g1_loss : 0.478258\n",
      "batch 277 g_loss : 2.164835\n",
      "batch 278 d_loss : 0.212896\n",
      "batch 278 g1_loss : 0.498117\n",
      "batch 278 g_loss : 1.888622\n",
      "batch 279 d_loss : 0.238377\n",
      "batch 279 g1_loss : 0.521761\n",
      "batch 279 g_loss : 1.958843\n",
      "batch 280 d_loss : 0.210082\n",
      "batch 280 g1_loss : 0.514800\n",
      "batch 280 g_loss : 1.849614\n",
      "batch 281 d_loss : 0.209898\n",
      "batch 281 g1_loss : 0.494316\n",
      "batch 281 g_loss : 2.120517\n",
      "batch 282 d_loss : 0.367771\n",
      "batch 282 g1_loss : 0.503311\n",
      "batch 282 g_loss : 1.507150\n",
      "batch 283 d_loss : 0.339436\n",
      "batch 283 g1_loss : 0.471839\n",
      "batch 283 g_loss : 2.156662\n",
      "batch 284 d_loss : 0.227636\n",
      "batch 284 g1_loss : 0.472869\n",
      "batch 284 g_loss : 2.001421\n",
      "batch 285 d_loss : 0.299021\n",
      "batch 285 g1_loss : 0.469259\n",
      "batch 285 g_loss : 1.715206\n",
      "batch 286 d_loss : 0.386942\n",
      "batch 286 g1_loss : 0.473734\n",
      "batch 286 g_loss : 1.909149\n",
      "batch 287 d_loss : 0.295216\n",
      "batch 287 g1_loss : 0.492550\n",
      "batch 287 g_loss : 2.062375\n",
      "batch 288 d_loss : 0.231684\n",
      "batch 288 g1_loss : 0.470538\n",
      "batch 288 g_loss : 1.812195\n",
      "batch 289 d_loss : 0.284810\n",
      "batch 289 g1_loss : 0.504408\n",
      "batch 289 g_loss : 1.488918\n",
      "batch 290 d_loss : 0.308709\n",
      "batch 290 g1_loss : 0.479823\n",
      "batch 290 g_loss : 1.707006\n",
      "batch 291 d_loss : 0.263437\n",
      "batch 291 g1_loss : 0.491698\n",
      "batch 291 g_loss : 2.144966\n",
      "batch 292 d_loss : 0.257636\n",
      "batch 292 g1_loss : 0.456753\n",
      "batch 292 g_loss : 1.877746\n",
      "batch 293 d_loss : 0.273738\n",
      "batch 293 g1_loss : 0.524338\n",
      "batch 293 g_loss : 1.450716\n",
      "batch 294 d_loss : 0.289207\n",
      "batch 294 g1_loss : 0.503705\n",
      "batch 294 g_loss : 2.457857\n",
      "batch 295 d_loss : 0.289459\n",
      "batch 295 g1_loss : 0.521089\n",
      "batch 295 g_loss : 1.731537\n",
      "batch 296 d_loss : 0.271567\n",
      "batch 296 g1_loss : 0.524154\n",
      "batch 296 g_loss : 1.863404\n",
      "batch 297 d_loss : 0.245975\n",
      "batch 297 g1_loss : 0.527148\n",
      "batch 297 g_loss : 1.938129\n",
      "batch 298 d_loss : 0.221416\n",
      "batch 298 g1_loss : 0.481494\n",
      "batch 298 g_loss : 2.174983\n",
      "batch 299 d_loss : 0.259015\n",
      "batch 299 g1_loss : 0.527338\n",
      "batch 299 g_loss : 1.670197\n",
      "batch 300 d_loss : 0.219182\n",
      "batch 300 g1_loss : 0.494286\n",
      "batch 300 g_loss : 1.973779\n",
      "batch 301 d_loss : 0.232159\n",
      "batch 301 g1_loss : 0.507267\n",
      "batch 301 g_loss : 2.092478\n",
      "batch 302 d_loss : 0.204941\n",
      "batch 302 g1_loss : 0.524719\n",
      "batch 302 g_loss : 2.167403\n",
      "batch 303 d_loss : 0.250522\n",
      "batch 303 g1_loss : 0.525593\n",
      "batch 303 g_loss : 1.833323\n",
      "batch 304 d_loss : 0.233679\n",
      "batch 304 g1_loss : 0.500499\n",
      "batch 304 g_loss : 2.569159\n",
      "batch 305 d_loss : 0.337654\n",
      "batch 305 g1_loss : 0.509069\n",
      "batch 305 g_loss : 1.338241\n",
      "batch 306 d_loss : 0.336656\n",
      "batch 306 g1_loss : 0.496135\n",
      "batch 306 g_loss : 2.482577\n",
      "batch 307 d_loss : 0.415780\n",
      "batch 307 g1_loss : 0.513758\n",
      "batch 307 g_loss : 1.040647\n",
      "batch 308 d_loss : 0.416104\n",
      "batch 308 g1_loss : 0.506121\n",
      "batch 308 g_loss : 2.406933\n",
      "batch 309 d_loss : 0.349260\n",
      "batch 309 g1_loss : 0.516658\n",
      "batch 309 g_loss : 1.112202\n",
      "batch 310 d_loss : 0.316093\n",
      "batch 310 g1_loss : 0.497069\n",
      "batch 310 g_loss : 2.405061\n",
      "batch 311 d_loss : 0.318804\n",
      "batch 311 g1_loss : 0.518103\n",
      "batch 311 g_loss : 1.111032\n",
      "batch 312 d_loss : 0.330423\n",
      "batch 312 g1_loss : 0.521827\n",
      "batch 312 g_loss : 2.466269\n",
      "batch 313 d_loss : 0.327483\n",
      "batch 313 g1_loss : 0.517238\n",
      "batch 313 g_loss : 1.173463\n",
      "batch 314 d_loss : 0.279298\n",
      "batch 314 g1_loss : 0.510472\n",
      "batch 314 g_loss : 2.457158\n",
      "batch 315 d_loss : 0.261381\n",
      "batch 315 g1_loss : 0.521385\n",
      "batch 315 g_loss : 1.878124\n",
      "batch 316 d_loss : 0.306006\n",
      "batch 316 g1_loss : 0.494593\n",
      "batch 316 g_loss : 1.558450\n",
      "batch 317 d_loss : 0.252774\n",
      "batch 317 g1_loss : 0.473839\n",
      "batch 317 g_loss : 2.243030\n",
      "batch 318 d_loss : 0.208144\n",
      "batch 318 g1_loss : 0.526741\n",
      "batch 318 g_loss : 1.773482\n",
      "batch 319 d_loss : 0.246513\n",
      "batch 319 g1_loss : 0.504958\n",
      "batch 319 g_loss : 2.111072\n",
      "batch 320 d_loss : 0.210388\n",
      "batch 320 g1_loss : 0.519165\n",
      "batch 320 g_loss : 2.174229\n",
      "batch 321 d_loss : 0.207916\n",
      "batch 321 g1_loss : 0.495031\n",
      "batch 321 g_loss : 2.136521\n",
      "batch 322 d_loss : 0.215856\n",
      "batch 322 g1_loss : 0.511551\n",
      "batch 322 g_loss : 1.970328\n",
      "batch 323 d_loss : 0.237900\n",
      "batch 323 g1_loss : 0.499133\n",
      "batch 323 g_loss : 1.930970\n",
      "batch 324 d_loss : 0.252714\n",
      "batch 324 g1_loss : 0.500774\n",
      "batch 324 g_loss : 2.037570\n",
      "batch 325 d_loss : 0.219292\n",
      "batch 325 g1_loss : 0.509350\n",
      "batch 325 g_loss : 1.950995\n",
      "batch 326 d_loss : 0.257534\n",
      "batch 326 g1_loss : 0.489113\n",
      "batch 326 g_loss : 1.916226\n",
      "batch 327 d_loss : 0.278190\n",
      "batch 327 g1_loss : 0.482901\n",
      "batch 327 g_loss : 2.089272\n",
      "batch 328 d_loss : 0.304088\n",
      "batch 328 g1_loss : 0.458008\n",
      "batch 328 g_loss : 1.560117\n",
      "batch 329 d_loss : 0.362855\n",
      "batch 329 g1_loss : 0.478395\n",
      "batch 329 g_loss : 1.459845\n",
      "batch 330 d_loss : 0.308063\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-b12e920899c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-79-b8003345f442>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(BATCH_SIZE)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_on_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mg1_loss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#for mG(z)-m(Y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch %d g1_loss : %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg1_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shubham/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m    931\u001b[0m         return self.model.train_on_batch(x, y,\n\u001b[1;32m    932\u001b[0m                                          \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                                          class_weight=class_weight)\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     def test_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/shubham/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1618\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shubham/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shubham/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shubham/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shubham/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/shubham/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shubham/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "kdf=np.arange(0,12)\n",
    "print(kdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0]\n",
      " [ 1]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]\n",
      " [11]]\n"
     ]
    }
   ],
   "source": [
    "kdf.resize(12,1)\n",
    "print(kdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "cvb=np.zeros(10,)\n",
    "print(cvb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "y1=X_train[0]\n",
    "print(y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " ..., \n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "cv2=np.zeros((10,) + X_train.shape[1:3], dtype=np.float32)\n",
    "print(cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(cv2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(BATCH_SIZE, nice=False):\n",
    "    g = generator_model()\n",
    "    g.compile(loss='hinge_loss', optimizer=\"adam\")\n",
    "    g.load_weights('generator')\n",
    "    if nice:\n",
    "        d = discriminator_model()\n",
    "        d.compile(loss='binary_crossentropy', optimizer=\"adam\")\n",
    "        d.load_weights('discriminator')\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE*20, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        d_pret = d.predict(generated_images, verbose=1)\n",
    "        index = np.arange(0, BATCH_SIZE*20)\n",
    "        index.resize((BATCH_SIZE*20, 1))\n",
    "        pre_with_index = list(np.append(d_pret, index, axis=1))\n",
    "        pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
    "        nice_images = np.zeros((BATCH_SIZE,) + generated_images.shape[1:3], dtype=np.float32)\n",
    "        nice_images = nice_images[:, :, :, None]\n",
    "        for i in range(BATCH_SIZE):\n",
    "            idx = int(pre_with_index[i][1])\n",
    "            nice_images[i, :, :, 0] = generated_images[idx, :, :, 0]\n",
    "        image = combine_images(nice_images)\n",
    "    else:\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        image = combine_images(generated_images)\n",
    "    image = image*127.5+127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(\n",
    "        \"generated_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "generate(128,nice=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(BATCH_SIZE, nice=False):\n",
    "    g = generator_model()\n",
    "    g.compile(loss='hinge_loss', optimizer=\"adam\")\n",
    "    g.load_weights('generator')\n",
    "    if nice:\n",
    "        d = discriminator_model()\n",
    "        d.compile(loss='binary_crossentropy', optimizer=\"adam\")\n",
    "        d.load_weights('discriminator')\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE*20, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        d_pret = d.predict(generated_images, verbose=1)\n",
    "        index = np.arange(0, BATCH_SIZE*20)\n",
    "        index.resize((BATCH_SIZE*20, 1))\n",
    "        pre_with_index = list(np.append(d_pret, index, axis=1))\n",
    "        pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
    "        nice_images = np.zeros((BATCH_SIZE,) + generated_images.shape[1:3], dtype=np.float32)\n",
    "        nice_images = nice_images[:, :, :, None]\n",
    "        for i in range(BATCH_SIZE):\n",
    "            idx = int(pre_with_index[i][1])\n",
    "            nice_images[i, :, :, 0] = generated_images[idx, :, :, 0]\n",
    "        image = combine_images(nice_images)\n",
    "    else:\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        image = combine_images(generated_images)\n",
    "    image = image*127.5+127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(\n",
    "        \"nice_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560/2560 [==============================] - 19s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "2560/2560 [==============================] - 6s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "generate(128,nice=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "#masking and completion portion starts \n",
    "exmpl=X_train[0,:,:,0]\n",
    "print(exmpl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa977ebb4d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADn9JREFUeJzt3X9sXfV5x/HPU8dxlhDauCmeSzMSIC3QsIbtKoCIgImR\npQgpoKqhUVWljDVdC3RsmQTLpjWb2JRNLVXKGJJZsyQVv0oLIn+wVmBV0GrgYbIQfpVfwV0TjE1w\nIYHSxLGf/eGTygXf73XuPfeeaz/vl2T53vOcc8+jk3x87r3fe8/X3F0A4vlA0Q0AKAbhB4Ii/EBQ\nhB8IivADQRF+ICjCDwRF+IGgCD8Q1IxG7mymtfkszWnkLoFQfq13dNgP2WTWrSn8ZrZS0mZJLZL+\nw903pdafpTk62y6qZZcAEnq8e9LrVv2038xaJN0i6dOSzpC0xszOqPbxADRWLa/5l0l6yd33uPth\nSXdJWpVPWwDqrZbwnyjpF+Pu782W/RYzW2dmvWbWO6xDNewOQJ7q/m6/u3e5e8ndS61qq/fuAExS\nLeHfJ2nBuPsfy5YBmAJqCf/jkhab2SIzmynpc5J25NMWgHqreqjP3Y+Y2TWSfqSxob4t7v5Mbp0B\nqKuaxvnd/QFJD+TUC4AG4uO9QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ER\nfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANB\nEX4gKMIPBFXTLL1m1ifpoKQRSUfcvZRHU8iPzUj/E7d8ZH5d9//8Xy8sWxuZPZrc9qRTBpP12V+1\nZP21m2aWre0s3Z3cdv/IO8n62fesT9ZP/avHkvVmUFP4M3/k7vtzeBwADcTTfiCoWsPvkh4ysyfM\nbF0eDQFojFqf9i93931mdoKkB83sZ+7+yPgVsj8K6yRplmbXuDsAeanpzO/u+7Lfg5Luk7RsgnW6\n3L3k7qVWtdWyOwA5qjr8ZjbHzOYevS1phaSn82oMQH3V8rS/Q9J9Znb0ce5w9x/m0hWAuqs6/O6+\nR9Kncuxl2mo5fXGy7m2tyfqrF3woWX/3nPJj0u0fTI9X/+RT6fHuIv3Xr+Ym6//ybyuT9Z4z7yhb\ne2X43eS2mwYuTtY/+hNP1qcChvqAoAg/EBThB4Ii/EBQhB8IivADQeXxrb7wRi78g2T9pq23JOsf\nby3/1dPpbNhHkvW/v/mLyfqMd9LDbefec03Z2tx9R5Lbtu1PDwXO7u1J1qcCzvxAUIQfCIrwA0ER\nfiAowg8ERfiBoAg/EBTj/Dloe/7VZP2JXy9I1j/eOpBnO7la339Osr7n7fSlv7ee8v2ytbdG0+P0\nHd/+72S9nqb+F3Yr48wPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0GZe+NGNI+3dj/bLmrY/prF0JXn\nJusHVqYvr92y+7hk/cmv3nzMPR114/7fT9YfvyA9jj/y5lvJup9b/urufV9LbqpFa55Mr4D36fFu\nHfCh9NzlGc78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUxXF+M9si6VJJg+6+JFvWLuluSQsl9Ula\n7e6/rLSzqOP8lbTM/3CyPvLGULL+yh3lx+qfOX9Lcttl/3xtsn7CLcV9px7HLu9x/q2S3jsR+g2S\nut19saTu7D6AKaRi+N39EUnvPfWskrQtu71N0mU59wWgzqp9zd/h7v3Z7dckdeTUD4AGqfkNPx97\n06DsGwdmts7Mes2sd1iHat0dgJxUG/4BM+uUpOz3YLkV3b3L3UvuXmpVW5W7A5C3asO/Q9La7PZa\nSffn0w6ARqkYfjO7U9Kjkj5hZnvN7CpJmyRdbGYvSvrj7D6AKaTidfvdfU2ZEgP2ORnZ/0ZN2w8f\nmFn1tp/8/LPJ+uu3tqQfYHSk6n2jWHzCDwiK8ANBEX4gKMIPBEX4gaAIPxAUU3RPA6df/0LZ2pVn\npkdk//Ok7mT9gs9enazPvfuxZB3NizM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFOP80kJom+42v\nnJ7c9v92vJus33Dj9mT9b1Zfnqz7/36wbG3BPz2a3FYNnD4+Is78QFCEHwiK8ANBEX4gKMIPBEX4\ngaAIPxBUxSm688QU3c1n6E/PTdZv//o3kvVFM2ZVve9Pbr8mWV98W3+yfmRPX9X7nq7ynqIbwDRE\n+IGgCD8QFOEHgiL8QFCEHwiK8ANBVRznN7Mtki6VNOjuS7JlGyV9SdLr2Wob3P2BSjtjnH/q8fOW\nJuvHb9qbrN958o+q3vdpP/6zZP0T/1D+OgaSNPLinqr3PVXlPc6/VdLKCZZ/y92XZj8Vgw+guVQM\nv7s/ImmoAb0AaKBaXvNfa2a7zWyLmc3LrSMADVFt+G+VdLKkpZL6JX2z3Ipmts7Mes2sd1iHqtwd\ngLxVFX53H3D3EXcflXSbpGWJdbvcveTupVa1VdsngJxVFX4z6xx393JJT+fTDoBGqXjpbjO7U9KF\nkuab2V5JX5d0oZktleSS+iR9uY49AqgDvs+PmrR0nJCsv3rFqWVrPddvTm77gQpPTD//yopk/a3l\nbyTr0xHf5wdQEeEHgiL8QFCEHwiK8ANBEX4gKIb6UJjv7U1P0T3bZibrv/LDyfql115X/rHv60lu\nO1Ux1AegIsIPBEX4gaAIPxAU4QeCIvxAUIQfCKri9/kR2+jy9KW7X/5seoruJUv7ytYqjeNXcvPQ\nWcn67Pt7a3r86Y4zPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTj/NGelJcn6C19Lj7Xfdt62ZP38\nWenv1NfikA8n648NLUo/wGh/jt1MP5z5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoiuP8ZrZA0nZJ\nHZJcUpe7bzazdkl3S1ooqU/Sanf/Zf1ajWvGopOS9Zev/GjZ2sYr7kpu+5nj9lfVUx42DJSS9Yc3\nn5Osz9uWvu4/0iZz5j8iab27nyHpHElXm9kZkm6Q1O3uiyV1Z/cBTBEVw+/u/e6+M7t9UNJzkk6U\ntErS0Y9/bZN0Wb2aBJC/Y3rNb2YLJZ0lqUdSh7sf/fzkaxp7WQBgiph0+M3sOEk/kHSdux8YX/Ox\nCf8mnPTPzNaZWa+Z9Q7rUE3NAsjPpMJvZq0aC/7t7n5vtnjAzDqzeqekwYm2dfcudy+5e6lVbXn0\nDCAHFcNvZibpO5Kec/ebxpV2SFqb3V4r6f782wNQL5P5Su95kr4g6Skz25Ut2yBpk6TvmdlVkn4u\naXV9Wpz6Ziz8vWT9rT/sTNav+McfJut//qF7k/V6Wt+fHo579N/LD+e1b/2f5LbzRhnKq6eK4Xf3\nn0oqN9/3Rfm2A6BR+IQfEBThB4Ii/EBQhB8IivADQRF+ICgu3T1JMzp/t2xtaMuc5LZfWfRwsr5m\n7kBVPeXhmn3Lk/Wdt6an6J7//aeT9faDjNU3K878QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUmHH+\nw3+Svkz04b8cStY3nPpA2dqK33mnqp7yMjDybtna+TvWJ7c97e9+lqy3v5kepx9NVtHMOPMDQRF+\nICjCDwRF+IGgCD8QFOEHgiL8QFBhxvn7Lkv/nXvhzHvqtu9b3jwlWd/88Ipk3UbKXTl9zGk3vlK2\ntnigJ7ntSLKK6YwzPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EZe6eXsFsgaTtkjokuaQud99sZhsl\nfUnS69mqG9y9/JfeJR1v7X62Mas3UC893q0DPpT+YEhmMh/yOSJpvbvvNLO5kp4wswez2rfc/RvV\nNgqgOBXD7+79kvqz2wfN7DlJJ9a7MQD1dUyv+c1soaSzJB39zOi1ZrbbzLaY2bwy26wzs14z6x3W\noZqaBZCfSYffzI6T9ANJ17n7AUm3SjpZ0lKNPTP45kTbuXuXu5fcvdSqthxaBpCHSYXfzFo1Fvzb\n3f1eSXL3AXcfcfdRSbdJWla/NgHkrWL4zcwkfUfSc+5+07jlneNWu1xSerpWAE1lMu/2nyfpC5Ke\nMrNd2bINktaY2VKNDf/1SfpyXToEUBeTebf/p5ImGjdMjukDaG58wg8IivADQRF+ICjCDwRF+IGg\nCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUxUt357ozs9cl/XzcovmS9jesgWPTrL01\na18SvVUrz95OcvePTGbFhob/fTs363X3UmENJDRrb83al0Rv1SqqN572A0ERfiCoosPfVfD+U5q1\nt2btS6K3ahXSW6Gv+QEUp+gzP4CCFBJ+M1tpZs+b2UtmdkMRPZRjZn1m9pSZ7TKz3oJ72WJmg2b2\n9Lhl7Wb2oJm9mP2ecJq0gnrbaGb7smO3y8wuKai3BWb2YzN71syeMbO/yJYXeuwSfRVy3Br+tN/M\nWiS9IOliSXslPS5pjbs/29BGyjCzPkkldy98TNjMzpf0tqTt7r4kW/avkobcfVP2h3Oeu1/fJL1t\nlPR20TM3ZxPKdI6fWVrSZZK+qAKPXaKv1SrguBVx5l8m6SV33+PuhyXdJWlVAX00PXd/RNLQexav\nkrQtu71NY/95Gq5Mb03B3fvdfWd2+6CkozNLF3rsEn0VoojwnyjpF+Pu71VzTfntkh4ysyfMbF3R\nzUygI5s2XZJek9RRZDMTqDhzcyO9Z2bppjl21cx4nTfe8Hu/5e6+VNKnJV2dPb1tSj72mq2Zhmsm\nNXNzo0wws/RvFHnsqp3xOm9FhH+fpAXj7n8sW9YU3H1f9ntQ0n1qvtmHB45Okpr9Hiy4n99oppmb\nJ5pZWk1w7Jppxusiwv+4pMVmtsjMZkr6nKQdBfTxPmY2J3sjRmY2R9IKNd/swzskrc1ur5V0f4G9\n/JZmmbm53MzSKvjYNd2M1+7e8B9Jl2jsHf+XJf1tET2U6etkSU9mP88U3ZukOzX2NHBYY++NXCXp\nw5K6Jb0o6SFJ7U3U23clPSVpt8aC1llQb8s19pR+t6Rd2c8lRR+7RF+FHDc+4QcExRt+QFCEHwiK\n8ANBEX4gKMIPBEX4gaAIPxAU4QeC+n8DZI6NXofNrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa97811f650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(exmpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa97861c610>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8ANBEX4gKMIPBEX4gaAIPxAU4QeC+n8DZI6NXofNrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa977e275d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exmpl=(exmpl*127.5)+127.5\n",
    "plt.imshow(exmpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "exmpl2=X_train[0,:,:,0]\n",
    "mask=np.ones((28,28))\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 12]\n",
      " [21 32]]\n"
     ]
    }
   ],
   "source": [
    "a=np.array([[1,2],[3,4]])\n",
    "b=np.array([[5,6],[7,8]])\n",
    "print(np.multiply(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "mask[10:17,10:17]=0.0\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa978431950>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADepJREFUeJzt3X+MHHUZx/HPY3u92lK1Z/U8sdICFSRVi25KCQ1ikFoJ\nSSFGpDFaCFp/oYI1kVSj1RhTjWIqIskBTYtRQBRCY1ADjQGNUDmaUkB+lzO2HnfUE1oQ2uvd4x83\nNSfcfne7O7uzd8/7lVxud56ZnSfTfm5257u7X3N3AYjnNUU3AKAYhB8IivADQRF+ICjCDwRF+IGg\nCD8QFOEHgiL8QFBTm7mzadbu0zWzmbsEQnlZL+qgH7Bq1q0r/Ga2XNIGSVMkXevu61PrT9dMnWJn\n1rNLAAnbfGvV69b8tN/Mpki6StKHJZ0kaaWZnVTr4wFornpe8y+W9KS773L3g5JulLQin7YANFo9\n4T9a0j/G3N+dLfs/ZrbazHrMrGdIB+rYHYA8Nfxqv7t3u3vJ3Uttam/07gBUqZ7w75E0d8z9t2XL\nAEwA9YT/PkkLzGy+mU2TdIGkLfm0BaDRah7qc/dDZnaJpD9odKhvo7s/nFtnABqqrnF+d79d0u05\n9QKgiXh7LxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjC\nDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0HVNUuv\nmfVK2i9pWNIhdy/l0RTyY1PT/8RT3jSnoft/7KvzytaGZ4wktz3muIFkfcbnLVl/5oppZWvbSzcl\nt907/GKyfsrNa5L1479yb7LeCuoKf+YD7r43h8cB0EQ87QeCqjf8LulOM7vfzFbn0RCA5qj3af9S\nd99jZm+WdIeZPerud49dIfujsFqSpmtGnbsDkJe6zvzuvif7PSDpVkmLx1mn291L7l5qU3s9uwOQ\no5rDb2YzzWzW4duSlkl6KK/GADRWPU/7OyXdamaHH+eX7v77XLoC0HA1h9/dd0l6T469TFpT3rkg\nWff2tmT9n+9/Q7L+0pLyY9Idr0+PV//pPenx7iL97j+zkvXv/3R5sr7tXb8sW3t66KXktuv7z0rW\n3/onT9YnAob6gKAIPxAU4QeCIvxAUIQfCIrwA0Hl8am+8IbPeG+yfsWmq5L1d7SV/+jpZDbkw8n6\nN6+8MFmf+mJ6uO3Umy8pW5u151By2/a96aHAGT3bkvWJgDM/EBThB4Ii/EBQhB8IivADQRF+ICjC\nDwTFOH8O2h/7Z7J+/8tzk/V3tPXn2U6u1vQtSdZ3vZD+6u9Nx/26bO35kfQ4fedP/pKsN9LE/8Bu\nZZz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAoc2/eiObrrMNPsTObtr9WMXjRqcn6vuXpr9eesvOo\nZP2Bz195xD0d9t29707W73t/ehx/+Lnnk3U/tfy3u/d+Kbmp5q98IL0CXmWbb9U+H0zPXZ7hzA8E\nRfiBoAg/EBThB4Ii/EBQhB8IivADQVUc5zezjZLOkTTg7guzZR2SbpI0T1KvpPPd/d+VdhZ1nL+S\nKXPemKw/9vX0FN8T1fGX3Vt0C5NO3uP8myS9ciL0yyVtdfcFkrZm9wFMIBXD7+53Sxp8xeIVkjZn\ntzdLOjfnvgA0WK2v+TvdvS+7/Yykzpz6AdAkdV/w89GLBmUvHJjZajPrMbOeIR2od3cAclJr+PvN\nrEuSst8D5VZ09253L7l7qU3tNe4OQN5qDf8WSauy26sk3ZZPOwCapWL4zewGSfdIOsHMdpvZxZLW\nSzrLzJ6Q9MHsPoAJpOL39rv7yjIlBuxzMrz3XxXWmJzj/CgW7/ADgiL8QFCEHwiK8ANBEX4gKMIP\nBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EVfEjvUDDWIVvmG7i9PERceYHgiL8QFCEHwiK\n8ANBEX4gKMIPBEX4gaAY50dhnv7ekmR9wTV9yfqhXb05dhMPZ34gKMIPBEX4gaAIPxAU4QeCIvxA\nUIQfCKriOL+ZbZR0jqQBd1+YLVsn6dOSns1WW+vutzeqSUxOD3/yp8n6iXM/layf8O30uWv4iV1H\n3FMk1Zz5N0laPs7yH7v7ouyH4AMTTMXwu/vdkgab0AuAJqrnNf8XzWynmW00s9m5dQSgKWoN/9WS\njpW0SFKfpB+VW9HMVptZj5n1DOlAjbsDkLeawu/u/e4+7O4jkq6RtDixbre7l9y91Kb2WvsEkLOa\nwm9mXWPunifpoXzaAdAs1Qz13SDpDElzzGy3pG9JOsPMFklySb2SPtPAHgE0QMXwu/vKcRZf14Be\nEMyIRpL1Rz9wbbL+8XnLkvXnlx5xS6HwDj8gKMIPBEX4gaAIPxAU4QeCIvxAUHx19wRw/GX3Ft1C\nQ7z80UPJ+gyblqxfM++3yfo5511a/rFv3ZbcNgLO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOP8\nSBpZuihZf+qj05P1hYt6y9YqjeNXcuXgycn6jNt66nr8yY4zPxAU4QeCIvxAUIQfCIrwA0ERfiAo\nwg8ExTj/JGelhcn641+q8Jn50zYn66dPP3jEPVXrgA8l6/cOzk8/wEhfjt1MPpz5gaAIPxAU4QeC\nIvxAUIQfCIrwA0ERfiCoiuP8ZjZX0vWSOiW5pG5332BmHZJukjRPUq+k8939341rNa6p849J1p+6\n6K1la+s+dmNy248ctbemnvKwtr+UrN+1YUmyPnvzPXm2E041Z/5Dkta4+0mSlkj6gpmdJOlySVvd\nfYGkrdl9ABNExfC7e5+7b89u75f0iKSjJa2QdPjtX5slnduoJgHk74he85vZPEknS9omqdPdD79/\n8hmNviwAMEFUHX4zO0rSbyRd6u77xtbc3TV6PWC87VabWY+Z9QzpQF3NAshPVeE3szaNBv8X7n5L\ntrjfzLqyepekgfG2dfdudy+5e6lN7Xn0DCAHFcNvZibpOkmPuPsVY0pbJK3Kbq+SdFv+7QFolGo+\n0nuapE9IetDMdmTL1kpaL+lXZnaxpL9LOr8xLU58U+e9PVl//n1dyfrHvvP7ZP2zb7glWW+kNX3p\n4bh7flZ+OK9j01+T284eYSivkSqG393/LMnKlM/Mtx0AzcI7/ICgCD8QFOEHgiL8QFCEHwiK8ANB\n8dXdVZra9ZaytcGNM5Pbfm7+Xcn6yln9NfWUh0v2LE3Wt1+dnqJ7zq8fStY79jNW36o48wNBEX4g\nKMIPBEX4gaAIPxAU4QeCIvxAUGHG+Q9+KP010QcvG0zW1x5/e9naste+WFNPeekffqls7fQta5Lb\nnviNR5P1jufS4/QjySpaGWd+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwgqzDh/77npv3OPv+vmhu37\nqueOS9Y33LUsWbfhct+cPurE7z5dtragf1ty2+FkFZMZZ34gKMIPBEX4gaAIPxAU4QeCIvxAUIQf\nCMrcPb2C2VxJ10vqlOSSut19g5mtk/RpSc9mq6519/Ifepf0OuvwU4xZvYFG2eZbtc8H028MyVTz\nJp9Dkta4+3YzmyXpfjO7I6v92N1/WGujAIpTMfzu3iepL7u938wekXR0oxsD0FhH9JrfzOZJOlnS\n4feMftHMdprZRjObXWab1WbWY2Y9QzpQV7MA8lN1+M3sKEm/kXSpu++TdLWkYyUt0ugzgx+Nt527\nd7t7yd1LbWrPoWUAeagq/GbWptHg/8Ldb5Ekd+9392F3H5F0jaTFjWsTQN4qht/MTNJ1kh5x9yvG\nLO8as9p5ktLTtQJoKdVc7T9N0ickPWhmO7JlayWtNLNFGh3+65X0mYZ0CKAhqrna/2dJ440bJsf0\nAbQ23uEHBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IquJX\nd+e6M7NnJf19zKI5kvY2rYEj06q9tWpfEr3VKs/ejnH3N1WzYlPD/6qdm/W4e6mwBhJatbdW7Uui\nt1oV1RtP+4GgCD8QVNHh7y54/ymt2lur9iXRW60K6a3Q1/wAilP0mR9AQQoJv5ktN7PHzOxJM7u8\niB7KMbNeM3vQzHaYWU/BvWw0swEze2jMsg4zu8PMnsh+jztNWkG9rTOzPdmx22FmZxfU21wz+6OZ\n/c3MHjazL2fLCz12ib4KOW5Nf9pvZlMkPS7pLEm7Jd0naaW7/62pjZRhZr2SSu5e+JiwmZ0u6QVJ\n17v7wmzZDyQNuvv67A/nbHf/Wov0tk7SC0XP3JxNKNM1dmZpSedKulAFHrtEX+ergONWxJl/saQn\n3X2Xux+UdKOkFQX00fLc/W5Jg69YvELS5uz2Zo3+52m6Mr21BHfvc/ft2e39kg7PLF3osUv0VYgi\nwn+0pH+Mub9brTXlt0u608zuN7PVRTczjs5s2nRJekZSZ5HNjKPizM3N9IqZpVvm2NUy43XeuOD3\nakvdfZGkD0v6Qvb0tiX56Gu2VhquqWrm5mYZZ2bp/yny2NU643Xeigj/Hklzx9x/W7asJbj7nuz3\ngKRb1XqzD/cfniQ1+z1QcD//00ozN483s7Ra4Ni10ozXRYT/PkkLzGy+mU2TdIGkLQX08SpmNjO7\nECMzmylpmVpv9uEtklZlt1dJuq3AXv5Pq8zcXG5maRV87Fpuxmt3b/qPpLM1esX/KUlfL6KHMn0d\nK+mB7OfhonuTdINGnwYOafTayMWS3ihpq6QnJN0pqaOFevu5pAcl7dRo0LoK6m2pRp/S75S0I/s5\nu+hjl+irkOPGO/yAoLjgBwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqP8CZHtB4fn9sHgAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa978604310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampl3=X_train[0,:,:,0]\n",
    "plt.imshow(np.multiply(mask,sampl3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "g1 = generator_model()\n",
    "g1.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "g1.load_weights('generator')\n",
    "noise1 = np.random.uniform(-1, 1, (1, 100))\n",
    "gen_image = g1.predict(noise1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "mask2=np.zeros((64,64))\n",
    "print(mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "mask2[24:40,24:40]=1.0\n",
    "print(mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "res1=np.multiply(mask,sampl3)\n",
    "print(res1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(gen_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "gen_image.reshape(28,28)\n",
    "print(gen_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "gen_image2=gen_image[0,:,:,0]\n",
    "print(gen_image2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa977c47050>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUP8PqrpmnvYA2loAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa97060e410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res2=np.multiply(mask2,gen_image2)\n",
    "res=np.add(res1,res2)\n",
    "plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
